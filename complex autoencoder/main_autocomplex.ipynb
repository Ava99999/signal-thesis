{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e465fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy\n",
    "import random\n",
    "import cmath\n",
    "#import pylops # might not need\n",
    "import math\n",
    "import pyproximal\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.saving import register_keras_serializable, deserialize_keras_object\n",
    "from tensorflow.test import compute_gradient\n",
    "from tensorflow.compat.v1 import assign_sub\n",
    "\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "from scipy.fft import fft, ifft, fft2, ifft2\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import autosetup \n",
    "from backpropagation import CBP\n",
    "from complex_optimizer import Complex_SGD, adaptive_stepsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6243d911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed190db",
   "metadata": {},
   "source": [
    "Some nice tensorflow links\n",
    "https://www.tensorflow.org/guide/keras/making_new_layers_and_models_via_subclassing#putting_it_all_together_an_end-to-end_example \n",
    "https://www.tensorflow.org/guide/keras/functional_api\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Layer#used-in-the-notebooks\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Layer#call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64642c61",
   "metadata": {},
   "source": [
    "## Autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00bbead",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3ae6f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# code from: https://www.tensorflow.org/tutorials/generative/autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1653b30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "(60000, 10, 10)\n",
      "(10000, 10, 10)\n",
      "(60000, 10, 10)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "1000\n"
     ]
    }
   ],
   "source": [
    "(x_train, _), (x_test, _) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255. #normalize the data\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "print(x_train.shape)\n",
    "print(x_test.shape)\n",
    "\n",
    "# make a smaller training set\n",
    "x_train_temp = x_train[..., tf.newaxis]\n",
    "x_train_temp = tf.image.resize(x_train_temp, [10,10])\n",
    "x_train_small = x_train_temp[:,:,:,0]\n",
    "\n",
    "x_test_temp = x_test[..., tf.newaxis]\n",
    "x_test_temp = tf.image.resize(x_test_temp, [10,10])\n",
    "x_test_small = x_test_temp[:,:,:,0]\n",
    "\n",
    "#x_train_small = tf.image.resize(x_train, [10, 10])\n",
    "#x_test_small = tf.image.resize(x_test, [10, 10])\n",
    "\n",
    "print(x_train_small.shape)\n",
    "print(x_test_small.shape)\n",
    "\n",
    "# make a complex (smaller) training set\n",
    "x_train_cx_small = tf.complex(np.ones((x_train_small.shape)).astype('float32'), x_train_small)\n",
    "x_test_cx_small = tf.complex(np.ones((x_test_small.shape)).astype('float32'), x_test_small)\n",
    "\n",
    "# make the training set smaller for testing code\n",
    "x_train_cx_reduced = x_train_cx_small[0:1000, :, :]\n",
    "\n",
    "print(x_train_cx_small.shape)\n",
    "print(type(x_train_cx_small))\n",
    "\n",
    "print(x_train_cx_reduced.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2f5faaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# representation training dataset (real case)\n",
    "ns = 5\n",
    "fig, ax = plt.subplots(1,ns)\n",
    "\n",
    "for i in range(ns):\n",
    "    x = x_train_small[i]\n",
    "    ax[i].imshow(np.real(x).reshape((10,10)),clim=[0,1])\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "acad1eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAAFBCAYAAAAR9FlyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAMZUlEQVR4nO3da4ilBR3H8efMjrqks6tuhoy7q21mxqKpeSsNiuy2mknLmiGZaZESRZYFvQgL9UWZkeIFtItgQUhiSRhZVqDtKkWg5rWWVkdGxby043qdPSfOykqB4v/Mzjh7fs/n82Z88Vt58H/Ar2dZn06v1+s1AAAMtZH5fgAAALadqAMACCDqAAACiDoAgACiDgAggKgDAAgg6gAAAog6AIAAo5VRt9ttJicnm7GxsabT6cz9UzEr+v9f6ampqWZ8fLwZGRms3918OLl5+7h5+7h5+/SKNy9FXf8DsGzZstl8Pl5HExMTzdKlSwf6NW4+3Ny8fdy8fdy8fSZe4+alqOsXfd8Df9unWbSL37EdFhuf7jZ7H7Lh5fsNws2Hk5u3j5u3j5u3z8bizUtRt/Ur2v4HYNGYD8GwmclX7G4+3Ny8fdy8fdy8fTqvcXMXBQAIIOoAAAKIOgCAAKIOACCAqAMACCDqAAACiDoAgACiDgAggKgDAAgg6gAAAog6AIAAog4AIICoAwAIIOoAAAKIOgCAAKIOACCAqAMACCDqAAACiDoAgACiDgAggKgDAAgg6gAAAog6AIAAog4AIICoAwAIIOoAAAKIOgCAAKIOACCAqAMACCDqAAACiDoAgACiDgAggKgDAAgg6gAAAog6AIAAog4AIICoAwAIIOoAAAKIOgCAAKIOACCAqAMACCDqAAACiDoAgACiDgAggKgDAAgg6gAAAog6AIAAog4AIICoAwAIIOoAAAKIOgCAAKIOACCAqAMACCDqAAACiDoAgACiDgAggKgDAAgg6gAAAog6AIAAog4AIICoAwAIIOoAAAKIOgCAAKIOACCAqAMACCDqAAACiDoAgACiDgAggKgDAAgg6gAAAog6AIAAog4AIICoAwAIIOoAAAKIOgCAAKIOACCAqAMACCDqAAACiDoAgACiDgAggKgDAAgg6gAAAog6AIAAog4AIICoAwAIIOoAAAKIOgCAAKIOACCAqAMACCDqAAACiDoAgACiDgAggKgDAAgg6gAAAog6AIAAog4AIICoAwAIIOoAAAKIOgCAAKIOACCAqAMACCDqAAACiDoAgACiDgAggKgDAAgg6gAAAoxWRr1eb8vPjU935/p5mEVb77X1foNw8+Hk5u3j5u3j5u2zsXjzUtRNTU1t+bn3IRtm49l4nfXvt3jx4oF/TZ+bDyc3bx83bx83b5+p17h5p1dI/W6320xOTjZjY2NNp9OZ7WdkjvRP2/8AjI+PNyMjg/1Ou5sPJzdvHzdvHzdvn17x5qWoAwBg++YPSgAABBB1AAABRB0AQABRBwAQQNQBAAQQdQAAAUQdAEAAUQcAEEDUAQAEEHUAAAFEHQBAAFEHABBA1AEABBB1AAABRB0AQABRBwAQQNQBAAQQdQAAAUQdAEAAUQcAEEDUAQAEEHUAAAFEHQBAAFEHABBA1AEABBB1AAABRB0AQABRBwAQQNQBAAQQdQAAAUQdAEAAUQcAEEDUAQAEEHUAAAFEHQBAAFEHABBA1AEABBB1AAABRB0AQABRBwAQQNQBAAQQdQAAAUQdAEAAUQcAEEDUAQAEEHUAAAFEHQBAAFEHABBA1AEABBB1AAABRB0AQABRBwAQQNQBAAQQdQAAAUQdAEAAUQcAEEDUAQAEEHUAAAFEHQBAAFEHABBA1AEABBB1AAABRB0AQABRBwAQQNQBAAQQdQAAAUQdAEAAUQcAEEDUAQAEEHUAAAFEHQBAAFEHABBA1AEABBB1AAABRB0AQABRBwAQQNQBAAQYrYy63W4zOTnZjI2NNZ1OZ+6filnR6/WaqampZnx8vBkZGazf3Xw4uXn7uHn7uHn79Io3L0Vd/wOwbNmy2Xw+XkcTExPN0qVLB/o1bj7c3Lx93Lx93Lx9Jl7j5qWo6xd939HNqma02WH2no45Nd282NzS3PDy/Qbh5sPJzdvHzdvHzdtnunjzUtRt/Yq2/wEY7fgQDI3eSz9m8hW7mw8pN28fN28fN2+fXu3m/qAEAEAAUQcAEEDUAQAEEHUAAAFEHQBAAFEHABBA1AEABBB1AAABSv/zYUizYOXbytt7P79refvWL902wycCgG3jmzoAgACiDgAggKgDAAgg6gAAAog6AIAAog4AIICoAwAIIOoAAAKIOgCAAKIOACDAvL8mbMFuu5W3/7h07/L2awffWN5+ZtFEeXvyvz5Y3t758Hh5u+Lsp8rb6Qfqz9sqhx9Qnl533Y/L21X3rC5vJ7757vJ22blrm2G2afUR5e3O1+a+Pu2x6+uvnNvj+Pvm9FmYuffc8Vx5+7P7Ditvl6+5c4ZPxExe63j/qbuXt2++vn7zHe5+oLzd/PgTzXzxTR0AQABRBwAQQNQBAAQQdQAAAUQdAEAAUQcAEEDUAQAEEHUAAAFEHQBAAFEHABBg3l8TtvnJJ8vbnW5/e3n70aPvL2+P2+vo8nbByjeWt8vvqr8eZrq8bJkjDyxPr/vFD8vbQy79cnm7aEO3vD33Wz8tb684d0UzzDad8p/ydudrm1h77Lxpvh+BV/Hkqe8qb1cvurC8vXnNwhk+EVu98OH6q9bOvPia8vYnB60sb793903l7VmfPKO87azzmjAAALaBqAMACCDqAAACiDoAgACiDgAggKgDAAgg6gAAAog6AIAAog4AIICoAwAIMO+vCRvEXt9ZW95+7iNrytvRfXYob6fvuq+85ZWNLKy/YufKay4rb9ccurq8XfpI/bM0iOMvqL/27opmuJ238pfl7cXN/s2863TK0/UXHFHe7vin+n8bL2seKm95ZZ3R+r+2fnfe98vbk1adNsBT3DvAtj2ePvHI8vbT376+vP3Rfm8ubx878x3l7cdv27e83Wfd7c0w8E0dAEAAUQcAEEDUAQAEEHUAAAFEHQBAAFEHABBA1AEABBB1AAABRB0AQABRBwAQYKheEzaIF9/7cHnb+cNe5e0Tz+xX3u5+3P3lbZusv6r+z/CEcw8ub5c8sm6GT8RMPNfdsbxdfMuS8vYr4zeWt09131DennX16eXtHisfLW8XHbuhvGXbXfjPm8vbVX8/ubzd5Q6v/tpWjx5e3+6/02R5e9WD9X+Xjo3cWt6uXn5Uk8Y3dQAAAUQdAEAAUQcAEEDUAQAEEHUAAAFEHQBAAFEHABBA1AEABBB1AAABRB0AQIDY14QN4rGfLy9vbz3nkvL2Y4veV95u3rixaYtdx54tb3e78o5mvg3yiqtj15xW3naa25thdsV+KwZYP15entO8s5kLy5u15e3X199Z3n63e8AMn4itXjymfvPxBfU7Ljqh/iqqbnnJq3nL2fVXdJ1/9kHl7cjCheXt9ev/XN423c1NGt/UAQAEEHUAAAFEHQBAAFEHABBA1AEABBB1AAABRB0AQABRBwAQQNQBAAQQdQAAAYbqNWHPrzqsvL38sovK28nN9VcCfeCzZ5S3O238S3nLK1vwx/HyduPz9VfJfGPfG8rbi075RHnbWTvcr/6C+XD8RTeVtyfdf2L9b/zcQzN7ILYvCxbM9xMMDd/UAQAEEHUAAAFEHQBAAFEHABBA1AEABBB1AAABRB0AQABRBwAQQNQBAAQQdQAAAebkNWEvfOjQ8vbqK39Q3v7+mcny9lPnf7W8XXLluvJ2p8arv7bVkhPrd3z+V0vK202/3rO8vfiS/cvbTuPVX23z1Oad5/sRWmXVLneVt795/65z+ixsf7qbNpW3/978bHnbGa0nUG96uhkGvqkDAAgg6gAAAog6AIAAog4AIICoAwAIIOoAAAKIOgCAAKIOACCAqAMACCDqAAACzMlrwnb87V/L29OXHz0Xj9Asaeqv/mL7feXL6DH17ZuaB2f4RPD/rthvxXw/Qqt8ce+j5vsRCHH6gceWtw9/YWV5u+dFa5th4Js6AIAAog4AIICoAwAIIOoAAAKIOgCAAKIOACCAqAMACCDqAAACiDoAgLa8UaLX6235Od282DQv/SVDYMu9/ud+g3Dz4eTm7ePm7ePmr67Xe6G83fz8c+XtdO+lf+bb+81LUTc1NbXl5y3NDbPxbLzO+vdbvHjxwL+mz82Hk5u3j5u3j5u/gqcG2F5en97TDMfNO71C6ne73WZycrIZGxtrOp3ObD8jc6R/2v4HYHx8vBkZGex32t18OLl5+7h5+7h5+/SKNy9FHQAA2zd/UAIAIICoAwAIIOoAAAKIOgCAAKIOACCAqAMACCDqAACa4fdf7KgrBMeBfbMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ns = 5\n",
    "fig, ax = plt.subplots(2,ns)\n",
    "\n",
    "for i in range(ns):\n",
    "    x = x_train_cx_small[i]\n",
    "    ax[0,i].imshow(np.real(x).reshape((10,10)),clim=[0,1], cmap= 'viridis')\n",
    "    ax[0,i].set_xticks([])\n",
    "    ax[0,i].set_yticks([])\n",
    "    ax[1,i].imshow(np.imag(x).reshape((10,10)),clim=[0,1], cmap='viridis')\n",
    "    ax[1,i].set_xticks([])\n",
    "    ax[1,i].set_yticks([])\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12ea2bf",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "481a9dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper for training\n",
    "# FOR SOME REASON THIS BREAKS DOWN AND THEN GIVES SIZE/SHAPE ERRORS? BUT EXECUTING IT SEPARATELY IS WORKING FINE\n",
    "@tf.function\n",
    "def train_step(x, encoder, decoder, optimizer):\n",
    "    y = encoder(decoder(x))\n",
    "    print(\"i still work\")\n",
    "    loss_value = autosetup.loss_MSE(y, x)\n",
    "    grads_and_vars = CBP(x, y, encoder, decoder, autosetup.dLossdaL, autosetup.Jac_modrelu)\n",
    "    _ = optimizer.apply_gradients(grads_and_vars)\n",
    "    return loss_value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "78244d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "100\n",
      "(1, 100)\n",
      "<class 'tensorflow.python.data.ops.batch_op._BatchDataset'>\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one sample) at sample 100: 87.2146\n",
      "Training loss (for one sample) at sample 200: 55.6129\n",
      "Training loss (for one sample) at sample 300: 26.3967\n",
      "Training loss (for one sample) at sample 400: 25.0953\n",
      "Training loss (for one sample) at sample 500: 9.1731\n",
      "Training loss (for one sample) at sample 600: 6.2533\n",
      "Training loss (for one sample) at sample 700: 10.0353\n",
      "Training loss (for one sample) at sample 800: 9.7028\n",
      "Training loss (for one sample) at sample 900: 7.9687\n",
      "Training loss (for one sample) at sample 1000: 11.0781\n",
      "Epoch 1 | Loss: 30.16505 | Max grad norm: \n",
      "Time taken: 28.65s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one sample) at sample 100: 5.2752\n",
      "Training loss (for one sample) at sample 200: 8.6797\n",
      "Training loss (for one sample) at sample 300: 9.0234\n",
      "Training loss (for one sample) at sample 400: 11.3849\n",
      "Training loss (for one sample) at sample 500: 5.5226\n",
      "Training loss (for one sample) at sample 600: 4.4730\n",
      "Training loss (for one sample) at sample 700: 7.1682\n",
      "Training loss (for one sample) at sample 800: 7.6780\n",
      "Training loss (for one sample) at sample 900: 7.0396\n",
      "Training loss (for one sample) at sample 1000: 8.3720\n",
      "Epoch 2 | Loss: 7.54047 | Max grad norm: \n",
      "Time taken: 27.84s\n"
     ]
    }
   ],
   "source": [
    "# ref: https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch\n",
    "\n",
    "# parameters (might move somewhere else)\n",
    "EPOCHS = 2\n",
    "dataset = x_train_cx_reduced\n",
    "dataset_size = dataset.shape[0]\n",
    "reshape_dataset = tf.reshape(dataset, (dataset_size,-1))\n",
    "sample_shape = reshape_dataset.shape[-1]\n",
    "print(dataset_size)\n",
    "print(sample_shape)\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(reshape_dataset).batch(1)\n",
    "\n",
    "for x in train_dataset.take(1):\n",
    "    print(x.shape)\n",
    "\n",
    "# train_dataset = (\n",
    "#     tf.data.Dataset.from_tensor_slices(reshape_dataset)\n",
    "#     .shuffle(dataset_size, reshuffle_each_iteration=True) # reshuffle the entire dataset\n",
    "#     .batch(1)\n",
    "# )\n",
    "\n",
    "encoder = autosetup.ComplexEncoder([50, 10])\n",
    "decoder = autosetup.ComplexDecoder([50, 100])\n",
    "\n",
    "# initialize layers: on first call their shape is set based on the shapes of the first data\n",
    "dummy = tf.zeros((1, sample_shape), dtype=tf.complex64)\n",
    "_ = decoder(encoder(dummy))\n",
    "\n",
    "print(type(train_dataset))\n",
    "\n",
    "optimizer = Complex_SGD(adaptive_stepsize)\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nStart of epoch {epoch+1}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    count = 0\n",
    "    epoch_loss = 0.0\n",
    "    for x in train_dataset:\n",
    "        y = decoder(encoder(x))\n",
    "        loss = autosetup.loss_MSE(y, x)\n",
    "        grads_and_vars = CBP(x, y, encoder, decoder, autosetup.dLossdaL, autosetup.Jac_modrelu)\n",
    "        _ = optimizer.apply_gradients(grads_and_vars)\n",
    "\n",
    "        count += 1 # this is a but ugly\n",
    "        epoch_loss += loss.numpy()\n",
    "\n",
    "        if count % 100 == 0:\n",
    "            print(\n",
    "                \"Training loss (for one sample) at sample %d: %.4f\"\n",
    "                % (count, float(loss))\n",
    "            )\n",
    "\n",
    "    avg_loss = epoch_loss/(dataset_size)\n",
    "    print(f\"Epoch {epoch+1} | Loss: {avg_loss:.5f} | Max grad norm: \") # {max_grad_norm:.2f} TODO\n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6987db3b",
   "metadata": {},
   "source": [
    "### Testing (temporary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0572838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "6\n",
      "2\n",
      "value initial loss function tf.Tensor(357.42612, shape=(), dtype=float32)\n",
      "(1, 100)\n",
      "(1, 100)\n",
      "dR_dqL from list and [-1] (1, 100)\n",
      "Layer L W1 <class 'keras.src.backend.Variable'> True\n",
      "layer number l =  3\n",
      "W1 <class 'keras.src.backend.Variable'> True\n",
      "layer number l =  2\n",
      "W1 <class 'keras.src.backend.Variable'> True\n",
      "layer number l =  1\n",
      "W1 <class 'keras.src.backend.Variable'> True\n",
      "list of gradients 12\n",
      "W1 <class 'keras.src.backend.Variable'> True\n",
      "W2 <class 'keras.src.backend.Variable'> True\n",
      "bias <class 'keras.src.backend.Variable'> True\n",
      "W1 <class 'keras.src.backend.Variable'> True\n",
      "W2 <class 'keras.src.backend.Variable'> True\n",
      "bias <class 'keras.src.backend.Variable'> True\n",
      "W1 <class 'keras.src.backend.Variable'> True\n",
      "W2 <class 'keras.src.backend.Variable'> True\n",
      "bias <class 'keras.src.backend.Variable'> True\n",
      "W1 <class 'keras.src.backend.Variable'> True\n",
      "W2 <class 'keras.src.backend.Variable'> True\n",
      "bias <class 'keras.src.backend.Variable'> True\n",
      "value after training loss tf.Tensor(133.60799, shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# encoder neuron size should include latent_dim at end and not original dimension\n",
    "# decoder should include original_dim at end and not latent_dim\n",
    "\n",
    "encoder = autosetup.ComplexEncoder([50, 10])\n",
    "decoder = autosetup.ComplexDecoder([50, 100])\n",
    "\n",
    "# create x_example\n",
    "x_testing = tf.reshape(x_train_cx_small[0], [1,-1])\n",
    "print(x_testing.shape)\n",
    "print(type(x_testing))\n",
    "\n",
    "# output of the autoencoder model encoder (untrained)\n",
    "y = encoder(x_testing)\n",
    "#print(y)\n",
    "print(len(encoder.weights)) # #[layers] x #[objects in a layer]\n",
    "print(len(encoder.layers_list))\n",
    "\n",
    "# testing autoencoder decoder (untrained)\n",
    "z_testing = tf.complex(2.0*np.ones(10, dtype=np.float32), 1.2*np.ones(10, dtype=np.float32))\n",
    "x_recon = decoder(y)\n",
    "init_loss = autosetup.loss_MSE(x_recon, x_testing)\n",
    "print(\"value initial loss function\", init_loss)\n",
    "#print(x_recon)\n",
    "#print(decoder(z_testing))\n",
    "\n",
    "# testing backpropagation\n",
    "grads_and_vars = CBP(x_testing, x_recon, encoder, decoder, autosetup.dLossdaL, autosetup.Jac_modrelu)\n",
    "print(\"list of gradients\", len(grads_and_vars))\n",
    "\n",
    "for g, v in grads_and_vars:\n",
    "    #print(f\"grad shape: {g.shape}, variable shape: {v.shape}\")\n",
    "    print(v.name, type(v), hasattr(v, \"assign_sub\"))\n",
    "    assert g.shape == v.shape\n",
    "\n",
    "# see if we see any change in loss \n",
    "learning_rate = 0.001\n",
    "for grad, var in grads_and_vars:\n",
    "    var.assign_sub(learning_rate * grad)\n",
    "\n",
    "y_update = encoder(x_testing)\n",
    "x_update = decoder(y)\n",
    "after_loss = autosetup.loss_MSE(x_update, x_testing)\n",
    "print(\"value after training loss\", after_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "51d0db64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'complex_optimizer.Complex_SGD'>\n",
      "<Variable path=decoder/encoder/W1, shape=(50, 100), dtype=complex64, value=[[ 0.08407198+0.0355203j   0.1064988 -0.11332123j -0.05681311-0.06265077j\n",
      "  ...  0.11416439+0.12217642j  0.11932155-0.05149338j\n",
      "   0.1347353 -0.07555947j]\n",
      " [ 0.07016787+0.13611604j -0.11399043+0.09901472j  0.11279282+0.06597946j\n",
      "  ... -0.11471839+0.12939231j  0.01090177-0.03540134j\n",
      "   0.04525091-0.00730222j]\n",
      " [-0.06751244-0.05650854j -0.05677575-0.05225705j  0.00348794-0.00813718j\n",
      "  ... -0.09384683-0.09460504j  0.11538276+0.12527736j\n",
      "   0.00735734-0.10907213j]\n",
      " ...\n",
      " [ 0.0353076 +0.10413655j  0.10275225+0.13137001j  0.08335386-0.10515676j\n",
      "  ...  0.11757358+0.14010115j  0.04667952+0.08015239j\n",
      "   0.00032138-0.05660041j]\n",
      " [ 0.06972934-0.055038j   -0.13404895+0.09888834j  0.06749296-0.11944198j\n",
      "  ... -0.0404437 -0.06584959j -0.01712391-0.08681728j\n",
      "  -0.12122338-0.11645416j]\n",
      " [ 0.1166731 +0.12365077j  0.0635538 +0.02370979j -0.06973651-0.03305044j\n",
      "  ...  0.0395662 -0.06890406j -0.05529035+0.03415842j\n",
      "   0.12840217-0.11126899j]]>\n",
      "<Variable path=decoder/encoder/W2, shape=(50, 100), dtype=complex64, value=[[ 0.08685447+0.00973574j  0.07895714+0.12699954j -0.07823589+0.08774947j\n",
      "  ... -0.04417842-0.10625183j  0.12423439-0.04200583j\n",
      "  -0.12639037-0.01854457j]\n",
      " [ 0.00768837-0.09146527j -0.07816596+0.12388922j  0.05419561-0.12158547j\n",
      "  ...  0.03562927-0.08418173j -0.06589961+0.02885485j\n",
      "   0.01641891+0.10828555j]\n",
      " [-0.11704222+0.10234569j  0.11574212+0.0534686j  -0.10294287-0.00110484j\n",
      "  ... -0.06967853+0.1003788j   0.06400591+0.10420622j\n",
      "   0.09657412-0.03698156j]\n",
      " ...\n",
      " [ 0.0701841 -0.1271857j   0.12092189-0.03359643j  0.03295869-0.01698557j\n",
      "  ... -0.037901  +0.12288585j  0.08155269+0.13983554j\n",
      "  -0.11858947+0.05680629j]\n",
      " [ 0.07058597+0.03122087j  0.1238327 +0.02775684j -0.0383166 -0.04816386j\n",
      "  ...  0.09508535+0.04014772j -0.06673275-0.0392807j\n",
      "  -0.11517593-0.00364196j]\n",
      " [ 0.02972419+0.04971041j -0.04929393-0.08933278j  0.0495053 -0.08460429j\n",
      "  ...  0.0923807 +0.10609585j -0.11939643-0.07630607j\n",
      "   0.0048638 +0.13611932j]]>\n",
      "<Variable path=decoder/encoder/bias, shape=(100,), dtype=complex64, value=[ 3.7635672e-03+4.9277605e-05j  2.0309486e-03-4.5292475e-04j\n",
      "  8.3581556e-04-8.7463734e-04j -9.7509020e-04-1.3349687e-03j\n",
      "  0.0000000e+00+0.0000000e+00j  1.4223958e-03-2.6985151e-03j\n",
      " -1.0103089e-03-1.2083833e-04j  3.3593054e-03-5.3205462e-05j\n",
      "  1.6945467e-03-1.3882621e-03j  1.2272359e-03-1.4984891e-03j\n",
      "  2.2053723e-04-9.3843054e-04j  5.8994879e-04+5.8253633e-04j\n",
      "  4.2956395e-04-6.6991663e-05j  8.4323221e-04+5.3102820e-04j\n",
      " -1.6632515e-03-6.2135071e-04j  0.0000000e+00+0.0000000e+00j\n",
      "  1.5413286e-03-4.2391627e-04j  1.8002127e-03+1.6451495e-03j\n",
      "  2.6796877e-03-6.4741768e-04j  2.2361884e-03-1.7913320e-03j\n",
      "  9.7637565e-04-8.4101886e-04j  2.1156550e-03-6.6127272e-05j\n",
      "  4.1052676e-04-7.2374602e-04j -4.3905020e-04+1.3807619e-03j\n",
      "  2.3047926e-03+4.8667158e-04j  1.7885034e-04+8.7202253e-04j\n",
      "  2.9347739e-03-1.7540548e-03j  7.1804374e-05-1.4179247e-03j\n",
      " -3.0975891e-04+7.7366520e-04j  3.4601092e-03-1.1231056e-03j\n",
      "  1.6378826e-03-6.4370979e-05j -1.2056198e-03-2.7413236e-04j\n",
      "  1.9614132e-04+1.2613772e-04j  3.7703846e-04+9.9794206e-04j\n",
      "  2.1868609e-03+1.1668520e-03j  1.1320091e-03-8.7487989e-04j\n",
      " -9.2413859e-04+1.4980607e-03j  6.5797963e-04-2.2186553e-03j\n",
      "  3.3257843e-04+1.6642414e-04j  1.7252899e-03+5.4235483e-04j\n",
      "  5.5859750e-04-1.3430386e-03j  2.2626522e-03+7.3349156e-04j\n",
      " -4.0412502e-04+3.1220657e-04j -2.0247351e-03-4.9845325e-03j\n",
      "  1.7813513e-04+1.6449206e-03j  2.8251626e-03+9.8084379e-04j\n",
      "  2.6497012e-03-1.5100302e-03j  3.1327205e-03+4.6914100e-04j\n",
      "  1.7671607e-03+2.8105155e-03j -1.9488619e-03+2.4619594e-04j\n",
      "  1.8395185e-03-1.8130703e-03j -5.3029857e-04+9.0139796e-04j\n",
      " -1.3731094e-03+5.8920641e-04j  0.0000000e+00+0.0000000e+00j\n",
      "  1.4506638e-03-5.0928612e-04j  0.0000000e+00+0.0000000e+00j\n",
      "  1.9876868e-03+1.5692068e-03j  2.4764950e-03-2.9670802e-04j\n",
      "  2.2043022e-03-1.6514927e-03j  6.8117370e-04+1.3316381e-05j\n",
      "  4.2953943e-03+4.1813531e-04j  2.8594866e-04-6.6080276e-04j\n",
      " -2.5312990e-04+8.3613460e-04j -2.3344732e-05+1.0366763e-03j\n",
      "  1.4127523e-03-5.8541389e-04j  1.7130293e-03+3.5306073e-03j\n",
      "  3.2443731e-04+1.0883041e-03j  8.2683755e-04+5.0417770e-04j\n",
      "  3.8396829e-04-5.1274500e-04j  4.0787578e-04-2.9796496e-04j\n",
      "  0.0000000e+00+0.0000000e+00j  2.5984000e-03+1.1812221e-03j\n",
      "  8.6549396e-04+3.2052997e-04j  2.7861760e-04-8.3862385e-04j\n",
      "  2.5171863e-03+6.8880658e-04j -2.3075632e-05+1.4277544e-03j\n",
      "  2.6322273e-04-1.1177405e-03j  1.7379818e-03-3.9381074e-04j\n",
      "  1.3416704e-05+1.5134527e-03j  5.3351023e-04+7.7449286e-04j\n",
      "  3.9512152e-04+2.2416552e-04j  2.5037138e-03+1.9373689e-03j\n",
      " -1.9172132e-04+1.5551090e-04j  1.1239822e-04+1.5714071e-03j\n",
      "  1.1841105e-03+1.0234268e-03j -6.3534537e-07+1.5423626e-04j\n",
      "  0.0000000e+00+0.0000000e+00j  1.8025134e-03-1.1104285e-03j\n",
      " -1.2136857e-03-2.4622055e-03j -8.1122119e-04-2.6606681e-04j\n",
      "  2.3764526e-03-1.4489661e-03j  1.6627850e-03-2.4589157e-04j\n",
      "  1.0566015e-03+1.3418290e-03j  2.6800000e-04-8.1959140e-04j\n",
      "  1.1505861e-04-1.4854135e-03j  1.2613655e-03+1.2513495e-03j\n",
      " -2.1454887e-03-1.4040490e-03j  4.8677297e-04+1.7116442e-03j\n",
      "  2.0784005e-03-1.5436970e-03j  1.5677412e-03+1.5669942e-03j]>\n",
      "<Variable path=decoder/encoder/W1, shape=(10, 50), dtype=complex64, value=[[-0.03344676+1.34584218e-01j -0.18558054+3.96117754e-02j\n",
      "   0.09243328+2.00130120e-01j  0.15772222-1.27117336e-01j\n",
      "  -0.20784518+6.22679405e-02j  0.12873502-1.76562324e-01j\n",
      "   0.12044217-2.53304616e-02j -0.12530921+2.03553438e-01j\n",
      "   0.1707788 -7.29728937e-02j  0.01695734-2.17550382e-01j\n",
      "   0.02451636-9.54211205e-02j  0.0765809 -1.26243383e-02j\n",
      "  -0.03115325-1.22337364e-01j -0.02739544+2.48683207e-02j\n",
      "  -0.09356486-1.24415860e-01j  0.03672299-1.09097473e-01j\n",
      "  -0.08595508-5.00816677e-05j  0.19715242-3.30930278e-02j\n",
      "  -0.06878128+9.39318165e-02j -0.1172983 -8.01192317e-03j\n",
      "  -0.21628183+1.27299875e-01j -0.03301287-6.02704324e-02j\n",
      "   0.09490126-1.80472091e-01j  0.05393773-4.43926547e-03j\n",
      "   0.20858027+1.70585498e-01j -0.04626168-6.36077672e-02j\n",
      "   0.10692851-1.57081887e-01j  0.0573162 -1.78323656e-01j\n",
      "  -0.03604003+1.41827375e-01j -0.05823103+7.12004602e-02j\n",
      "  -0.18677533+2.00093031e-01j  0.18501441-1.88170105e-01j\n",
      "  -0.07584622+2.28285529e-02j -0.19463569-8.25345442e-02j\n",
      "  -0.12662011-5.59035987e-02j -0.03124461-2.06595168e-01j\n",
      "  -0.08007029-9.01910067e-02j -0.17609769-8.22013244e-03j\n",
      "  -0.03626032-3.82598527e-02j  0.19173798+1.33403257e-01j\n",
      "   0.05125678-4.14512828e-02j  0.08095489-2.43336465e-02j\n",
      "  -0.19167012+1.26413465e-01j  0.17822193+2.46704854e-02j\n",
      "  -0.06725363-4.62534698e-03j  0.12341063-9.84536335e-02j\n",
      "  -0.14382385-3.50783626e-03j  0.04390034+2.62147225e-02j\n",
      "   0.00249826-2.26986166e-02j  0.2218752 +7.20232800e-02j]\n",
      " [-0.01747942-2.09067568e-01j -0.20926541-2.78233998e-02j\n",
      "   0.16052642+7.47304484e-02j  0.05662458-1.75936863e-01j\n",
      "  -0.05108915+1.44690603e-01j -0.11481419+7.76719898e-02j\n",
      "  -0.05210257+1.58810213e-01j  0.04388092-1.74357355e-01j\n",
      "  -0.12837416-1.36176035e-01j -0.1305854 -6.52604625e-02j\n",
      "  -0.16303577+1.89282179e-01j  0.218069  -1.04036793e-01j\n",
      "   0.05971633+5.92427664e-02j  0.18767744-2.08521783e-01j\n",
      "   0.09290155+4.64557931e-02j -0.136173  -1.22196451e-01j\n",
      "  -0.16761455-6.63276240e-02j  0.17837349+1.36195555e-01j\n",
      "   0.10579031-1.56309769e-01j  0.11614206+1.74748749e-01j\n",
      "  -0.22231126-1.92571431e-01j -0.04533258-6.67985678e-02j\n",
      "   0.21636926-1.27504647e-01j -0.04604705+1.12529315e-01j\n",
      "   0.01811539-1.05092764e-01j -0.01644412-9.17893797e-02j\n",
      "  -0.1003297 -6.22805133e-02j  0.1793204 +2.05302820e-01j\n",
      "  -0.03193809-1.66788742e-01j  0.14512622-1.20088486e-02j\n",
      "  -0.16230136+6.23401739e-02j -0.198324  +1.13405742e-01j\n",
      "   0.08597867+4.91895638e-02j -0.1540256 -1.77640438e-01j\n",
      "  -0.0369454 -2.08018810e-01j  0.20415686-1.29484311e-01j\n",
      "   0.06297065+7.47887194e-02j -0.004005  +7.52821937e-02j\n",
      "   0.10755204+3.32485363e-02j  0.16599026+4.45002830e-03j\n",
      "   0.21327761+1.57161072e-01j  0.09219127+9.75540280e-02j\n",
      "   0.19008352-1.14467964e-01j  0.1293586 +1.12319283e-01j\n",
      "  -0.15574764+1.51497081e-01j  0.1424764 -1.37319565e-01j\n",
      "  -0.1779682 +5.13314717e-02j  0.01957917+2.09816411e-01j\n",
      "  -0.00468938-1.88554078e-01j -0.10407445-1.35433003e-01j]\n",
      " [-0.05568753-1.73404932e-01j -0.18753012-2.21153781e-01j\n",
      "  -0.21157537-2.24251628e-01j  0.09466897-1.93154573e-01j\n",
      "   0.0637622 +1.87267046e-02j -0.00370457-1.24296829e-01j\n",
      "   0.09486424+6.88911304e-02j -0.00721418-1.63904056e-01j\n",
      "  -0.20748836-1.68040961e-01j  0.02870416-1.04709134e-01j\n",
      "   0.18999656+1.54214367e-01j  0.10867693+6.30950034e-02j\n",
      "   0.08690063+4.59616864e-03j  0.0773956 -1.58187337e-02j\n",
      "  -0.2047879 +4.00826409e-02j  0.2196613 -1.19667321e-01j\n",
      "  -0.10066498-1.12556599e-01j -0.0941993 +2.62507983e-02j\n",
      "   0.13919732+2.01343313e-01j -0.0399832 -1.95456028e-01j\n",
      "  -0.19453342-5.64269200e-02j -0.17619969-1.88107282e-01j\n",
      "  -0.13744324-5.07444069e-02j  0.09805902+6.51858151e-02j\n",
      "   0.1149551 +2.54628225e-03j -0.07195687+1.38341010e-01j\n",
      "   0.09008977-1.67217284e-01j  0.05739002+1.02892093e-01j\n",
      "  -0.19600867+1.82362162e-02j  0.20375046-2.11557731e-01j\n",
      "   0.05672181-1.44092679e-01j -0.20613743-1.34480610e-01j\n",
      "   0.21945818-1.72429010e-01j  0.18160032-1.05074689e-01j\n",
      "   0.12828454+2.19232127e-01j -0.14887677-2.49446742e-02j\n",
      "   0.12085488-7.56612644e-02j  0.19146158+1.31568477e-01j\n",
      "  -0.02186029+1.93794653e-01j  0.16955501+9.14687887e-02j\n",
      "   0.07326097+1.85050622e-01j  0.15249649+5.34452777e-03j\n",
      "  -0.18560015+2.12459564e-01j -0.09367669+6.86933771e-02j\n",
      "   0.20042393+5.40843653e-03j  0.18038592+2.40724701e-02j\n",
      "   0.06947017-2.19831064e-01j -0.21832608+2.77567357e-02j\n",
      "   0.04717811-6.48675188e-02j -0.02178506-8.73470586e-03j]\n",
      " [ 0.20897765+2.08951518e-01j -0.06186786-1.31858990e-01j\n",
      "   0.1919641 -1.09169707e-01j  0.17845187-9.14412457e-03j\n",
      "  -0.10577415+1.08605646e-01j  0.18211259+1.30544022e-01j\n",
      "  -0.02056489+2.96161715e-02j  0.12659071+5.79997897e-02j\n",
      "  -0.15209134+7.90247917e-02j -0.18448488+1.69492096e-01j\n",
      "   0.20912915-2.72789486e-02j  0.17850524+6.29290715e-02j\n",
      "   0.12423493-5.59671735e-03j  0.14273524+2.11925924e-01j\n",
      "   0.06441123+1.82544172e-01j -0.11597007-1.55869961e-01j\n",
      "  -0.09528587+9.37594101e-02j -0.15450658-2.05858052e-01j\n",
      "   0.09953598+1.85959935e-02j -0.18833196+1.67705882e-02j\n",
      "  -0.17668286-1.60352841e-01j  0.03703636-1.26096562e-01j\n",
      "  -0.12959194-2.09800139e-01j -0.09428869+8.16943571e-02j\n",
      "  -0.14639962+1.10385768e-01j -0.06817397-2.16606021e-01j\n",
      "   0.1692734 -4.96585444e-02j -0.096486  +1.21215716e-01j\n",
      "   0.07263245-1.66306362e-01j -0.13185675+7.95853734e-02j\n",
      "  -0.0266489 -2.01546848e-01j  0.21993044-9.22862813e-02j\n",
      "  -0.0234058 -1.67991132e-01j -0.05408493-1.95803598e-01j\n",
      "   0.1109241 -1.15244448e-01j -0.04768388+1.65462092e-01j\n",
      "  -0.027562  -1.17545187e-01j  0.08197965-9.28831846e-03j\n",
      "  -0.17858034-8.56047049e-02j  0.1199315 +1.66050747e-01j\n",
      "   0.00793052-2.07641065e-01j  0.17771524-1.05594851e-01j\n",
      "   0.06557348-9.87934917e-02j -0.20546101+7.91552663e-02j\n",
      "   0.03379986+2.09823415e-01j  0.11886147+1.29586026e-01j\n",
      "   0.0284987 -1.10839218e-01j  0.04063958-6.31508827e-02j\n",
      "  -0.14727394-1.57840520e-01j -0.11588668-6.30488992e-02j]\n",
      " [-0.04869762-2.03260809e-01j -0.17498952-8.28890800e-02j\n",
      "   0.12008899+1.82448804e-01j  0.03248611+1.94710955e-01j\n",
      "   0.20934884-9.40011069e-02j -0.02099693-4.54236194e-02j\n",
      "  -0.2188511 +1.33011833e-01j  0.09668893-1.02417782e-01j\n",
      "   0.00388468+1.06266610e-01j  0.1874422 +1.48547724e-01j\n",
      "  -0.08447709+1.69002518e-01j  0.12049835+8.36076438e-02j\n",
      "   0.02246089+1.46553904e-01j  0.08427452-3.77639048e-02j\n",
      "   0.10521709+4.05189134e-02j -0.01201192-1.80744365e-01j\n",
      "   0.07800409-1.47067636e-01j  0.09617209+1.39563531e-01j\n",
      "   0.01425227-5.99416941e-02j  0.2055698 +6.22711740e-02j\n",
      "   0.06459564+2.08360791e-01j -0.22345832-1.95170373e-01j\n",
      "  -0.09035457+8.23896751e-02j -0.10461478-1.81659624e-01j\n",
      "  -0.22036923+1.45276174e-01j  0.01406174-1.97461575e-01j\n",
      "  -0.08109013-2.17871696e-01j -0.09436878+1.05958872e-01j\n",
      "  -0.06920399-7.70232081e-02j -0.03979539+1.61923453e-01j\n",
      "  -0.04179171-2.15689046e-03j  0.21471378-5.98167144e-02j\n",
      "   0.11007785+1.62909776e-01j  0.13497843-1.98324755e-01j\n",
      "   0.18926707+1.27876580e-01j  0.13932732+1.69391617e-01j\n",
      "   0.12368555-2.17276424e-01j  0.10215872-1.05569236e-01j\n",
      "   0.1310188 -8.75449404e-02j  0.04910559-1.01122372e-01j\n",
      "  -0.05517983+2.09432319e-01j -0.12755612-2.12288320e-01j\n",
      "  -0.11039067+4.23674248e-02j  0.02873689-9.32292789e-02j\n",
      "   0.16604695-1.65940613e-01j -0.14320266-7.34197125e-02j\n",
      "   0.15311207-6.15232103e-02j -0.14123496+6.92507327e-02j\n",
      "  -0.08123118+6.58115372e-02j  0.07285834-1.13180205e-01j]\n",
      " [-0.18985517-9.82165560e-02j -0.10181729-3.73280793e-02j\n",
      "   0.06017522+1.93752870e-01j -0.11612517+1.17232271e-01j\n",
      "  -0.05457711+1.33212104e-01j  0.22175658+9.91147533e-02j\n",
      "   0.01393382+5.44191990e-03j -0.17572728+1.63288675e-02j\n",
      "  -0.10768913+1.18139036e-01j -0.20464739+9.27692745e-03j\n",
      "   0.22470433-9.92673934e-02j  0.1280295 -3.72150019e-02j\n",
      "  -0.19727682+1.14077032e-01j  0.20409925+1.86254174e-01j\n",
      "   0.16204832-3.99445519e-02j  0.2050403 +9.07493904e-02j\n",
      "   0.18085736+1.88984454e-01j -0.12287083-7.42503032e-02j\n",
      "   0.02880374-1.08476259e-01j  0.18982743+4.05759551e-02j\n",
      "   0.08906636+6.67318627e-02j  0.02671776-1.92664757e-01j\n",
      "  -0.09229831+2.00575396e-01j -0.21420549-1.39990985e-01j\n",
      "   0.07652734+7.68079981e-02j  0.21736243-2.13275224e-01j\n",
      "  -0.14380535-1.01523604e-02j -0.07147541-9.02165323e-02j\n",
      "  -0.18546128+1.40978128e-01j  0.06055843-2.57864445e-02j\n",
      "   0.19506061-7.50202104e-04j  0.22352555+4.79511321e-02j\n",
      "   0.04069638+1.11866714e-02j -0.1994862 +1.20749652e-01j\n",
      "   0.06380911+1.53105497e-01j  0.07230049-3.41932811e-02j\n",
      "  -0.12679462-1.10143237e-01j  0.06637083+1.63566381e-01j\n",
      "  -0.10881807+1.03944637e-01j  0.01570819-1.36608347e-01j\n",
      "   0.08445672-2.15603903e-01j -0.0559932 +1.87718213e-01j\n",
      "   0.09354146+9.77411494e-03j -0.19331002+5.13439961e-02j\n",
      "  -0.07145713-1.18827187e-01j -0.1442492 -1.96954921e-01j\n",
      "   0.09683399+1.95689753e-01j  0.05286716-1.30738989e-01j\n",
      "  -0.06495756-8.54452625e-02j  0.18695575+4.13156375e-02j]\n",
      " [ 0.04841281-1.47379413e-01j  0.19220571-7.87663683e-02j\n",
      "   0.19345514+1.05688512e-01j -0.21135801+5.54898679e-02j\n",
      "  -0.15801862-1.39886871e-01j  0.12485965+9.40134153e-02j\n",
      "  -0.20113418-1.35273069e-01j -0.0341522 -2.08847865e-01j\n",
      "  -0.14778556-4.76031788e-02j  0.17209013+1.14938870e-01j\n",
      "  -0.11202118-1.91865936e-01j  0.18277925-1.66118681e-01j\n",
      "  -0.03179783+2.20190048e-01j -0.07880637-1.84101701e-01j\n",
      "   0.19968742+1.04564084e-02j -0.1920768 -1.93281978e-01j\n",
      "   0.20003761-4.13949564e-02j -0.21036838-2.17616484e-01j\n",
      "   0.17838834+9.68570560e-02j -0.15342234-1.45321116e-01j\n",
      "  -0.11076287+1.19199030e-01j  0.07112782+1.50055200e-01j\n",
      "  -0.07439808-7.50167295e-02j -0.03769579-9.60544497e-02j\n",
      "   0.14331202+1.90730020e-01j  0.1600783 +1.23919159e-01j\n",
      "   0.19050224+6.65879473e-02j  0.06585813-1.40758306e-01j\n",
      "   0.15563789+7.53331631e-02j  0.13742355-1.55347079e-01j\n",
      "   0.01513605+7.45146489e-03j -0.16928005-7.20834732e-02j\n",
      "   0.01776496-7.34332055e-02j -0.06444813-2.15022773e-01j\n",
      "   0.16906606+1.91355944e-01j  0.00648409-1.33326605e-01j\n",
      "  -0.01060195-1.98349759e-01j  0.18235399-5.51830046e-02j\n",
      "   0.12559171+7.26909935e-02j -0.18823117+5.03290780e-02j\n",
      "  -0.17297493-2.20127612e-01j -0.21971314+1.93070918e-01j\n",
      "   0.01784067+9.21069756e-02j  0.04788028+4.12731580e-02j\n",
      "   0.16323245+1.59570545e-01j -0.090395  -1.00772344e-01j\n",
      "   0.1881638 -5.91481254e-02j  0.10487513-5.45323305e-02j\n",
      "   0.1777639 -2.09841892e-01j  0.08088689-2.11325601e-01j]\n",
      " [-0.00518511+1.16837859e-01j -0.05084658+5.32661714e-02j\n",
      "  -0.21952523+6.46305233e-02j  0.16393533+1.75332472e-01j\n",
      "   0.150501  -9.64046642e-02j -0.02906468+1.13167509e-01j\n",
      "  -0.05785476-1.96396604e-01j -0.15344106-2.14687124e-01j\n",
      "   0.12929112-3.53950486e-02j -0.10705328-1.69816419e-01j\n",
      "   0.15093057-6.61551952e-02j -0.18131384+3.17972824e-02j\n",
      "  -0.08245554+1.11133084e-02j -0.14870577-1.46438509e-01j\n",
      "   0.00762215-1.72967210e-01j  0.03300255+1.71352386e-01j\n",
      "  -0.06221433+1.34436622e-01j  0.10677268-1.16706908e-01j\n",
      "  -0.04783311-2.01729357e-01j -0.13143025+3.15792598e-02j\n",
      "   0.16197369-2.63806023e-02j -0.13173139-2.41466309e-03j\n",
      "   0.03115059-1.96154952e-01j  0.14758433+1.72062501e-01j\n",
      "  -0.06654245-1.87496021e-01j -0.06389271-1.13965899e-01j\n",
      "   0.1719001 +2.24700376e-01j  0.1446243 -4.60293982e-03j\n",
      "  -0.12604354-1.97134316e-01j -0.16804421-1.48253217e-01j\n",
      "  -0.15342362+1.16317026e-01j -0.04533219+8.25001746e-02j\n",
      "  -0.10812777-1.00513764e-01j -0.11111893+1.40748605e-01j\n",
      "   0.04226029+1.35098159e-01j  0.17752251-5.25607802e-02j\n",
      "  -0.03558847+2.14603823e-03j  0.0756787 -8.47598463e-02j\n",
      "  -0.06214045+1.64253443e-01j  0.19694515-1.99986044e-02j\n",
      "   0.21322869-4.53042984e-02j  0.05912514-1.99996218e-01j\n",
      "   0.18903668+5.14102541e-02j -0.06026538+1.32393604e-02j\n",
      "  -0.01809497-4.77511622e-02j  0.00575713+2.34511103e-02j\n",
      "   0.00297845-1.79880455e-01j  0.06954092+2.16127366e-01j\n",
      "  -0.05553191+2.23982379e-01j -0.14504108-1.13653488e-01j]\n",
      " [ 0.05944041+2.63884827e-03j  0.08253997-1.10786229e-01j\n",
      "   0.18801042-1.19096726e-01j  0.10915106-8.83598700e-02j\n",
      "  -0.11370472+1.61990851e-01j -0.17909376+1.64572865e-01j\n",
      "   0.1720801 -5.84676974e-02j -0.0946459 +1.92188978e-01j\n",
      "   0.13957743+2.13572130e-01j -0.18915968+1.41662061e-01j\n",
      "  -0.1387586 +6.00811094e-02j -0.10890125+4.51407731e-02j\n",
      "   0.02904306-1.22085288e-02j -0.00895308-2.10778341e-01j\n",
      "   0.11444638-2.88230814e-02j -0.17664756-7.23786727e-02j\n",
      "   0.03998372+3.46459486e-02j -0.19531573-1.96291342e-01j\n",
      "   0.08921468+8.32584426e-02j -0.209189  -1.17399327e-01j\n",
      "   0.13745843+1.49378851e-01j  0.21459717-3.75824906e-02j\n",
      "  -0.00566116-2.06000999e-01j  0.08182723+1.24147693e-02j\n",
      "  -0.09943901+1.32364221e-02j -0.00786654+2.14921106e-02j\n",
      "   0.03784912-1.97457090e-01j  0.04119654-7.17201382e-02j\n",
      "  -0.18519609+1.96270302e-01j -0.05294387+8.13100189e-02j\n",
      "   0.21243188+6.67696893e-02j -0.22107854-1.98833302e-01j\n",
      "  -0.02012251-1.56307477e-03j -0.01556601+1.41681597e-01j\n",
      "   0.01665424-1.08210877e-01j -0.0080661 -1.56828374e-01j\n",
      "  -0.12778127-1.33327559e-01j -0.12616053-1.71172351e-01j\n",
      "   0.03601229+3.15264538e-02j  0.01818738+1.73340559e-01j\n",
      "   0.0463422 +2.19336718e-01j -0.15175547+1.51357174e-01j\n",
      "   0.02854857-6.63682935e-04j  0.02094591+1.05441466e-01j\n",
      "   0.06490905-9.12860036e-02j -0.06996109-1.27877370e-01j\n",
      "   0.17387787-1.80854201e-01j -0.11026996+8.12487155e-02j\n",
      "   0.02553391+1.00642808e-01j  0.18249582-1.07986160e-01j]\n",
      " [ 0.12425551-7.20973909e-02j -0.05689928+1.23007568e-02j\n",
      "  -0.14218943-2.94925049e-02j -0.08658669-3.57371457e-02j\n",
      "   0.03770312-1.63709581e-01j -0.05860174-7.98522457e-02j\n",
      "   0.20425057+1.77381307e-01j -0.21396206+1.68520242e-01j\n",
      "   0.08570744+7.58010149e-02j -0.0180453 -3.56129408e-02j\n",
      "   0.0846331 +2.01073766e-01j  0.15969905-6.04417548e-02j\n",
      "  -0.02937254+1.66245773e-01j -0.1890085 -7.81893358e-02j\n",
      "  -0.18894345-2.01230664e-02j  0.06954136-4.09509242e-02j\n",
      "  -0.18210818-2.68540140e-02j  0.03076714+1.88192964e-01j\n",
      "   0.10447375+1.09542431e-02j  0.13192417+7.66039416e-02j\n",
      "   0.14822355-5.86270839e-02j  0.07749434-1.05057627e-01j\n",
      "   0.04675081-4.92556244e-02j -0.03403423+1.60034925e-01j\n",
      "   0.13894057-1.39668822e-01j -0.10056048-2.45933700e-02j\n",
      "  -0.00135908-1.68759286e-01j  0.01901823+6.21996596e-02j\n",
      "   0.08406942+1.18174337e-01j  0.01491118+1.88435018e-01j\n",
      "   0.0009463 -1.68489084e-01j -0.0316139 -6.94718286e-02j\n",
      "   0.15439567+6.26663957e-03j  0.05162145-2.71527059e-02j\n",
      "   0.06345484-1.75277203e-01j -0.1244824 +1.80494815e-01j\n",
      "  -0.07174378-1.86746374e-01j -0.12432586-9.41732600e-02j\n",
      "  -0.09793725+3.41494828e-02j -0.13721173-1.67450219e-01j\n",
      "   0.11875591+4.73964289e-02j -0.07249388+2.16794774e-01j\n",
      "   0.08066486+1.95452377e-01j -0.18895233+2.95623243e-02j\n",
      "   0.05298689-2.70070396e-02j -0.08636674+3.18822972e-02j\n",
      "   0.1513986 -1.15787774e-01j  0.01422844-1.17089286e-01j\n",
      "   0.06002411-1.92241281e-01j  0.04723487+7.62561932e-02j]]>\n",
      "<Variable path=decoder/encoder/W2, shape=(10, 50), dtype=complex64, value=[[-1.57731891e-01+0.04503507j -5.70534095e-02+0.00956125j\n",
      "  -1.82544202e-01+0.04697968j -3.99390981e-03+0.03347575j\n",
      "  -1.73925146e-01+0.20251037j  2.63202991e-02-0.02081277j\n",
      "   9.91444960e-02+0.02204797j  1.71040520e-01+0.17693962j\n",
      "   4.38891090e-02-0.00787946j -5.43715619e-02+0.07757095j\n",
      "   1.78855434e-01-0.1682949j   2.05496073e-01+0.15821877j\n",
      "   6.38140440e-02-0.13653028j  7.27401152e-02+0.0163975j\n",
      "  -5.32214418e-02-0.00780404j -2.37840097e-02+0.15370922j\n",
      "   6.54641911e-02-0.03308634j  1.72446415e-01+0.03721488j\n",
      "  -1.34822592e-01-0.14636478j  1.77058637e-01+0.03015248j\n",
      "   5.82140498e-02-0.15906401j -1.48698822e-01-0.18215418j\n",
      "   7.69908652e-02-0.02968911j  4.81311008e-02+0.1910461j\n",
      "   6.23937994e-02-0.01269368j  6.32538553e-03-0.1086458j\n",
      "  -5.86873889e-02-0.00632974j  1.27233878e-01-0.07264024j\n",
      "   2.93835159e-02+0.20784076j -1.42687455e-01+0.07169773j\n",
      "   1.53586075e-01-0.02715285j  1.98006064e-01-0.01032698j\n",
      "  -9.85407755e-02-0.08317039j  1.08632073e-01-0.05241245j\n",
      "  -2.67832633e-02-0.19676062j -6.57527223e-02+0.06680568j\n",
      "  -1.81483567e-01-0.01996521j -2.02915862e-01-0.00978967j\n",
      "  -2.04975158e-01-0.10479262j  2.14973822e-01+0.07582356j\n",
      "  -1.43344596e-01-0.12301163j -2.32281648e-02-0.01830058j\n",
      "  -5.35383970e-02+0.07951558j  1.93804931e-02+0.02671092j\n",
      "  -1.19514450e-01-0.16144077j -3.23683545e-02+0.06726555j\n",
      "   1.48201764e-01+0.11250301j  1.88068554e-01-0.04908669j\n",
      "   4.67662215e-02+0.00045299j  1.93578973e-01+0.07364644j]\n",
      " [-6.83152378e-02-0.06164221j  1.84787899e-01+0.03825664j\n",
      "  -1.30594522e-01+0.22544643j  1.72821850e-01+0.1080593j\n",
      "  -2.08077565e-01+0.22139513j -2.23531350e-01-0.21202016j\n",
      "  -3.41576058e-03+0.11580592j -1.16602793e-01+0.1638926j\n",
      "  -6.36885464e-02+0.16317281j  2.54036277e-03+0.07323692j\n",
      "   5.22802547e-02+0.12664364j  1.25173852e-01+0.15854417j\n",
      "   1.30248815e-01-0.18080817j -1.82652682e-01-0.17180409j\n",
      "  -9.78761315e-02+0.15820912j  1.28491089e-01-0.11289545j\n",
      "  -2.24395782e-01+0.18356141j -7.76370466e-02+0.07758923j\n",
      "  -3.08818258e-02+0.02736787j -8.34017843e-02+0.17658253j\n",
      "  -1.32716194e-01-0.15429635j  1.11944728e-01+0.10079554j\n",
      "  -1.63848907e-01+0.0689646j  -9.85574722e-02-0.01722164j\n",
      "  -6.32339790e-02-0.12234755j  1.30410761e-01+0.10427109j\n",
      "  -1.44836113e-01+0.18822987j  2.08222538e-01-0.01187937j\n",
      "   1.93608850e-01+0.18620409j -8.97292569e-02+0.14197555j\n",
      "  -1.92892238e-01-0.01427045j -4.25173603e-02-0.15066105j\n",
      "  -1.44952908e-01-0.0293671j  -1.35968179e-01-0.02512232j\n",
      "   1.54052213e-01+0.03037346j  4.94630821e-02+0.14989178j\n",
      "  -1.00389630e-01-0.05832635j -1.32618379e-02+0.18799604j\n",
      "   1.05547816e-01-0.053191j    2.68860292e-02+0.1959989j\n",
      "  -4.73435409e-02-0.1912168j   1.74483240e-01+0.10886487j\n",
      "   2.25610614e-01-0.04277886j -2.28583049e-02-0.15276586j\n",
      "   1.15795113e-01-0.19149339j -1.96306393e-01-0.19097653j\n",
      "  -1.36426955e-01-0.2187863j  -1.10279188e-01+0.19276664j\n",
      "   4.37516607e-02+0.02727476j -1.78077236e-01+0.00352033j]\n",
      " [ 1.34336606e-01-0.02310413j  1.90530196e-01+0.21717942j\n",
      "  -1.28719330e-01-0.09483796j -9.72673893e-02-0.18988973j\n",
      "  -1.14770643e-01-0.16402166j  6.18602671e-02+0.21555477j\n",
      "   1.26267187e-02-0.00370204j  3.87454033e-02-0.0786956j\n",
      "   6.71386570e-02-0.03569146j -5.89563847e-02+0.13381366j\n",
      "   9.83522646e-03+0.14292029j  7.07668960e-02-0.11502019j\n",
      "   1.60324931e-01-0.06795466j  9.21552107e-02-0.03491077j\n",
      "  -1.17741011e-01+0.09631564j  1.42559409e-01-0.13356924j\n",
      "   5.10529131e-02-0.10838688j -7.68948495e-02+0.12187846j\n",
      "   1.77878872e-01-0.01213207j  1.81509890e-02+0.03688548j\n",
      "  -5.26054762e-02+0.20164065j -1.86296150e-01+0.19737235j\n",
      "  -5.61610423e-02-0.10946348j  9.92557593e-03-0.15850565j\n",
      "   5.80602735e-02-0.15991214j -1.32164791e-01-0.11233212j\n",
      "   7.23726898e-02+0.20455593j -1.63110390e-01+0.0288238j\n",
      "   1.21190891e-01-0.17623566j  1.16499543e-01+0.03472369j\n",
      "  -3.40373837e-04+0.03901338j  1.45626813e-01+0.07635693j\n",
      "   7.68985748e-02+0.17323427j  1.22212328e-01+0.01938132j\n",
      "  -2.04006895e-01+0.07552444j  1.71738237e-01-0.07199817j\n",
      "   2.07801778e-02+0.04991867j -1.83618188e-01-0.18292536j\n",
      "  -1.60033628e-01+0.12865196j  6.51393160e-02+0.18437478j\n",
      "  -2.29640659e-02+0.01269912j  1.05282903e-01+0.01866237j\n",
      "  -2.40922254e-02+0.05489876j  2.98409984e-02-0.10608523j\n",
      "  -2.06038449e-03-0.10714573j  3.64114605e-02-0.06037377j\n",
      "  -1.90851212e-01+0.01913979j  2.23822474e-01+0.02942073j\n",
      "  -3.77393886e-02-0.10863393j -1.25915796e-01-0.18194781j]\n",
      " [-1.59554273e-01+0.05460309j -1.55017480e-01+0.01800903j\n",
      "  -8.82810280e-02+0.02919059j -1.71768993e-01+0.00667438j\n",
      "  -3.98244634e-02-0.21509326j -2.09432662e-01+0.06524341j\n",
      "   2.05235905e-03-0.07579011j  2.30770539e-02+0.16092798j\n",
      "   8.73688236e-02-0.21118717j  1.04076475e-01-0.09387084j\n",
      "   2.05742493e-01+0.01534554j  7.95622589e-04+0.18312885j\n",
      "  -9.49538127e-02-0.09329647j -5.71740530e-02-0.07715645j\n",
      "   6.87655658e-02+0.19728619j  4.39668586e-03+0.2236854j\n",
      "   3.92393172e-02-0.16135699j  8.40535536e-02-0.16608416j\n",
      "   3.68997715e-02+0.10222308j -1.76352978e-01-0.1607049j\n",
      "  -5.00841253e-02-0.05729942j -2.19579026e-01+0.06485312j\n",
      "  -2.20827356e-01+0.13217425j  1.68014690e-01+0.12349836j\n",
      "   1.49175376e-01-0.13768882j  1.56458765e-01+0.08162636j\n",
      "  -1.62944309e-02-0.1722012j  -4.72647063e-02-0.14921983j\n",
      "   1.84859395e-01-0.09195035j  2.14272082e-01-0.10549871j\n",
      "  -5.95098734e-02-0.03387787j -1.08931325e-01+0.04806558j\n",
      "   9.41669792e-02-0.12699702j -5.51777482e-02+0.04121342j\n",
      "  -2.79132035e-02-0.0377457j  -7.12336302e-02+0.19680618j\n",
      "   1.55430704e-01+0.21151447j -6.13024309e-02-0.00670568j\n",
      "  -2.13813365e-01-0.21285449j  1.80549379e-02-0.19969177j\n",
      "  -2.12394312e-01+0.22201136j -2.20009102e-03-0.19393186j\n",
      "  -8.41311589e-02-0.10363363j -1.10257238e-01-0.17189519j\n",
      "  -3.26378755e-02+0.17536011j  1.47357330e-01+0.03221656j\n",
      "   1.81355327e-01+0.07341398j -7.01168925e-03-0.1262497j\n",
      "  -3.29884328e-02-0.12616497j -1.23088270e-01-0.1581343j ]\n",
      " [-1.59547314e-01-0.08736328j -9.33228582e-02+0.11385657j\n",
      "   7.69835263e-02-0.20301157j -1.15203626e-01-0.13372032j\n",
      "  -2.40413379e-03+0.07077508j -5.67462249e-03+0.02654266j\n",
      "   8.84105936e-02+0.18939142j  1.69164285e-01-0.09513399j\n",
      "  -5.85726574e-02-0.20285305j -1.31238863e-01-0.06540167j\n",
      "   1.10966563e-01-0.20570038j -5.15428707e-02+0.00545625j\n",
      "  -2.01027125e-01-0.08455371j  8.57928023e-02+0.08107901j\n",
      "   2.97871009e-02-0.14488664j  1.17333002e-01+0.03169657j\n",
      "  -8.82101357e-02+0.17089553j  2.12093249e-01+0.03784636j\n",
      "  -2.23799180e-02-0.09612957j -1.31117642e-01-0.06755712j\n",
      "   1.04489431e-01-0.1420237j   1.07088603e-01+0.1758849j\n",
      "   2.07540035e-01-0.02361971j  1.60699353e-01-0.01431074j\n",
      "  -1.63375035e-01+0.10943428j -1.80270121e-01+0.17535397j\n",
      "   8.49633664e-02+0.1928082j  -2.14304343e-01+0.02452769j\n",
      "   1.16872661e-01-0.1245556j   6.98744366e-03-0.11406438j\n",
      "   2.01524541e-01-0.23138398j -2.21937466e-02+0.06197064j\n",
      "  -1.91458911e-01+0.06118874j -3.37767936e-02+0.20644121j\n",
      "   7.08802566e-02-0.1807861j   1.96094185e-01+0.17924796j\n",
      "  -1.55380085e-01+0.1408984j   1.87675089e-01-0.18256578j\n",
      "   1.74281478e-01-0.04263245j  1.58800200e-01-0.08908036j\n",
      "   4.74220375e-03-0.03286409j -1.43819496e-01+0.1086747j\n",
      "   1.02543280e-01-0.13939656j -1.03660170e-02-0.11934722j\n",
      "  -1.62349120e-01-0.19581237j -1.63631693e-01+0.22978753j\n",
      "  -1.15830861e-01+0.01890176j -1.51133845e-02+0.07068401j\n",
      "   4.33840156e-02+0.0536417j   2.12360159e-01+0.17216057j]\n",
      " [-3.44919227e-02+0.11684843j -4.84799407e-02+0.10408836j\n",
      "   8.53144377e-03+0.17878704j  2.11442187e-01-0.20259172j\n",
      "  -2.05741480e-01+0.17878097j  1.14901364e-01+0.03025833j\n",
      "   2.43227594e-02-0.10315417j  8.20328966e-02-0.01425973j\n",
      "  -4.72420417e-02-0.14993584j  1.99329823e-01+0.00850074j\n",
      "   4.07236032e-02-0.05814984j  1.15472034e-01+0.08490693j\n",
      "  -1.60415590e-01-0.0297807j  -1.42470345e-01-0.09378922j\n",
      "  -1.56921849e-01+0.01627452j -1.89025849e-01-0.04490002j\n",
      "  -1.56271737e-02+0.12580109j -8.61753672e-02-0.14590995j\n",
      "  -2.81884074e-02-0.20234275j -4.75965776e-02+0.03638788j\n",
      "   9.77001265e-02-0.05742905j -5.89832738e-02-0.02724581j\n",
      "   1.09785192e-01+0.08502904j -3.34972814e-02-0.01504366j\n",
      "  -3.82847432e-03-0.0179548j   2.01709241e-01+0.17406836j\n",
      "  -9.62615833e-02-0.20275754j  2.18192548e-01+0.17335449j\n",
      "  -1.33197919e-01-0.08946162j  8.92975628e-02-0.01760236j\n",
      "  -5.13310730e-02+0.02057447j  1.50866464e-01-0.12793224j\n",
      "   1.81065828e-01-0.01667701j  6.94037676e-02-0.12558098j\n",
      "  -1.91417217e-01+0.22004603j  1.77633882e-01-0.0920268j\n",
      "  -1.50325373e-02-0.06561126j  5.13798818e-02+0.04912287j\n",
      "   1.02193095e-01-0.08608042j  1.64021119e-01+0.20468897j\n",
      "   4.38555293e-02+0.14100161j -8.00767019e-02-0.14782551j\n",
      "   2.05719024e-02-0.09559828j -3.91422473e-02+0.06843973j\n",
      "  -1.14157379e-01+0.18399276j -1.67196188e-02-0.12512086j\n",
      "   5.36403619e-02-0.09872359j  1.81556806e-01-0.08723319j\n",
      "  -6.37545139e-02+0.19343427j -1.97540537e-01+0.19992314j]\n",
      " [-1.98233634e-01-0.13735358j -1.30600959e-01+0.18802099j\n",
      "   2.90410817e-02+0.19271667j  1.24513917e-01-0.13924347j\n",
      "   5.92651358e-03-0.05024661j  1.39212608e-01-0.17365183j\n",
      "   1.30222468e-02+0.08924384j  6.18408099e-02-0.08240119j\n",
      "   1.02987453e-01-0.01726019j  1.40311480e-01-0.12080481j\n",
      "  -4.49005142e-03+0.15639469j  6.69491105e-03-0.1799469j\n",
      "   3.88511866e-02-0.21109141j -1.00796364e-01+0.19711697j\n",
      "  -1.81212872e-01+0.04079729j  5.98903224e-02-0.01841495j\n",
      "  -1.99601114e-01-0.03928902j  1.22283459e-01+0.0353647j\n",
      "  -4.03224379e-02+0.12202605j  1.79948196e-01-0.11381207j\n",
      "   1.51427075e-01-0.10731175j  6.09157570e-02+0.1592465j\n",
      "  -2.21084237e-01+0.09078348j  1.67469159e-01-0.19031282j\n",
      "   2.86380984e-02-0.0511317j  -1.15750268e-01-0.05602263j\n",
      "   2.06036419e-01-0.08757885j -1.04811296e-01-0.11368232j\n",
      "  -4.25762450e-03-0.03229907j  3.41895744e-02-0.18482228j\n",
      "   8.47942457e-02+0.06739561j  2.17312679e-01+0.05981063j\n",
      "  -1.75322413e-01+0.20353317j -2.04737827e-01+0.00085553j\n",
      "  -1.46002740e-01-0.0170035j   1.13107041e-01+0.20135236j\n",
      "   1.06527790e-01+0.03093804j  7.17108557e-03-0.11727748j\n",
      "   1.31711811e-01+0.0243411j  -9.41492394e-02+0.07042412j\n",
      "  -4.17569987e-02-0.04810633j -2.14976639e-01+0.12620197j\n",
      "   2.24228188e-01-0.20396578j -1.72919229e-01+0.15687865j\n",
      "  -1.62478894e-01-0.20698373j  2.82676555e-02+0.18857668j\n",
      "  -7.00193122e-02+0.06732694j  1.19023181e-01+0.05334447j\n",
      "  -4.04632613e-02+0.02341723j -2.00368091e-02+0.10260801j]\n",
      " [-1.60046294e-01+0.09578511j  1.32607415e-01-0.01463742j\n",
      "  -4.80407961e-02+0.15982419j  1.44788504e-01+0.08107184j\n",
      "  -2.25432560e-01-0.11690596j -6.72788918e-02+0.05341732j\n",
      "   1.62538752e-01-0.04823482j  5.88826612e-02-0.06673717j\n",
      "  -1.41271651e-01+0.0491998j  -7.74764791e-02+0.01575362j\n",
      "   2.11328283e-01+0.1005271j  -1.93796456e-01+0.06041378j\n",
      "   1.77811652e-01-0.08137852j -1.01064958e-01-0.064177j\n",
      "   1.63800195e-02+0.10018165j -3.02659366e-02-0.16154218j\n",
      "  -3.52150686e-02+0.00261635j -5.79923466e-02-0.09250898j\n",
      "   1.79627404e-01+0.13022152j -2.06985995e-01+0.12492858j\n",
      "   1.61239415e-01+0.14397748j -6.64145052e-02+0.20986214j\n",
      "   1.61181584e-01+0.08433779j -1.50785252e-01-0.04419123j\n",
      "   7.04053640e-02-0.05656571j -1.03955209e-01+0.12460744j\n",
      "  -1.02081165e-01-0.21526791j  9.05289799e-02+0.10173333j\n",
      "  -2.12959349e-01-0.01460254j -2.02091396e-01+0.17068917j\n",
      "  -6.24190979e-02+0.16372159j -1.06285647e-01-0.11378127j\n",
      "   2.19269842e-01+0.14818513j  2.16731191e-01+0.11429181j\n",
      "   9.44582522e-02+0.15506351j  8.22918266e-02-0.01966625j\n",
      "   7.28042796e-02-0.00914339j -5.26721701e-02+0.03057375j\n",
      "   1.92766875e-01-0.1215259j   1.15456954e-01+0.1574412j\n",
      "  -1.91783503e-01-0.01390491j  1.35551155e-01+0.19073144j\n",
      "  -1.59765109e-01-0.1371692j   1.20475054e-01+0.07879572j\n",
      "   1.40137345e-01-0.15482444j  2.09059775e-01+0.16258858j\n",
      "   5.75207844e-02-0.11760681j  1.73952699e-01-0.04671242j\n",
      "  -7.83304647e-02-0.07118265j  4.03329134e-02-0.04282807j]\n",
      " [ 2.02409551e-01-0.19942358j  2.09765971e-01-0.08726892j\n",
      "  -1.34893462e-01+0.00716495j  8.95061195e-02+0.10942377j\n",
      "  -1.18101135e-01-0.03200476j  4.22939882e-02+0.18860817j\n",
      "  -2.65359171e-02+0.13019897j -1.51029423e-01+0.14693472j\n",
      "  -1.33332804e-01-0.11176573j  1.99656352e-01-0.12177697j\n",
      "  -5.55586703e-02+0.06685555j -8.17063376e-02-0.02754146j\n",
      "   1.76653564e-01-0.02687891j -2.30050609e-02-0.15750584j\n",
      "  -4.09226492e-03+0.18429643j  8.36471394e-02+0.20942503j\n",
      "  -1.74126402e-01+0.20020902j -9.81943607e-02-0.00899324j\n",
      "   9.67054889e-02+0.22273424j  1.73731297e-01-0.08202436j\n",
      "  -1.47581771e-01+0.1956299j  -1.64628163e-01-0.15591866j\n",
      "   1.62281275e-01-0.05521828j -6.90282956e-02+0.21148705j\n",
      "   8.96741822e-02-0.07469359j -2.15884253e-01-0.15614772j\n",
      "  -1.57257468e-01+0.12565458j -1.64028704e-01+0.01635643j\n",
      "   2.02805996e-01-0.12014198j  2.23183632e-02+0.20787066j\n",
      "   2.12485775e-01-0.00075156j -5.21506183e-02-0.01161283j\n",
      "   4.74094413e-02-0.09808484j -7.94044137e-03-0.00286923j\n",
      "   1.07308097e-01+0.15225618j  2.67158095e-02+0.01062988j\n",
      "  -1.08139515e-02-0.02117406j -1.74747348e-01-0.02412328j\n",
      "   5.56810014e-02-0.06066127j  1.59041330e-01+0.0079761j\n",
      "  -9.38676968e-02+0.12005031j -1.60137430e-01+0.04280175j\n",
      "  -3.05127837e-02-0.08449803j -1.98787093e-01+0.12347751j\n",
      "  -4.73482870e-02+0.04439518j  1.12979747e-01-0.03536348j\n",
      "  -2.29917616e-02+0.1387348j   6.50137588e-02+0.02940364j\n",
      "  -1.25801519e-01-0.09359844j -1.57640219e-01-0.19883743j]\n",
      " [ 1.22314908e-01+0.00660555j -1.50151297e-01-0.03196434j\n",
      "  -2.20395222e-01-0.19344257j -1.95370093e-01+0.02430883j\n",
      "   1.86600536e-01-0.03253904j -1.02321180e-02-0.03448638j\n",
      "   4.42997916e-05-0.18004388j  3.09672784e-02+0.08668522j\n",
      "   1.73333019e-01+0.10245295j  1.96955755e-01+0.08711663j\n",
      "  -9.68280733e-02-0.15456815j  2.40375884e-02-0.20629844j\n",
      "  -1.81853384e-01-0.17502497j  1.37532905e-01+0.01892959j\n",
      "  -1.13349222e-01+0.07784262j  1.28535032e-01+0.18675663j\n",
      "   1.49593323e-01-0.16530222j -1.03868283e-01+0.01957659j\n",
      "  -4.35228497e-02+0.00797607j  1.25232786e-01-0.20795499j\n",
      "   1.23509608e-01-0.2151964j   4.36391570e-02+0.17876656j\n",
      "   7.94310942e-02+0.1861175j  -1.74199983e-01+0.03346617j\n",
      "  -8.43721256e-02+0.20463233j  3.37039144e-03+0.09307709j\n",
      "  -1.92701951e-01+0.06037905j  2.02548310e-01+0.12350858j\n",
      "  -1.78833380e-01-0.16932794j  5.12063056e-02-0.00698972j\n",
      "   1.39223505e-02+0.21595718j -8.47298950e-02-0.19291534j\n",
      "   2.11600751e-01+0.20848732j -9.73239169e-03-0.1997522j\n",
      "   2.14812279e-01-0.16640879j -2.74849907e-02+0.16185962j\n",
      "   1.87285542e-01+0.01893509j -5.52171543e-02-0.18137729j\n",
      "   1.13987952e-01+0.03962643j  1.76989749e-01+0.13393609j\n",
      "  -5.52551150e-02-0.07288251j  1.19789764e-01+0.05870157j\n",
      "  -1.53588176e-01-0.14378197j  2.08669066e-01+0.18351948j\n",
      "   1.31903991e-01+0.05674714j  2.46158964e-03-0.08310577j\n",
      "   2.96416655e-02+0.16013034j -1.85278594e-01+0.16972403j\n",
      "  -3.66749316e-02+0.16270344j -1.86367542e-01-0.12850277j]]>\n",
      "<Variable path=decoder/encoder/bias, shape=(50,), dtype=complex64, value=[ 0.00032493+2.8163823e-03j  0.00203855-1.0911264e-03j\n",
      " -0.00061817+2.9905639e-03j  0.00175791-9.0540368e-03j\n",
      " -0.0010016 +2.3161991e-05j -0.00020347-3.8641351e-04j\n",
      " -0.00094294-3.2522168e-03j -0.00108989+2.4469311e-03j\n",
      "  0.00188106-1.7140270e-03j  0.00107083-2.8283242e-03j\n",
      " -0.00321693-2.5218488e-03j  0.00259424-9.3991985e-04j\n",
      " -0.00111846-6.7706202e-04j  0.00134557+3.0471294e-03j\n",
      "  0.00248659+7.1003912e-03j -0.0004183 -2.0091352e-03j\n",
      " -0.00027725-2.0918567e-03j -0.00389626-3.1049687e-03j\n",
      " -0.00125863+7.7558160e-03j  0.0034471 -7.1762097e-03j\n",
      " -0.00255072-1.3727602e-03j -0.00038551+2.3319155e-03j\n",
      "  0.00260013+4.6899370e-03j  0.0011928 -3.5679720e-03j\n",
      "  0.00043687+3.1845209e-03j  0.00109807+3.6631927e-03j\n",
      "  0.0027524 +1.5332482e-03j -0.00088502+7.0184957e-05j\n",
      "  0.00172882-5.6899426e-04j  0.00763465-3.9376244e-03j\n",
      " -0.00208817-8.1996797e-03j -0.0010829 -9.6672087e-04j\n",
      " -0.00075403+3.4188267e-03j  0.00273582-7.3120673e-03j\n",
      "  0.0013676 -9.5592998e-04j  0.00094312+2.7108672e-03j\n",
      "  0.00087241-1.3132719e-03j  0.00219133+3.0106767e-03j\n",
      " -0.00646095+4.0716897e-03j -0.00760281+4.0925089e-03j\n",
      " -0.00072228-1.5278599e-04j -0.00473752-3.0911158e-04j\n",
      "  0.00130781+1.8254071e-03j -0.00591236+9.5994258e-03j\n",
      " -0.00612941+4.8565660e-03j  0.00437637+2.7531411e-03j\n",
      "  0.003215  -1.1449910e-03j -0.00052966-1.2244291e-03j\n",
      " -0.00209911+3.9553810e-03j  0.00220306+6.5825129e-04j]>\n",
      "<Variable path=encoder/encoder/W1, shape=(50, 10), dtype=complex64, value=[[ 0.14976843-0.13401106j  0.00586661+0.15840283j -0.07211945-0.06831563j\n",
      "   0.03461652-0.10183228j  0.14876859+0.21281575j -0.13206269-0.11557066j\n",
      "   0.16899264+0.00143043j  0.12509868-0.07961082j -0.11466996-0.18589199j\n",
      "   0.17419319-0.14462067j]\n",
      " [ 0.10763812+0.09286908j -0.186621  +0.16205533j -0.17609924+0.10256059j\n",
      "   0.01690742-0.04365001j -0.03023009-0.09649667j  0.14933488+0.10040737j\n",
      "   0.15839334+0.17453392j -0.13884866+0.1345646j   0.110403  +0.02822617j\n",
      "   0.04740455+0.15432972j]\n",
      " [ 0.14653474+0.18043186j  0.16615584-0.0960987j  -0.15242982-0.19838417j\n",
      "  -0.03303581-0.14052567j -0.23337267+0.19554098j -0.19385481+0.02190727j\n",
      "  -0.14387736-0.04397188j  0.07199734-0.0970398j   0.17070562+0.16938941j\n",
      "  -0.074242  -0.04357914j]\n",
      " [-0.02760599-0.03972184j -0.18322994+0.11859959j  0.16108987-0.17718852j\n",
      "  -0.1594265 -0.00792464j -0.02419878-0.20747526j -0.01983008+0.0200574j\n",
      "  -0.14614369+0.17552744j -0.16805096+0.01085349j -0.10210984+0.10887627j\n",
      "  -0.08809003-0.00939011j]\n",
      " [ 0.13470604-0.08044655j  0.17167737+0.17148954j  0.00806272+0.07995073j\n",
      "   0.13610266+0.0840193j   0.15864278+0.00492048j  0.16418941+0.19850059j\n",
      "   0.07404499+0.12584858j -0.16265619-0.19264713j  0.03617066-0.08528089j\n",
      "   0.20822322+0.14894328j]\n",
      " [ 0.16766332-0.06023206j -0.02922887+0.12707058j -0.22039191+0.12208321j\n",
      "   0.19118275-0.20967096j -0.09425998+0.03177091j  0.12477719+0.21763743j\n",
      "  -0.20124398+0.04816625j -0.15204489+0.06258252j -0.15470186+0.09282394j\n",
      "   0.03251602-0.065494j  ]\n",
      " [-0.1949666 -0.12706816j  0.15089063+0.04227071j -0.13761653+0.18070364j\n",
      "   0.01458734+0.1480028j   0.1482901 +0.13755198j -0.1833578 +0.15760997j\n",
      "   0.12113512-0.16712269j  0.06114796-0.11328579j -0.09249619+0.22284062j\n",
      "   0.16947922-0.19876587j]\n",
      " [ 0.10157034-0.0103035j  -0.17432788+0.17057987j  0.10500979-0.06072223j\n",
      "  -0.03212111-0.05802477j  0.0450456 +0.20421752j -0.01914186+0.11873697j\n",
      "  -0.0723368 -0.15993553j -0.20134187-0.22386551j -0.00461862-0.19128616j\n",
      "   0.22450428-0.10313252j]\n",
      " [ 0.12770353-0.18710384j -0.16823886+0.01617031j -0.00316154-0.20449433j\n",
      "   0.10145705+0.08057252j  0.16112596-0.16045348j -0.21943195-0.06834622j\n",
      "   0.01152954-0.0259977j  -0.06252222-0.1434492j   0.12550211+0.05641762j\n",
      "   0.1892206 +0.08760811j]\n",
      " [ 0.05537037-0.0285911j   0.16594659-0.14972301j -0.21460898+0.20419647j\n",
      "  -0.16611128+0.19126979j  0.03174454-0.05341407j  0.10303649-0.0365103j\n",
      "   0.18877755-0.07375626j  0.13282949+0.02375307j -0.08396179-0.12881032j\n",
      "   0.22311316+0.13732637j]\n",
      " [ 0.18286733-0.21506758j -0.18692683+0.14061528j -0.02742427-0.16815211j\n",
      "   0.15934223-0.06019449j -0.05721168+0.03527236j -0.14283021-0.21892561j\n",
      "  -0.00161434+0.18221948j  0.0087021 +0.01471209j -0.2192775 +0.20330743j\n",
      "   0.2040104 +0.01248536j]\n",
      " [-0.11208159-0.21830507j -0.17414726-0.12886642j  0.08792892-0.07189855j\n",
      "  -0.20605893-0.12010272j -0.0015554 -0.15695041j -0.05206835+0.11701631j\n",
      "   0.02022281+0.06842121j  0.13092768-0.03284017j  0.02133052+0.21033263j\n",
      "   0.10713214-0.06120948j]\n",
      " [ 0.0226155 -0.09420702j  0.00955365+0.07729152j -0.17636673+0.1702319j\n",
      "   0.02116616-0.19521335j  0.19621421+0.08474074j  0.1698192 -0.12252682j\n",
      "   0.12551709+0.21713217j  0.03717863-0.21014157j -0.14034861-0.16147602j\n",
      "  -0.14697878-0.02345923j]\n",
      " [-0.03452824+0.07126725j -0.07291698+0.20820083j -0.19943653+0.12649819j\n",
      "  -0.06179184-0.22537021j  0.08295478-0.09723069j  0.02504474+0.00592934j\n",
      "  -0.12021572+0.20944183j  0.09889925-0.02028435j -0.04810787-0.08076535j\n",
      "   0.20244738-0.14186887j]\n",
      " [ 0.22536181-0.06998641j -0.04413   +0.10333712j  0.09427643-0.10468357j\n",
      "   0.23002131+0.21504949j  0.10516731+0.00546433j -0.05694738+0.16099586j\n",
      "  -0.17742333-0.1633668j  -0.05157836+0.01200614j  0.03480603+0.15359484j\n",
      "   0.12157041+0.01723737j]\n",
      " [ 0.16418655+0.2028103j   0.1597787 +0.0440104j   0.10478535-0.04284215j\n",
      "  -0.15110308-0.11010347j -0.0399279 -0.15560032j -0.18337962+0.13910218j\n",
      "  -0.14227836+0.11788153j  0.04390277-0.19202077j  0.19236988+0.04212094j\n",
      "   0.19996993+0.18983197j]\n",
      " [-0.16152093+0.02014063j -0.07585277-0.05314162j  0.03137115+0.11928706j\n",
      "  -0.13931827+0.22141407j  0.22784197+0.17955118j  0.19188863+0.11994059j\n",
      "   0.05456737-0.0230422j  -0.05773786+0.1415526j  -0.13651994-0.07392913j\n",
      "   0.01712746+0.14757259j]\n",
      " [ 0.04950676-0.19910994j -0.01773199+0.20228305j  0.01593152-0.08679712j\n",
      "  -0.17145708+0.02275943j  0.076828  +0.08320969j -0.2002671 -0.219156j\n",
      "  -0.10300827-0.11076897j  0.18836568+0.1881556j   0.13148461-0.19219117j\n",
      "  -0.18134129+0.05538473j]\n",
      " [ 0.07487828+0.1369418j  -0.00867455+0.03034653j  0.11589813-0.06925065j\n",
      "  -0.12226568-0.18297566j  0.03123036+0.19377117j  0.08517972-0.1835625j\n",
      "   0.12454926-0.14217071j -0.11828886-0.11106228j  0.15081482-0.01769396j\n",
      "   0.18990539-0.09735708j]\n",
      " [-0.11045802-0.01783348j -0.10938144+0.10186787j -0.0677748 -0.10701764j\n",
      "  -0.22743951-0.04936224j -0.07349586+0.10810491j  0.00071992+0.1301755j\n",
      "   0.18070154+0.09173743j  0.19537093-0.030327j    0.14351584+0.06148549j\n",
      "   0.1117697 +0.09146895j]\n",
      " [-0.19459487+0.1935039j   0.18835996-0.20312655j  0.08712775-0.21842074j\n",
      "   0.11198457-0.12203797j -0.08774793-0.10994714j -0.11597568+0.15103164j\n",
      "   0.18101706-0.02104644j  0.07540655-0.10295581j  0.1983567 -0.00685738j\n",
      "   0.16561282+0.02330743j]\n",
      " [-0.12028795+0.20137988j -0.11155716-0.11876108j  0.16374864+0.12002911j\n",
      "  -0.22702649+0.2277827j   0.03727232+0.07113352j  0.18801306-0.1663781j\n",
      "  -0.10852093-0.05358476j -0.1868966 +0.1632143j  -0.235202  +0.17926662j\n",
      "   0.20535831-0.15194955j]\n",
      " [ 0.06799581-0.09977673j  0.11750603-0.01561566j  0.00361008+0.16214068j\n",
      "   0.0401398 -0.21980698j -0.12841849+0.14255428j -0.01385566-0.21077447j\n",
      "   0.18110952-0.11369763j -0.1597083 +0.20301202j -0.15263824+0.09576362j\n",
      "  -0.16616993+0.11668932j]\n",
      " [-0.18830349+0.14759779j  0.04379094+0.1930968j   0.21897596-0.03830398j\n",
      "  -0.2141094 -0.17590241j  0.07111263+0.05382206j  0.10460462-0.12891695j\n",
      "   0.10133768+0.20852183j -0.10137662+0.03920895j -0.00605803-0.21315414j\n",
      "   0.0177293 +0.10834875j]\n",
      " [ 0.06937196+0.20222853j  0.25662324-0.14245038j -0.07776621+0.1556831j\n",
      "  -0.10320967+0.05705664j  0.08081826-0.03497127j -0.04923803+0.0461827j\n",
      "  -0.18963614+0.11723424j  0.12953474+0.00877339j -0.06324353+0.1673003j\n",
      "   0.12158959-0.00984446j]\n",
      " [ 0.07710192+0.19118896j  0.09824116-0.04158574j  0.22248259+0.13357952j\n",
      "   0.21688555-0.11312895j -0.19038773+0.12159564j  0.0631352 +0.04450389j\n",
      "  -0.05442083+0.09968404j -0.02892858-0.0146284j  -0.13349523-0.20665176j\n",
      "  -0.04995848+0.22555715j]\n",
      " [-0.13896519-0.05800368j -0.05893768-0.01064317j -0.10189876+0.05511103j\n",
      "  -0.05055417-0.20231077j  0.05762152-0.06208497j  0.09600166-0.1156116j\n",
      "   0.2108263 +0.18013813j  0.21303141+0.06774624j  0.08530331-0.12759805j\n",
      "   0.03568788-0.01927686j]\n",
      " [-0.04297381-0.09439287j -0.00217677-0.24134941j -0.17846523-0.02384742j\n",
      "   0.04394333-0.08826741j  0.157741  -0.06940194j  0.19827615+0.17880559j\n",
      "  -0.14592262+0.15649116j  0.13208067-0.23568721j -0.21433316-0.07158881j\n",
      "   0.24030696+0.10718399j]\n",
      " [-0.06035622-0.19984895j -0.02356737+0.18735085j -0.13155465+0.19127163j\n",
      "   0.20342162-0.12815124j  0.01314707+0.11776255j  0.01149409+0.1993847j\n",
      "  -0.20941576-0.10859861j -0.12754677-0.00117346j  0.17576185+0.21572337j\n",
      "  -0.05305396-0.1480755j ]\n",
      " [-0.13533987-0.20953797j -0.14156368+0.14370675j  0.15757519+0.1750154j\n",
      "   0.08407412-0.13518621j -0.01405341+0.02871412j -0.02661415+0.0419435j\n",
      "   0.04662012+0.07579112j -0.1916627 +0.21235164j  0.18665974+0.10166384j\n",
      "   0.0312876 +0.14429796j]\n",
      " [-0.13345185-0.05374441j -0.01691045+0.09157328j -0.10747071+0.17736931j\n",
      "   0.10408373+0.1965049j  -0.07175225+0.12309984j  0.11919901-0.09146383j\n",
      "   0.05476235-0.18415205j  0.14583634-0.21732843j  0.13254964+0.13812387j\n",
      "  -0.06428714+0.19836149j]\n",
      " [-0.03086337+0.2165532j   0.12811764+0.15247321j  0.23125562-0.02586789j\n",
      "   0.1285801 -0.0270442j   0.06688954-0.2133539j  -0.20436971-0.12086205j\n",
      "  -0.007656  +0.19625509j -0.18366857+0.04084742j  0.11026407+0.04271036j\n",
      "   0.04634503-0.11150396j]\n",
      " [ 0.14936869+0.18783827j  0.12516999-0.20933902j -0.17206098-0.1193239j\n",
      "  -0.21875165-0.01543753j  0.119036  +0.109237j    0.2291495 +0.13621813j\n",
      "   0.03368397+0.28290763j -0.01229164-0.15077037j -0.01616086-0.21582466j\n",
      "  -0.11009077+0.07663081j]\n",
      " [-0.09832876-0.07201279j -0.14663619+0.07737775j -0.11205103-0.14240262j\n",
      "  -0.2018631 -0.05478176j  0.10057384-0.12062497j  0.03677081-0.0597746j\n",
      "  -0.01326218+0.00894399j  0.0608197 -0.05477875j  0.15978271+0.17962848j\n",
      "   0.02848905+0.09091822j]\n",
      " [-0.23184255-0.024707j   -0.17311661-0.02767002j  0.12429443-0.1859207j\n",
      "  -0.10430551-0.00343976j  0.11007502+0.10288483j  0.1443856 -0.03605429j\n",
      "   0.09836426+0.07716155j  0.07798988-0.01059511j  0.15199059-0.1871316j\n",
      "  -0.13608226-0.00724823j]\n",
      " [-0.16666478+0.08662368j -0.04809587+0.1015243j  -0.04909513-0.05183787j\n",
      "  -0.01404785+0.06895202j -0.1271713 +0.20860934j -0.20325592+0.05132785j\n",
      "  -0.11896263-0.13163008j -0.13297345+0.03120709j -0.05787197+0.0201133j\n",
      "   0.21579845-0.09330612j]\n",
      " [-0.0425453 +0.14893475j  0.09998828+0.07134598j  0.09262028-0.0753569j\n",
      "  -0.02831166+0.05466428j  0.04365279-0.0967025j  -0.16935267+0.08772659j\n",
      "  -0.10491397-0.23976995j -0.1704417 -0.15062365j -0.09156738+0.02408224j\n",
      "   0.17568956-0.18005219j]\n",
      " [-0.18450284+0.12361332j -0.10381442+0.14968044j  0.00362804-0.10934626j\n",
      "  -0.05809173+0.01759665j -0.06727536+0.0082431j  -0.00690229+0.21059941j\n",
      "  -0.10607295+0.01205525j -0.18663591+0.16851059j -0.23067938+0.1795537j\n",
      "   0.09433337+0.15041547j]\n",
      " [ 0.02314482-0.13618393j  0.14877664+0.17630015j  0.19678986+0.01273584j\n",
      "  -0.02873567-0.21906295j  0.20668183-0.09763253j -0.07673147+0.1913989j\n",
      "  -0.07296185+0.13761373j  0.23417728-0.10767344j -0.01617913+0.02057038j\n",
      "   0.12342422-0.21529244j]\n",
      " [ 0.05397945-0.15794069j -0.08396295+0.04170661j  0.10962957-0.11106781j\n",
      "   0.18758407+0.15660372j -0.05079758-0.20486082j -0.02904684+0.00911082j\n",
      "  -0.01240571-0.08356119j  0.06745341-0.1755588j   0.08315457-0.17605615j\n",
      "   0.0398374 -0.01793899j]\n",
      " [-0.06803218-0.02068245j -0.03880105+0.10795271j -0.0293799 -0.04882064j\n",
      "  -0.15116616+0.15454347j  0.205935  +0.1448909j  -0.08857124-0.11822224j\n",
      "   0.0960529 -0.10918427j  0.03742353-0.13826501j  0.19531494-0.13637456j\n",
      "  -0.06272499-0.10360879j]\n",
      " [ 0.12195632+0.13241561j -0.17206398-0.20893714j -0.01890043-0.11744138j\n",
      "   0.20709634+0.10004547j  0.06996353-0.1775899j  -0.12860008+0.2164371j\n",
      "   0.03405356+0.0789609j  -0.14795926+0.06533451j  0.06918955-0.19496132j\n",
      "   0.1717002 -0.13574867j]\n",
      " [-0.19640991+0.04925521j -0.10217353+0.06855266j  0.15593953+0.1264324j\n",
      "   0.0268776 -0.1144276j   0.16588618-0.17209981j  0.10902142-0.19307901j\n",
      "   0.03867438+0.17604786j -0.01723052-0.20611712j -0.20039588+0.08099535j\n",
      "   0.18848167+0.21328901j]\n",
      " [-0.14125319-0.08359501j -0.20069811-0.18599054j -0.2232262 -0.22609942j\n",
      "   0.07638662+0.12532964j  0.22496605-0.21228491j  0.20592186+0.1416194j\n",
      "   0.18415867-0.01186636j -0.11564886-0.06968825j  0.12680703-0.02036524j\n",
      "  -0.15461878+0.17584854j]\n",
      " [-0.00052894-0.21536425j -0.1863997 -0.13970377j  0.0727437 +0.12377391j\n",
      "  -0.22320424-0.12563711j -0.07989459+0.0224421j   0.11005657-0.14036022j\n",
      "  -0.1117753 -0.09425624j  0.00099919+0.01781984j -0.09139466-0.00871693j\n",
      "  -0.21974301-0.06590953j]\n",
      " [ 0.0537528 +0.07892736j -0.02941748+0.18509303j  0.00754217+0.04796855j\n",
      "   0.04366918-0.15432945j -0.19104986-0.13721615j  0.01343545+0.19561397j\n",
      "   0.13601461-0.20737156j -0.17600895+0.13758342j -0.18540388+0.00969819j\n",
      "  -0.08929112+0.14732333j]\n",
      " [-0.10552536-0.21094483j -0.21170607-0.11774701j  0.21524647-0.13853972j\n",
      "  -0.19291268-0.04621882j  0.01231811+0.10201328j -0.09289899-0.00537273j\n",
      "   0.04705326+0.22572657j -0.16045664+0.04426645j  0.01040747-0.22385623j\n",
      "  -0.03370273-0.03128489j]\n",
      " [-0.19059677-0.01375788j  0.15789719+0.02351872j  0.1702677 -0.12579918j\n",
      "  -0.07832167-0.18389598j  0.01823853+0.00579386j  0.2213072 +0.03477904j\n",
      "   0.18010834+0.18094029j -0.20373257+0.04836784j -0.13165349-0.17760843j\n",
      "   0.02527637-0.06311786j]\n",
      " [ 0.04811423-0.05680401j  0.21177402+0.17114876j -0.15924163+0.01890073j\n",
      "   0.05427876+0.07138099j  0.20539711+0.06915636j -0.14178865-0.02382907j\n",
      "   0.14313917-0.11923325j -0.21213607+0.13313444j -0.05293142-0.06710452j\n",
      "   0.05535208+0.02038151j]\n",
      " [ 0.25980696+0.11668275j  0.09197356+0.05295562j  0.05110148+0.00206822j\n",
      "  -0.1527    +0.08587234j -0.2151088 -0.04215302j  0.17357972-0.04585305j\n",
      "   0.05246211+0.11674685j -0.07536776+0.19187805j  0.14482827+0.12395471j\n",
      "  -0.19593506+0.16881084j]]>\n",
      "<Variable path=encoder/encoder/W2, shape=(50, 10), dtype=complex64, value=[[-1.22953944e-01-1.48422822e-01j -1.07148007e-01+2.52133366e-02j\n",
      "  -7.36967921e-02-2.22594477e-02j  1.05096124e-01-8.97783861e-02j\n",
      "  -1.22331113e-01-1.09001733e-01j -1.84902459e-01+2.04640374e-01j\n",
      "  -1.31518608e-02+2.67245710e-01j -3.20447125e-02+4.29488458e-02j\n",
      "   1.73521906e-01-2.95945667e-02j -1.41001388e-01+8.20962861e-02j]\n",
      " [ 1.85764238e-01-2.28413716e-01j  1.09710924e-01-9.76150930e-02j\n",
      "   1.67041555e-01-6.57795817e-02j  1.32076412e-01-2.34992161e-01j\n",
      "   2.53500845e-02-1.23569921e-01j  1.53011847e-02+1.54500023e-01j\n",
      "  -1.51872523e-02-1.84398204e-01j  1.41080603e-01-1.33659884e-01j\n",
      "   7.95531832e-03-7.91954771e-02j  1.82009831e-01-1.72032863e-01j]\n",
      " [-1.93747848e-01-4.14680392e-02j  2.21794844e-01+7.07102865e-02j\n",
      "   2.52041649e-02+1.15080513e-01j  7.75422826e-02-2.03058556e-01j\n",
      "   1.92238957e-01+2.28404373e-01j  2.09136069e-01+1.34133428e-01j\n",
      "  -8.06180686e-02+8.82263854e-02j -1.00128785e-01-1.20534047e-01j\n",
      "  -1.67339578e-01+5.31181917e-02j -1.10634575e-02-7.53319412e-02j]\n",
      " [ 1.28391147e-01+8.53926316e-02j  5.33240139e-02+5.03752381e-02j\n",
      "   1.90332476e-02+2.70728488e-05j  1.28283024e-01+6.12828247e-02j\n",
      "   3.63430157e-02+1.09587364e-01j  2.82616336e-02-2.49402896e-02j\n",
      "  -2.24530742e-01-4.95418310e-02j  2.26129949e-01-8.72725323e-02j\n",
      "   2.94553600e-02+1.25588626e-01j -1.79296378e-02+2.90769450e-02j]\n",
      " [ 1.11878932e-01-2.13984415e-01j -1.43397301e-01+1.99942142e-02j\n",
      "   1.90835461e-01-1.51050106e-01j -1.31643325e-01-1.88771129e-01j\n",
      "  -1.63137272e-01-7.92674944e-02j -1.09694391e-01-1.51808541e-02j\n",
      "  -4.44286950e-02-9.71807986e-02j  1.31701529e-01-9.36589390e-02j\n",
      "  -1.84053794e-01-6.03761291e-03j  6.12830818e-02-1.01793386e-01j]\n",
      " [-1.02605760e-01+8.82602036e-02j  2.55556613e-01-1.66167721e-01j\n",
      "  -7.22012296e-02-1.28630474e-01j -1.32342517e-01+4.86749113e-02j\n",
      "   1.88841149e-02-2.00476155e-01j -1.21645764e-01-2.03700542e-01j\n",
      "   1.00669205e-01-2.07073271e-01j  7.15948343e-02+1.41879991e-01j\n",
      "   1.50964245e-01-2.77148876e-02j  2.05495004e-02+5.15004396e-02j]\n",
      " [ 1.85453922e-01-1.44055575e-01j -2.27777287e-01-1.70340672e-01j\n",
      "   3.65920328e-02+1.79993048e-01j -5.72673678e-02-1.08646490e-01j\n",
      "  -1.60311103e-01-6.32774904e-02j -7.73599371e-02-1.17974533e-02j\n",
      "  -7.38458112e-02+4.66258898e-02j -9.18619782e-02+9.64838117e-02j\n",
      "  -2.28181124e-01+8.62147957e-02j  2.18126774e-01+2.76454221e-02j]\n",
      " [ 5.47904372e-02-2.18586802e-01j  1.67020380e-01-6.97412416e-02j\n",
      "   2.12052967e-02-1.51640594e-01j -1.76271632e-01+1.20485328e-01j\n",
      "  -4.10353020e-03-1.25046924e-01j  1.23786233e-01-2.64946148e-02j\n",
      "   5.96837476e-02+7.65961111e-02j  1.70631960e-01+8.54875743e-02j\n",
      "  -1.99060485e-01-1.96483657e-01j -1.93213057e-02+1.48071066e-01j]\n",
      " [ 1.73238546e-01+3.67358886e-02j -1.10927574e-01+2.02743132e-02j\n",
      "   1.74573317e-01+1.79645598e-01j  2.42950376e-02+5.53844348e-02j\n",
      "  -1.83122847e-02+2.35652588e-02j -1.64407849e-01-1.29580900e-01j\n",
      "   1.93634629e-01-1.07164234e-01j -1.09202452e-01+3.63400839e-02j\n",
      "   1.53499961e-01+1.81050882e-01j  1.76482067e-01+1.49124995e-01j]\n",
      " [-1.00655325e-01-9.93506908e-02j -1.10403381e-01-7.40862936e-02j\n",
      "  -1.05164491e-01+7.45164976e-02j  1.68222278e-01+1.78382382e-01j\n",
      "   9.75525379e-02-8.32710937e-02j -1.82907358e-01+2.63059586e-02j\n",
      "   8.75603929e-02+1.04472076e-03j -2.29117963e-02-1.80291653e-01j\n",
      "  -5.09012714e-02+1.70705244e-02j -8.50090235e-02+1.33541852e-01j]\n",
      " [-2.01690719e-01-8.52960944e-02j  1.88715622e-01-1.30575269e-01j\n",
      "   1.24393195e-01-1.94718257e-01j -3.84303629e-02+8.91278088e-02j\n",
      "  -6.21827617e-02+1.03955224e-01j  1.32503241e-01+7.64281005e-02j\n",
      "  -1.02749139e-01+1.78377822e-01j -1.78185344e-01-1.43137760e-02j\n",
      "  -2.12649345e-01+8.39559138e-02j -1.71963781e-01-2.09708482e-01j]\n",
      " [-1.17587604e-01+5.76157309e-02j -3.26628760e-02-2.94080786e-02j\n",
      "   5.04410341e-02+1.81319088e-01j -1.48105085e-01+1.19331852e-02j\n",
      "   2.09958538e-01-4.59425412e-02j -2.15989143e-01+5.12043806e-03j\n",
      "  -1.90540656e-01+1.97847426e-01j  1.60331592e-01-5.20622954e-02j\n",
      "  -2.57411059e-02+1.35753319e-01j  2.14224845e-01-8.45518187e-02j]\n",
      " [-5.78770356e-04-1.02733232e-01j  6.18562363e-02-2.07772940e-01j\n",
      "  -2.20860869e-01+3.69974924e-03j -1.97395355e-01+1.80261925e-01j\n",
      "   8.83942023e-02+5.74906282e-02j  1.47078469e-01-1.41436800e-01j\n",
      "   6.56545907e-02+3.28401960e-02j -1.72036409e-01-9.08002779e-02j\n",
      "   8.33282620e-02-1.62256762e-01j  1.87728062e-01+7.43293017e-02j]\n",
      " [ 9.45085809e-02+1.09805010e-01j -1.84327774e-02+6.68986738e-02j\n",
      "   4.07550782e-02+4.69258390e-02j -1.93442982e-02-1.71090782e-01j\n",
      "   1.28922015e-01+8.38287845e-02j  5.99883161e-02+9.31531042e-02j\n",
      "   1.73883513e-01-1.19337752e-01j -1.28549021e-02-6.08792640e-02j\n",
      "  -2.03975830e-02+2.92702541e-02j  1.76281661e-01+1.11336522e-01j]\n",
      " [-2.67413501e-02-6.84425756e-02j  8.25572461e-02-4.95367162e-02j\n",
      "   4.56166677e-02+5.31964563e-02j  1.79985687e-01-8.41185357e-03j\n",
      "   8.13131109e-02+1.61135063e-01j -1.62859559e-01+1.35437474e-01j\n",
      "  -1.08148649e-01-2.69926600e-02j -1.39972270e-01-1.07365541e-01j\n",
      "   5.82299419e-02-7.61659965e-02j  1.88224941e-01-1.87524557e-02j]\n",
      " [ 3.14962794e-03+1.17676839e-01j -4.23765332e-02+2.04774901e-01j\n",
      "  -1.15850821e-01+2.10435122e-01j -1.69428289e-02-6.91695809e-02j\n",
      "  -8.97066891e-02-1.01035945e-01j  1.80007964e-01+1.46916866e-01j\n",
      "   1.27542302e-01+2.54159607e-02j -9.98532921e-02-4.47775200e-02j\n",
      "  -2.78036762e-02+1.71082735e-01j  8.70596394e-02+1.23596571e-01j]\n",
      " [ 7.52500221e-02-4.64088023e-02j  2.20930278e-01+1.02447487e-01j\n",
      "   4.41254349e-03-1.65754423e-01j  1.57827184e-01-1.73232108e-01j\n",
      "   8.13054964e-02+1.24726444e-04j  5.72041236e-02+1.47211719e-02j\n",
      "  -6.69085458e-02+7.46639296e-02j  5.81195094e-02+1.21987566e-01j\n",
      "  -1.56984150e-01+1.10893920e-01j  4.38675769e-02-2.70001329e-02j]\n",
      " [ 1.07988946e-01-2.78825462e-02j  1.06542125e-01-1.68254852e-01j\n",
      "  -1.74024582e-01+8.40990432e-03j -1.13710731e-01+1.41795099e-01j\n",
      "  -1.95443556e-01-1.75610915e-01j  6.28041178e-02+1.74502283e-01j\n",
      "   9.53362882e-02+2.12389813e-03j  7.13371336e-02+1.64021552e-01j\n",
      "  -1.90108895e-01+2.13143900e-01j -2.08076108e-02+6.18501455e-02j]\n",
      " [ 1.60276845e-01-1.13721557e-01j -1.21306337e-01-4.02534977e-02j\n",
      "  -1.24879740e-01+1.87190309e-01j  1.18371248e-01+1.52690157e-01j\n",
      "   1.95659205e-01-1.32889777e-01j -1.01105776e-02+5.64394481e-02j\n",
      "   7.69895911e-02+2.76141793e-01j  1.67569980e-01-1.95556819e-01j\n",
      "   1.40773393e-02+2.75331475e-02j  1.98081627e-01-2.66895257e-02j]\n",
      " [-9.95074511e-02-1.41398340e-01j  1.08692355e-01-3.13285738e-02j\n",
      "  -1.45258904e-01+4.46367115e-02j -7.06312582e-02+1.41465008e-01j\n",
      "  -1.40271530e-01-2.86061261e-02j  1.01062670e-01+1.72260731e-01j\n",
      "   1.62978157e-01+9.09902826e-02j  1.66654527e-01-8.53177393e-04j\n",
      "  -7.46187791e-02+2.96741612e-02j  1.07616559e-01-1.68612096e-02j]\n",
      " [-1.03628308e-01+1.12891778e-01j -1.14278793e-01-1.59753393e-02j\n",
      "   1.77832127e-01+1.29065841e-01j  9.78250951e-02+4.92397323e-02j\n",
      "  -2.09905490e-01+1.46202043e-01j  2.05511004e-02-6.75447509e-02j\n",
      "  -8.18397775e-02+2.39543870e-01j  1.71410769e-01-7.10409880e-02j\n",
      "   1.96146265e-01-1.17073558e-01j -1.59361288e-02+1.50453150e-01j]\n",
      " [-1.15852483e-01-1.56392604e-01j -4.82184533e-03+3.27886119e-02j\n",
      "  -1.14654368e-02-1.64366260e-01j  4.58668619e-02-4.37916853e-02j\n",
      "  -1.20612741e-01+1.90702066e-01j  9.25240889e-02+1.93396583e-01j\n",
      "  -1.42615795e-01-2.25459680e-01j  1.40104935e-01+1.01889051e-01j\n",
      "  -1.60308704e-01-4.32418212e-02j  1.34039018e-02+2.13988125e-01j]\n",
      " [ 1.25806913e-01-2.20378358e-02j  9.90195721e-02+1.63545251e-01j\n",
      "  -1.62742436e-01-3.29651088e-02j -6.94993734e-02+1.56534240e-01j\n",
      "  -1.82745114e-01-1.13906421e-01j -2.25670189e-01+3.33879329e-02j\n",
      "   7.20574026e-05+4.96200621e-02j -1.79400057e-01+1.49164513e-01j\n",
      "   1.26015946e-01-1.26161978e-01j  1.16005465e-02-2.18970180e-01j]\n",
      " [ 1.95957869e-01-4.86171618e-02j -1.88059390e-01+1.38396457e-01j\n",
      "   1.93951413e-01+7.54228309e-02j  9.73868966e-02+4.61364388e-02j\n",
      "  -2.45933328e-03-7.52478912e-02j -2.56633293e-02-1.79717422e-01j\n",
      "  -1.98524952e-01-2.17496186e-01j  3.50507386e-02+2.66918205e-02j\n",
      "   3.67100164e-02-5.58703095e-02j  1.13435179e-01-1.75167006e-02j]\n",
      " [-1.77518070e-01-1.32811010e-01j  7.28204474e-02-1.91424236e-01j\n",
      "   4.00265604e-02-3.07901911e-02j -2.06950426e-01-7.61808529e-02j\n",
      "   1.80370882e-01-1.51484590e-02j -5.24237752e-02-1.43200383e-01j\n",
      "  -2.27857724e-01-1.90516356e-02j  9.93487686e-02+1.18908845e-01j\n",
      "  -6.42502978e-02-2.10798189e-01j -6.61731586e-02+2.28775218e-01j]\n",
      " [ 1.02266567e-02+7.91958421e-02j -3.95003520e-03-1.07125178e-01j\n",
      "  -1.54645607e-01+1.51246682e-01j -9.98737216e-02-1.50498971e-02j\n",
      "   1.20450392e-01+2.54821815e-02j -9.93447080e-02-1.49166301e-01j\n",
      "  -1.76854562e-02-2.04733126e-02j  1.99155644e-01+7.30641186e-02j\n",
      "   1.87749997e-01-1.77489966e-01j  1.37581334e-01-7.79555365e-02j]\n",
      " [-1.73426703e-01-5.31499982e-02j  2.63742711e-02-1.27938464e-01j\n",
      "   3.72840976e-03+2.03940943e-01j -5.21354750e-02+6.94024190e-02j\n",
      "   4.02648817e-04-5.80675295e-03j -2.32427064e-02-1.29122943e-01j\n",
      "   1.72228619e-01-1.22853339e-01j  1.02845557e-01-7.90019855e-02j\n",
      "   6.94207177e-02+1.86523795e-03j  2.12032661e-01+1.40489623e-01j]\n",
      " [ 1.09427728e-01+9.32336524e-02j -1.07725546e-01-5.34442365e-02j\n",
      "   3.52055766e-02-5.32903476e-04j  9.39220786e-02+5.05269989e-02j\n",
      "   6.71463311e-02+1.46502361e-01j  3.53895454e-03-1.02146991e-01j\n",
      "   1.76166773e-01-8.62403437e-02j -1.86826400e-02+1.18690416e-01j\n",
      "   2.63968498e-01+9.39311683e-02j -2.13929936e-01+1.83746871e-02j]\n",
      " [ 1.82026997e-01+4.20021499e-03j  2.09387243e-01-1.57433316e-01j\n",
      "   5.21804718e-03-1.23951554e-01j -1.10497713e-01+1.72400940e-02j\n",
      "  -1.17106615e-02+1.84661344e-01j -4.92090732e-02+1.34641185e-01j\n",
      "  -4.98628169e-02+1.50483444e-01j  1.76381275e-01+1.95284322e-01j\n",
      "   7.22312480e-02-3.01768407e-02j -3.46903056e-02+1.59168214e-01j]\n",
      " [ 1.89065441e-01-1.44787535e-01j -1.77327052e-01+3.45319510e-02j\n",
      "   1.29836574e-01-1.83262408e-01j  9.34693888e-02+1.10442303e-01j\n",
      "   6.53394386e-02-2.01144323e-01j  9.51229706e-02-8.90492350e-02j\n",
      "   2.89594512e-02-1.79840118e-01j  2.08154738e-01+4.70399223e-02j\n",
      "  -1.71007961e-01+4.69619930e-02j -1.01106040e-01-2.09891647e-01j]\n",
      " [ 2.12621205e-02-1.12936355e-01j  1.57928169e-01-1.51622012e-01j\n",
      "   5.35254590e-02+7.53005501e-03j -3.40594053e-02-4.26898971e-02j\n",
      "  -1.09791517e-01-1.54912755e-01j  2.18985036e-01-9.07342508e-03j\n",
      "  -8.47595260e-02-2.11590141e-01j  4.13238537e-03+1.41716704e-01j\n",
      "   4.92140390e-02+1.07299984e-01j  3.88973989e-02+4.24966700e-02j]\n",
      " [-8.78417864e-02-8.89585353e-05j  6.03179708e-02+7.01328740e-03j\n",
      "  -1.98392481e-01+1.54515311e-01j  1.58185631e-01+1.16283506e-01j\n",
      "  -7.86245987e-03-4.19434048e-02j  1.76510826e-01+1.51653439e-01j\n",
      "   6.68185903e-03-1.41666993e-01j -2.86612250e-02-4.57480475e-02j\n",
      "   1.02806650e-02-1.15946054e-01j -2.48315018e-02+1.70968279e-01j]\n",
      " [-1.97993368e-02+1.87713038e-02j -8.60178173e-02-5.30264899e-02j\n",
      "  -5.67492060e-02+9.36131775e-02j  3.49542201e-02+3.58875431e-02j\n",
      "   2.71077212e-02-3.41636827e-03j  5.74990881e-05+1.11630850e-01j\n",
      "  -8.05366710e-02+1.93025228e-02j  1.15865298e-01+7.14097098e-02j\n",
      "   3.23879197e-02+8.76402482e-02j  1.00923046e-01+1.60672098e-01j]\n",
      " [-6.19917288e-02+1.15028106e-01j  2.56504148e-01-1.76994100e-01j\n",
      "  -1.19343646e-01-1.32294502e-02j  1.87916160e-01-2.35367000e-01j\n",
      "   4.87140231e-02+9.45523456e-02j -9.53619927e-02+8.68576542e-02j\n",
      "   1.67078912e-01-2.54296958e-01j -5.68761956e-04-4.95224409e-02j\n",
      "  -1.57923460e-01+8.22060928e-02j -8.98855925e-02+5.89226931e-02j]\n",
      " [ 1.66751623e-01-2.55933423e-02j -5.77937178e-02-6.29813075e-02j\n",
      "   1.02277763e-01+1.95529670e-01j  1.43692955e-01-9.73649547e-02j\n",
      "   1.71862513e-01-8.58771130e-02j -3.21183465e-02+1.08273260e-01j\n",
      "  -6.48539960e-02+7.60489777e-02j -2.00485468e-01+6.85422793e-02j\n",
      "   9.67780203e-02-6.62764013e-02j -2.02271670e-01-2.80052610e-02j]\n",
      " [ 2.11417601e-01+6.78688288e-02j  1.48170874e-01-6.99713603e-02j\n",
      "  -1.68036699e-01+1.03343979e-01j -6.94463821e-03+1.65141374e-01j\n",
      "  -1.39644835e-02-6.85162991e-02j -2.22910896e-01-1.64688185e-01j\n",
      "   8.45476985e-02+1.09181985e-01j  1.83407992e-01+5.31107467e-03j\n",
      "   2.19951853e-01+6.38819067e-04j  9.94076952e-02-9.18768570e-02j]\n",
      " [-3.86617146e-02-2.02416033e-01j -1.09942272e-01-1.74525440e-01j\n",
      "   2.14725491e-02-8.03982019e-02j  4.02040519e-02+1.04353435e-01j\n",
      "   8.65412652e-02+1.68566734e-01j -5.94502501e-02+7.36233499e-03j\n",
      "  -5.83853088e-02+1.30772978e-01j -2.29059756e-01+5.69656454e-02j\n",
      "   1.08911088e-02+2.00666964e-01j -3.13783213e-02-9.16299224e-02j]\n",
      " [ 2.55566597e-01-7.50440061e-02j -1.63204536e-01+9.13923755e-02j\n",
      "  -1.14762232e-01-2.27656476e-02j -9.15769041e-02+1.09509356e-01j\n",
      "  -2.09169149e-01+5.14391698e-02j -1.72721565e-01+1.46563739e-01j\n",
      "   6.44769073e-02-3.07497736e-02j  4.45372649e-02+9.30026472e-02j\n",
      "  -1.72416449e-01-1.78745762e-02j  9.06108692e-02+2.13419825e-01j]\n",
      " [-2.13847712e-01-4.18280065e-02j  2.17146846e-03+8.35791752e-02j\n",
      "   1.24771819e-02-2.49791483e-05j -1.16077930e-01+1.20185152e-01j\n",
      "   3.60926315e-02-9.44161713e-02j  1.09731995e-01-1.69385582e-01j\n",
      "  -1.12564508e-02+7.60837495e-02j -6.44579232e-02+1.84056640e-01j\n",
      "  -1.01988979e-01+7.17642233e-02j -1.01044893e-01+9.44593549e-02j]\n",
      " [-1.55785665e-01+1.91315748e-02j -6.28528297e-02-1.58440575e-01j\n",
      "   1.25384489e-02-1.12637736e-01j  6.78669810e-02-1.63666189e-01j\n",
      "   1.20335773e-01+1.71965614e-01j  4.31127734e-02+2.92131659e-02j\n",
      "  -6.02690652e-02-2.34317422e-01j -1.58911005e-01+6.07520565e-02j\n",
      "  -4.22274210e-02-1.92365184e-01j  8.01747665e-02+5.35396636e-02j]\n",
      " [-1.72194451e-01-2.21683979e-01j  1.03618689e-01-4.65877131e-02j\n",
      "   7.16787130e-02-9.08296630e-02j  2.07140476e-01-1.07244790e-01j\n",
      "  -5.83367869e-02+6.01543114e-02j  1.67397514e-01-6.70761662e-03j\n",
      "   1.85869411e-02+9.93019640e-02j -5.09668998e-02-8.27051103e-02j\n",
      "  -3.04070171e-02+4.79758643e-02j -1.11036673e-01+1.07627556e-01j]\n",
      " [-1.91931903e-01+1.81042254e-01j -1.43428490e-01+7.35228583e-02j\n",
      "   8.41390043e-02-2.77160574e-02j  2.24069264e-02-1.12757556e-01j\n",
      "  -1.91253737e-01+3.68931494e-03j  8.23192224e-02-1.27971500e-01j\n",
      "   6.34222254e-02+1.21623561e-01j -1.86100125e-01-1.47651702e-01j\n",
      "   1.80639058e-01+2.78562531e-02j -9.49801207e-02-8.72468352e-02j]\n",
      " [-1.21648706e-01+1.27268314e-01j -1.06187858e-01-1.11953631e-01j\n",
      "   1.66509166e-01-1.45017236e-01j -1.61456794e-01-1.68064848e-01j\n",
      "  -1.15689255e-01-1.49507537e-01j -3.21138836e-02+5.68766855e-02j\n",
      "  -1.93819880e-01+8.17328468e-02j -8.80806074e-02+1.39611825e-01j\n",
      "   4.41521071e-02-5.15458621e-02j -1.24499567e-01-1.39644802e-01j]\n",
      " [-1.09492563e-01+1.54569253e-01j -1.85471699e-01-1.29597753e-01j\n",
      "   1.33894712e-01+7.46779591e-02j -1.37976497e-01-4.14187983e-02j\n",
      "  -1.98442370e-01+1.44868150e-01j -3.04962527e-02-1.50383085e-01j\n",
      "   1.38575643e-01+1.45573661e-01j  1.44451231e-01+1.26904458e-01j\n",
      "   3.48447375e-02+1.98942516e-02j  1.53640509e-01+3.53401303e-02j]\n",
      " [ 1.83761835e-01-1.21090986e-01j  2.08529279e-01+1.21180877e-01j\n",
      "  -1.01688199e-01+4.21738178e-02j -1.94652975e-01-1.05675004e-01j\n",
      "   1.44185703e-02+1.79529890e-01j -1.88907310e-02+2.07274392e-01j\n",
      "   1.43711299e-01+1.33137360e-01j -8.63102227e-02+2.05144301e-01j\n",
      "  -1.57460809e-01+4.51457016e-02j  1.42160177e-01+1.45990804e-01j]\n",
      " [-2.71748248e-02-9.25602019e-02j -1.71971638e-02-1.48038909e-01j\n",
      "  -1.61382288e-01+1.77474976e-01j -2.12021276e-01-4.12777662e-02j\n",
      "   1.74051136e-01+2.06298083e-02j -1.16993830e-01-1.05326526e-01j\n",
      "   1.82719693e-01-1.60364658e-01j -8.42826962e-02-8.20701867e-02j\n",
      "  -1.24035858e-01-2.25446559e-02j  1.18934512e-02+1.89501554e-01j]\n",
      " [-1.25027463e-01+1.92024544e-01j  4.39168289e-02+7.37171620e-02j\n",
      "  -8.68548453e-02-2.13699535e-01j -6.21643625e-02-1.48329303e-01j\n",
      "   1.92843288e-01-6.06154688e-02j  2.06463918e-01-5.59876747e-02j\n",
      "  -2.88295783e-02-5.63639626e-02j  2.45982260e-02+7.47865587e-02j\n",
      "   1.99447572e-01+1.65649146e-01j -9.21888202e-02+1.02113575e-01j]\n",
      " [-3.27576213e-02-5.27780093e-02j -1.21553894e-03-1.44782558e-01j\n",
      "   2.26619273e-01-1.03201792e-01j -6.21813200e-02+1.08306885e-01j\n",
      "  -1.07112087e-01+6.72325864e-02j -1.77699372e-01+1.70146689e-01j\n",
      "  -1.17277183e-01+1.55895174e-01j  1.25999957e-01-1.56382993e-02j\n",
      "  -2.11309027e-02-9.54553783e-02j  1.28163218e-01+1.86816260e-01j]\n",
      " [ 9.07115918e-03-1.39835566e-01j -1.37705132e-01+2.00943481e-02j\n",
      "   1.10073008e-01+1.70231760e-01j -4.31704037e-02-2.18845412e-01j\n",
      "   1.19662382e-01-9.85468701e-02j -1.65306449e-01-2.02125013e-01j\n",
      "  -8.03610384e-02-1.81203812e-01j  1.06089927e-01+1.65215060e-01j\n",
      "   1.36422187e-01-8.68753530e-03j  1.06936790e-01-8.97793621e-02j]\n",
      " [ 1.56250790e-01-4.14867625e-02j  1.52638301e-01-1.33506879e-01j\n",
      "   2.16826573e-01-8.83081034e-02j  2.18088880e-01-2.81877369e-02j\n",
      "   3.62061188e-02-2.21630335e-01j -1.96968272e-01-1.66096374e-01j\n",
      "  -1.54569507e-01-1.76920323e-03j  1.25644833e-01+4.35577929e-02j\n",
      "  -1.48694187e-01-1.12257153e-01j -8.26850906e-02-2.21342236e-01j]]>\n",
      "<Variable path=encoder/encoder/bias, shape=(10,), dtype=complex64, value=[-0.00740285+0.02486573j -0.01515483+0.02271459j  0.00939135-0.00276686j\n",
      "  0.01281795+0.00703645j -0.01392935-0.00069374j  0.00654605-0.00270237j\n",
      "  0.02049929+0.02298221j -0.02302485-0.00339669j -0.00361263+0.01358504j\n",
      "  0.00319859-0.00788669j]>\n",
      "<Variable path=encoder/encoder/W1, shape=(100, 50), dtype=complex64, value=[[ 0.09244864+0.14494692j  0.01227243-0.07528866j  0.06672193+0.08785915j\n",
      "  ...  0.05395623-0.10782754j -0.13224775-0.01979711j\n",
      "   0.05224774-0.07382949j]\n",
      " [-0.07050645+0.0035815j  -0.11980142-0.06231909j -0.10489909+0.14543955j\n",
      "  ...  0.10318528+0.04265403j -0.10653669+0.03780513j\n",
      "  -0.03972917-0.07382254j]\n",
      " [-0.0619216 +0.02853465j  0.04755785-0.09838584j -0.11732392+0.15900908j\n",
      "  ...  0.06002105-0.04441363j  0.07011312-0.09732947j\n",
      "  -0.06698553-0.14093293j]\n",
      " ...\n",
      " [-0.0714357 -0.04302206j -0.07941628+0.05878137j  0.10564069-0.00454861j\n",
      "  ...  0.05376237-0.11026691j  0.00517795+0.08025176j\n",
      "  -0.07394775-0.13102566j]\n",
      " [ 0.08904701-0.05661314j -0.12146333-0.13268255j -0.14273226-0.02225829j\n",
      "  ...  0.0699699 +0.11344243j  0.09673986-0.00735459j\n",
      "  -0.04254872+0.08161419j]\n",
      " [-0.00452796+0.10771661j  0.14258158+0.03107573j  0.05568873+0.06307203j\n",
      "  ... -0.00895085-0.01511014j -0.10317195+0.03215495j\n",
      "  -0.1478385 -0.09576894j]]>\n",
      "<Variable path=encoder/encoder/W2, shape=(100, 50), dtype=complex64, value=[[-0.07265263-0.03421506j -0.05271096-0.01307347j  0.01112413+0.12489831j\n",
      "  ... -0.12287355+0.01332687j  0.06338564+0.14595723j\n",
      "   0.0632841 +0.03280787j]\n",
      " [ 0.11277856+0.02657668j -0.1127562 -0.02787834j  0.11656117+0.01440323j\n",
      "  ...  0.04317464-0.10740376j -0.06184525-0.00126685j\n",
      "   0.10691104+0.06865239j]\n",
      " [-0.02521329-0.11814093j -0.07381197-0.09056284j  0.05144933+0.15859567j\n",
      "  ... -0.09923618+0.04537129j -0.10113029+0.09840984j\n",
      "  -0.12248113-0.08123337j]\n",
      " ...\n",
      " [ 0.0614639 -0.1240541j   0.00856802-0.01850586j -0.01428736+0.08690303j\n",
      "  ... -0.08501196-0.07549147j -0.04169052+0.10530627j\n",
      "   0.01364577+0.02103592j]\n",
      " [ 0.02688791+0.11238761j  0.01919247+0.06677756j -0.0492213 -0.07876166j\n",
      "  ...  0.09421512+0.06479654j  0.06680076+0.02320735j\n",
      "  -0.06021702-0.12759712j]\n",
      " [ 0.00697797+0.04791318j  0.12965508-0.04572244j -0.04575689-0.07764552j\n",
      "  ... -0.03302861+0.06832311j -0.11133735+0.01083017j\n",
      "   0.03983155+0.06864156j]]>\n",
      "<Variable path=encoder/encoder/bias, shape=(50,), dtype=complex64, value=[-0.01524849+0.01518806j  0.01122001+0.0084925j  -0.01334411+0.02146715j\n",
      "  0.00944092-0.01374223j -0.00074367+0.00941263j  0.00176098-0.00337052j\n",
      " -0.02071685+0.00196459j -0.00569862+0.0042986j   0.00722577-0.0005184j\n",
      " -0.01242464+0.01330639j  0.01574346+0.01224231j -0.00332796+0.00449248j\n",
      " -0.007723  -0.00094429j  0.0040961 -0.02203102j -0.01211351+0.00219746j\n",
      "  0.00865583-0.00369326j  0.00131393-0.00775048j -0.01635944+0.00402899j\n",
      " -0.00371926+0.01739744j  0.00479851+0.01184888j  0.00667862+0.00971107j\n",
      " -0.00067712-0.00261714j  0.01142912+0.01323823j  0.00490536+0.00118005j\n",
      " -0.02408992+0.00045712j -0.00412408+0.00225463j -0.00393542+0.00133713j\n",
      " -0.00285733-0.01379213j -0.01215267+0.00238351j  0.00798994-0.00753412j\n",
      " -0.01587445-0.00294687j -0.00054784+0.01466511j -0.01456092+0.02025601j\n",
      " -0.0041655 -0.01259122j -0.01264552-0.00584667j  0.00152816-0.00122384j\n",
      " -0.00022151-0.01725055j  0.01085351+0.00721662j  0.00438527+0.00012451j\n",
      " -0.00755522+0.00130846j  0.00252645+0.01552561j  0.0372597 -0.0050413j\n",
      "  0.00779616-0.01021289j  0.0087275 -0.00910321j -0.00503322-0.01792221j\n",
      "  0.00504808+0.01819276j  0.00068153-0.01912004j -0.00109886+0.01056302j\n",
      " -0.00960935+0.00468215j -0.01032119-0.00223548j]>\n"
     ]
    }
   ],
   "source": [
    "# test optimizer\n",
    "stepsize_function = copt.adaptive_stepsize\n",
    "optimizer = copt.Complex_SGD(stepsize_function)\n",
    "print(type(optimizer))\n",
    "optimizer.apply_gradients(grads_and_vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1043ce2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "complex tensor tf.Tensor([-10.-2.j  -5.-1.j   0.+0.j   5.+1.j  10.+2.j], shape=(5,), dtype=complex64)\n",
      "tf.Tensor(\n",
      "[-9.01942 -1.8038839j  -4.019419-0.80388385j  0.      +0.j\n",
      "  4.019419+0.80388385j  9.01942 +1.8038839j ], shape=(5,), dtype=complex64)\n",
      "[10.198039   5.0990195  0.         5.0990195 10.198039 ]\n",
      "[9.198039  4.0990195 0.        4.0990195 9.198039 ]\n",
      "tf.Tensor(260.0, shape=(), dtype=float32)\n",
      "(<tf.Tensor: shape=(5,), dtype=complex64, numpy=array([-10.+2.j,  -5.+1.j,   0.-0.j,   5.-1.j,  10.-2.j], dtype=complex64)>, <tf.Tensor: shape=(5,), dtype=complex64, numpy=array([-10.-2.j,  -5.-1.j,   0.+0.j,   5.+1.j,  10.+2.j], dtype=complex64)>)\n",
      "tf.Tensor(\n",
      "[[2 4]\n",
      " [6 8]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[2 4]\n",
      " [6 8]], shape=(2, 2), dtype=int32)\n",
      "tf.Tensor(\n",
      "[[ 6  6]\n",
      " [14 14]], shape=(2, 2), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# test activation fuction\n",
    "seq = np.array([-10,-5,0,5,10])\n",
    "c_seq = np.array([-2,-1,0,1,2])\n",
    "real_tensor = tf.convert_to_tensor(seq.astype('float32'))\n",
    "imag_tensor = tf.convert_to_tensor(c_seq.astype('float32'))\n",
    "c_tensor = tf.complex(real_tensor, imag_tensor)\n",
    "\n",
    "print(\"complex tensor\", c_tensor)\n",
    "modrelu = lambda z: autosetup.modrelu(z, b=-1)\n",
    "print(modrelu(c_tensor))\n",
    "print(np.abs(c_tensor))\n",
    "print(np.abs(modrelu(c_tensor)))\n",
    "\n",
    "# test Jacobian activation function\n",
    "#print(\"jacobians\", autosetup.Jac_modrelu(c_tensor))\n",
    "#print(\"absolute value c_tensor\", 2/tf.cast(tf.math.abs(c_tensor), c_tensor.dtype)**3)\n",
    "\n",
    "\n",
    "# test loss function \n",
    "aL = 2*c_tensor \n",
    "loss = autosetup.loss_MSE(aL, c_tensor)\n",
    "print(loss)\n",
    "\n",
    "print(autosetup.dLossdaL(aL, c_tensor))\n",
    "\n",
    "# stupid elementwise computation test\n",
    "x1 = tf.constant(([1,2],[3,4]))\n",
    "x2 = tf.constant(([2,2],[2,2]))\n",
    "print(tf.math.multiply(x1,x2))\n",
    "print(x1*x2)\n",
    "print(x1@x2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1af58fa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([1.+0.j 2.+0.j 3.+0.j], shape=(3,), dtype=complex64)\n",
      "tf.Tensor([1.+1.j 2.+2.j 3.+3.j 4.+4.j], shape=(4,), dtype=complex64)\n",
      "(3, 4)\n",
      "tf.Tensor(\n",
      "[[ 1. +1.j  2. +2.j  3. +3.j  4. +4.j]\n",
      " [ 2. +2.j  4. +4.j  6. +6.j  8. +8.j]\n",
      " [ 3. +3.j  6. +6.j  9. +9.j 12.+12.j]], shape=(3, 4), dtype=complex64)\n",
      "[0, 1, 2, 3, 4, 5, 6, 7, 8, 9]\n",
      "[9, 8, 7, 6, 5, 4, 3, 2, 1, 0]\n",
      "[9, 8, 7, 6, 5, 4, 3, 2, 1]\n"
     ]
    }
   ],
   "source": [
    "u = tf.complex(tf.constant([1.,2.,3.]), tf.constant([0., 0., 0.]))\n",
    "v = tf.complex(tf.constant([1.,2.,3.,4.]), tf.constant([1.,2.,3.,4.]))\n",
    "\n",
    "print(u)\n",
    "print(v)\n",
    "e = tf.einsum('i,j->ij', u, v)  # output[i,j] = u[i]*v[j]\n",
    "print(e.shape)\n",
    "print(e)\n",
    "\n",
    "print(list(range(10)))\n",
    "print(list(reversed(range(10))))\n",
    "print(list(reversed(range(1,10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae9ed44e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "@register_keras_serializable()\n",
    "class Autoencoder(Model):\n",
    "  def __init__(self, latent_dim, shape, **kwargs):\n",
    "    super().__init__(**kwargs)\n",
    "    self.latent_dim = latent_dim\n",
    "    self.shape = shape\n",
    "    self.encoder = tf.keras.Sequential([\n",
    "      layers.Flatten(),\n",
    "      layers.Dense(latent_dim, activation='relu'),\n",
    "    ])\n",
    "    self.decoder = tf.keras.Sequential([\n",
    "      layers.Dense(tf.math.reduce_prod(shape).numpy(), activation='sigmoid'),\n",
    "      layers.Reshape(shape)\n",
    "    ])\n",
    "  \n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded\n",
    "  \n",
    "\n",
    "  def get_config(self):\n",
    "    config = super().get_config()\n",
    "    config.update(\n",
    "      {\n",
    "        \"latent_dim\": self.latent_dim,\n",
    "        \"shape\": self.shape,\n",
    "       # \"encoder\": self.encoder,\n",
    "       # \"decoder\": self.decoder,\n",
    "      }\n",
    "    )\n",
    "    return config\n",
    "\n",
    "  # can be removed I think\n",
    "  # @classmethod\n",
    "  # def from_config(cls, config):\n",
    "  #     config[\"latent_dim\"] = deserialize_keras_object(config[\"latent_dim\"])\n",
    "  #     config[\"shape\"] = deserialize_keras_object(config[\"shape\"])\n",
    "  #     #config[\"encoder\"] = deserialize_keras_object(config[\"encoder\"])\n",
    "  #     #config[\"decoder\"] = deserialize_keras_object(config[\"decoder\"])\n",
    "  #     return cls(**config)\n",
    "\n",
    "\n",
    "shape = x_test_small.shape[1:]\n",
    "latent_dim = 10\n",
    "autoencoder = Autoencoder(latent_dim, shape)\n",
    "print(len(autoencoder.layers))\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "1fbf80d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are casting an input of type complex64 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1658/1875\u001b[0m \u001b[32m\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - loss: 0.4029"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[40], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m, loss\u001b[38;5;241m=\u001b[39mlosses\u001b[38;5;241m.\u001b[39mMeanSquaredError()) \u001b[38;5;66;03m# configuration of the model for training, adam is a stochastic gradient method that estimates moments\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[43mautoencoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_cx_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_train_cx_small\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# number of times the entire training dataset is run through the model\u001b[39;49;00m\n\u001b[0;32m      4\u001b[0m \u001b[43m                \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# shuffles the data set before each training epoch\u001b[39;49;00m\n\u001b[0;32m      5\u001b[0m \u001b[43m                \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mx_test_cx_small\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_test_cx_small\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# validation at the end of each epoch\u001b[39;00m\n\u001b[0;32m      6\u001b[0m                 \u001b[38;5;66;03m# batch size is 32 by default\u001b[39;00m\n\u001b[0;32m      8\u001b[0m autoencoder\u001b[38;5;241m.\u001b[39msummary()\n",
      "File \u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\keras\\src\\utils\\traceback_utils.py:117\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    115\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:371\u001b[0m, in \u001b[0;36mTensorFlowTrainer.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq)\u001b[0m\n\u001b[0;32m    369\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step, iterator \u001b[38;5;129;01min\u001b[39;00m epoch_iterator:\n\u001b[0;32m    370\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_begin(step)\n\u001b[1;32m--> 371\u001b[0m     logs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_function\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    372\u001b[0m     callbacks\u001b[38;5;241m.\u001b[39mon_train_batch_end(step, logs)\n\u001b[0;32m    373\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstop_training:\n",
      "File \u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\trainer.py:219\u001b[0m, in \u001b[0;36mTensorFlowTrainer._make_function.<locals>.function\u001b[1;34m(iterator)\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mfunction\u001b[39m(iterator):\n\u001b[0;32m    216\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\n\u001b[0;32m    217\u001b[0m         iterator, (tf\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mIterator, tf\u001b[38;5;241m.\u001b[39mdistribute\u001b[38;5;241m.\u001b[39mDistributedIterator)\n\u001b[0;32m    218\u001b[0m     ):\n\u001b[1;32m--> 219\u001b[0m         opt_outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmulti_step_on_iterator\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    220\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m opt_outputs\u001b[38;5;241m.\u001b[39mhas_value():\n\u001b[0;32m    221\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    148\u001b[0m filtered_tb \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    149\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 150\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m fn(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n",
      "File \u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:833\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    830\u001b[0m compiler \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxla\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnonXla\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    832\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m OptionalXlaContext(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jit_compile):\n\u001b[1;32m--> 833\u001b[0m   result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    835\u001b[0m new_tracing_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mexperimental_get_tracing_count()\n\u001b[0;32m    836\u001b[0m without_tracing \u001b[38;5;241m=\u001b[39m (tracing_count \u001b[38;5;241m==\u001b[39m new_tracing_count)\n",
      "File \u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\polymorphic_function.py:878\u001b[0m, in \u001b[0;36mFunction._call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    875\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock\u001b[38;5;241m.\u001b[39mrelease()\n\u001b[0;32m    876\u001b[0m \u001b[38;5;66;03m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[0;32m    877\u001b[0m \u001b[38;5;66;03m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[1;32m--> 878\u001b[0m results \u001b[38;5;241m=\u001b[39m \u001b[43mtracing_compilation\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    879\u001b[0m \u001b[43m    \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_variable_creation_config\u001b[49m\n\u001b[0;32m    880\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    881\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_created_variables:\n\u001b[0;32m    882\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCreating variables on a non-first call to a function\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    883\u001b[0m                    \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m decorated with tf.function.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\tracing_compilation.py:139\u001b[0m, in \u001b[0;36mcall_function\u001b[1;34m(args, kwargs, tracing_options)\u001b[0m\n\u001b[0;32m    137\u001b[0m bound_args \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mbind(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    138\u001b[0m flat_inputs \u001b[38;5;241m=\u001b[39m function\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39munpack_inputs(bound_args)\n\u001b[1;32m--> 139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pylint: disable=protected-access\u001b[39;49;00m\n\u001b[0;32m    140\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcaptured_inputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcaptured_inputs\u001b[49m\n\u001b[0;32m    141\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\concrete_function.py:1322\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[1;34m(self, tensor_inputs, captured_inputs)\u001b[0m\n\u001b[0;32m   1318\u001b[0m possible_gradient_type \u001b[38;5;241m=\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[0;32m   1319\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (possible_gradient_type \u001b[38;5;241m==\u001b[39m gradients_util\u001b[38;5;241m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[0;32m   1320\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m executing_eagerly):\n\u001b[0;32m   1321\u001b[0m   \u001b[38;5;66;03m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[1;32m-> 1322\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_inference_function\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_preflattened\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1323\u001b[0m forward_backward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[0;32m   1324\u001b[0m     args,\n\u001b[0;32m   1325\u001b[0m     possible_gradient_type,\n\u001b[0;32m   1326\u001b[0m     executing_eagerly)\n\u001b[0;32m   1327\u001b[0m forward_function, args_with_tangents \u001b[38;5;241m=\u001b[39m forward_backward\u001b[38;5;241m.\u001b[39mforward()\n",
      "File \u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:216\u001b[0m, in \u001b[0;36mAtomicFunction.call_preflattened\u001b[1;34m(self, args)\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_preflattened\u001b[39m(\u001b[38;5;28mself\u001b[39m, args: Sequence[core\u001b[38;5;241m.\u001b[39mTensor]) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[0;32m    215\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Calls with flattened tensor inputs and returns the structured output.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 216\u001b[0m   flat_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_flat\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    217\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunction_type\u001b[38;5;241m.\u001b[39mpack_output(flat_outputs)\n",
      "File \u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\eager\\polymorphic_function\\atomic_function.py:251\u001b[0m, in \u001b[0;36mAtomicFunction.call_flat\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m record\u001b[38;5;241m.\u001b[39mstop_recording():\n\u001b[0;32m    250\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mexecuting_eagerly():\n\u001b[1;32m--> 251\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_bound_context\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcall_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    252\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    253\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    254\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction_type\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflat_outputs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    255\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    256\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    257\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m make_call_op_in_graph(\n\u001b[0;32m    258\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m    259\u001b[0m         \u001b[38;5;28mlist\u001b[39m(args),\n\u001b[0;32m    260\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_bound_context\u001b[38;5;241m.\u001b[39mfunction_call_options\u001b[38;5;241m.\u001b[39mas_attrs(),\n\u001b[0;32m    261\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\eager\\context.py:1688\u001b[0m, in \u001b[0;36mContext.call_function\u001b[1;34m(self, name, tensor_inputs, num_outputs)\u001b[0m\n\u001b[0;32m   1686\u001b[0m cancellation_context \u001b[38;5;241m=\u001b[39m cancellation\u001b[38;5;241m.\u001b[39mcontext()\n\u001b[0;32m   1687\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cancellation_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1688\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m \u001b[43mexecute\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1689\u001b[0m \u001b[43m      \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mutf-8\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1690\u001b[0m \u001b[43m      \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnum_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1691\u001b[0m \u001b[43m      \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1692\u001b[0m \u001b[43m      \u001b[49m\u001b[43mattrs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1693\u001b[0m \u001b[43m      \u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1694\u001b[0m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1695\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1696\u001b[0m   outputs \u001b[38;5;241m=\u001b[39m execute\u001b[38;5;241m.\u001b[39mexecute_with_cancellation(\n\u001b[0;32m   1697\u001b[0m       name\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m),\n\u001b[0;32m   1698\u001b[0m       num_outputs\u001b[38;5;241m=\u001b[39mnum_outputs,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1702\u001b[0m       cancellation_manager\u001b[38;5;241m=\u001b[39mcancellation_context,\n\u001b[0;32m   1703\u001b[0m   )\n",
      "File \u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\eager\\execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[1;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m \u001b[43mpywrap_tfe\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mTFE_Py_Execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mctx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     54\u001b[0m \u001b[43m                                      \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mattrs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_outputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[0;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError()) # configuration of the model for training, adam is a stochastic gradient method that estimates moments\n",
    "autoencoder.fit(x_train_cx_small, x_train_cx_small,\n",
    "                epochs=10, # number of times the entire training dataset is run through the model\n",
    "                shuffle=True, # shuffles the data set before each training epoch\n",
    "                validation_data=(x_test_cx_small, x_test_cx_small)) # validation at the end of each epoch\n",
    "                # batch size is 32 by default\n",
    "\n",
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df5618ef",
   "metadata": {},
   "source": [
    "##### Load & save autoencoder model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ae1a4487",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('autoencoder_10epochs_mnist_10x10.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "44102d97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: From c:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\keras\\src\\backend\\tensorflow\\core.py:219: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " sequential_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> \n",
       "\n",
       " sequential_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">1,100</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " sequential_2 (\u001b[38;5;33mSequential\u001b[0m)        (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)                        \u001b[38;5;34m1,010\u001b[0m \n",
       "\n",
       " sequential_3 (\u001b[38;5;33mSequential\u001b[0m)        (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m)                    \u001b[38;5;34m1,100\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,332</span> (24.74 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,332\u001b[0m (24.74 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,110</span> (8.24 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,110\u001b[0m (8.24 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,222</span> (16.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m4,222\u001b[0m (16.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "autoencoder_reconstructed = tf.keras.models.load_model('autoencoder_10epochs_mnist_10x10.keras')\n",
    "autoencoder_reconstructed.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea596d0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(10000, 10, 10)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x400 with 20 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"autoencoder\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"autoencoder\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"font-weight: bold\"> Layer (type)                    </span><span style=\"font-weight: bold\"> Output Shape           </span><span style=\"font-weight: bold\">       Param # </span>\n",
       "\n",
       " sequential (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)          (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                        <span style=\"color: #00af00; text-decoration-color: #00af00\">1,010</span> \n",
       "\n",
       " sequential_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        (<span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                    <span style=\"color: #00af00; text-decoration-color: #00af00\">1,100</span> \n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m\n",
       "\n",
       " sequential (\u001b[38;5;33mSequential\u001b[0m)          (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m)                        \u001b[38;5;34m1,010\u001b[0m \n",
       "\n",
       " sequential_1 (\u001b[38;5;33mSequential\u001b[0m)        (\u001b[38;5;34m32\u001b[0m, \u001b[38;5;34m10\u001b[0m, \u001b[38;5;34m10\u001b[0m)                    \u001b[38;5;34m1,100\u001b[0m \n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,332</span> (24.74 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,332\u001b[0m (24.74 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,110</span> (8.24 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m2,110\u001b[0m (8.24 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Optimizer params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,222</span> (16.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Optimizer params: \u001b[0m\u001b[38;5;34m4,222\u001b[0m (16.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "encoded_imgs = autoencoder.encoder(x_test_small).numpy()\n",
    "print(encoded_imgs.shape)\n",
    "decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n",
    "print(decoded_imgs.shape)\n",
    "\n",
    "ns = 10\n",
    "plt.figure(figsize=(20, 4))\n",
    "for i in range(ns):\n",
    "  # display original\n",
    "  ax = plt.subplot(2, ns, i + 1)\n",
    "  plt.imshow(x_test_small[i])\n",
    "  plt.title(\"original\")\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "\n",
    "  # display reconstruction\n",
    "  ax = plt.subplot(2, ns, i + 1 + ns)\n",
    "  plt.imshow(decoded_imgs[i])\n",
    "  plt.title(\"reconstructed\")\n",
    "  plt.gray()\n",
    "  ax.get_xaxis().set_visible(False)\n",
    "  ax.get_yaxis().set_visible(False)\n",
    "plt.show()\n",
    "\n",
    "autoencoder.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de89a64",
   "metadata": {},
   "source": [
    "#### Extracting autoencoder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6cc3a47e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 10, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x274ccea72e0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# random input looks like this\n",
    "z_random = np.random.normal(size=(1,10))\n",
    "test_z = autoencoder.decoder(z_random) #test_z is a tf \n",
    "print(test_z.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(test_z[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3921a8e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n",
      "(1, 100, 10)\n",
      "tf.Tensor([[1. 1. 1. 1. 1. 1. 1. 1. 1. 1.]], shape=(1, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# OLD SAVE FOR NOW IF IT GETS WORSE\n",
    "# # compute gradient function\n",
    "# def grad_decoder_1D(decoder, input_dim):\n",
    "#     '''\n",
    "#     first wrap decoder into tensorflow function to improve computation speed\n",
    "#     specifically also changes 2D output to 1D output\n",
    "\n",
    "#     input:\n",
    "#         decoder:        the autoencoder.decoder as input, maps 1D input z to 2D output\n",
    "#         input_dim:      int, size of the input dimension (usually representing latent space)\n",
    "\n",
    "#     output:\n",
    "#         jac_operator:   a function that computes the jacobian wrt input z and returns the gradients and output in terms of a tensor\n",
    "\n",
    "#     '''\n",
    "#     decoder_1D = lambda x : tf.reshape(decoder(x), [tf.shape(decoder(x))[0], -1])\n",
    "\n",
    "#     @tf.function(reduce_retracing=True)\n",
    "#     def jac_operator(z):\n",
    "#         '''\n",
    "#         input:\n",
    "#             z:      vector in the latent space, size = (sample size, dimension latent space)\n",
    "#         '''\n",
    "#         z = tf.convert_to_tensor(z) # leaves z unchanged if input is already in form of tf.tensor\n",
    "#         z = tf.reshape(z, [-1, input_dim]) # leaves z unchanged if size is already shaped (sample size, dim latent space), else performs 2D array conversion\n",
    "\n",
    "#         with tf.GradientTape() as tape:\n",
    "#             tape.watch(z)           # record derivatives\n",
    "#             output = decoder_1D(z)     # the function to compute the derivative of\n",
    "\n",
    "#         # gradient wrt z = (batch size, input length)\n",
    "#         gradients = tape.batch_jacobian(output, z)\n",
    "\n",
    "#         return output, gradients\n",
    "    \n",
    "#     return jac_operator\n",
    "\n",
    "# def make_tensor_shape(z):\n",
    "#     #z = z.reshape((1,-1))\n",
    "#     tensor_z = tf.convert_to_tensor(z, dtype=tf.float32)\n",
    "#     return tf.reshape(tensor_z,[1,-1])\n",
    "\n",
    "\n",
    "# decoderfun_2D  = lambda z : autoencoder.decoder(z) \n",
    "\n",
    "# test_jac = grad_decoder_1D(decoderfun_2D, latent_dim)\n",
    "# output, grads = test_jac(z_random)\n",
    "\n",
    "# print(output.shape)\n",
    "# print(grads.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fac24c9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 10)\n",
      "(100,)\n",
      "<class 'numpy.ndarray'>\n",
      "(100, 10)\n"
     ]
    }
   ],
   "source": [
    "# compute function generative map\n",
    "def make_tensor_shape(z):\n",
    "    #z = z.reshape((1,-1))\n",
    "    tensor_z = tf.convert_to_tensor(z, dtype=tf.float32)\n",
    "    return tf.reshape(tensor_z,[1,-1])\n",
    "\n",
    "def make_tensor(z):\n",
    "    return tf.convert_to_tensor(z, dtype=tf.float32)\n",
    "\n",
    "def decoderfunc_1D(decoder, z):\n",
    "    '''\n",
    "    Converts the autoencoder.decoder function into a generative embedding function.\n",
    "\n",
    "    input:\n",
    "        decoder:        keras sequential (intended use: autoencoder.decoder), numpy.array(sample size, latent_dim) --> tensor(sample size, dim x dim))    \n",
    "        z:              np.array of length (latent_dim)\n",
    "\n",
    "    output:\n",
    "        decoderfunc_1D: function that maps z to numpy array of lenght dim^2 (flattened original image)\n",
    "    '''\n",
    "    return decoder(tf.reshape(make_tensor(z), [1,-1])).numpy().flatten() \n",
    "\n",
    "# compute Jacobian generative map\n",
    "def jac_decoder_1D(decoder, input_dim):\n",
    "    '''\n",
    "    currently creates function that only handles 1D input\n",
    "\n",
    "    first wrap decoder into tensorflow function to improve computation speed\n",
    "    specifically also changes 2D output to 1D output\n",
    "    can only handle z as 1D input\n",
    "\n",
    "    input:\n",
    "        decoder:        keras sequential, numpy.array(sample size, latent_dim) --> tensor(sample size, dim x dim)) \n",
    "        input_dim:      int, size of the input dimension (usually representing latent space)\n",
    "\n",
    "    output:\n",
    "        jac_operator:   a function that computes the jacobian wrt input z and returns the gradients and output in terms of a tensor\n",
    "\n",
    "    '''\n",
    "    decoder_1D = lambda x : tf.reshape(decoder(x), [tf.shape(decoder(x))[0], -1])\n",
    "\n",
    "    @tf.function(reduce_retracing=True)\n",
    "    def jac_operator_tf(z):\n",
    "        '''\n",
    "        input:\n",
    "            z:      vector in the latent space, np.array of length input_dim\n",
    "        '''\n",
    "        z = tf.convert_to_tensor(z) # leaves z unchanged if input is already in form of tf.tensor\n",
    "        z = tf.reshape(z, [1, input_dim]) # leaves z unchanged if size is already shaped (sample size, dim latent space), else performs 2D array conversion\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            tape.watch(z)           # record derivatives\n",
    "            output = decoder_1D(z)     # the function to compute the derivative of\n",
    "\n",
    "        # gradient wrt z = (batch size, input length)\n",
    "        gradients = tape.batch_jacobian(output, z)\n",
    "\n",
    "        return gradients\n",
    "    \n",
    "    def jac_operator(z):\n",
    "        gradients = jac_operator_tf(z)\n",
    "        return gradients[0].numpy()\n",
    "\n",
    "    return jac_operator\n",
    "\n",
    "\n",
    "encode = autoencoder.encoder(x_test_small)\n",
    "print(encode.shape)\n",
    "\n",
    "x1 = encode[0,:] # test object\n",
    "y1 = decoderfunc_1D(autoencoder.decoder, x1)\n",
    "print(y1.shape)\n",
    "y1_recon = y1.reshape((10,10))\n",
    "\n",
    "compute_jac = jac_decoder_1D(autoencoder.decoder, latent_dim)\n",
    "dGdx = compute_jac(x1)\n",
    "\n",
    "print(type(dGdx))\n",
    "print(dGdx.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e57d273",
   "metadata": {},
   "source": [
    "### Set-up from ptygenography"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5615aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Op:\n",
    "    def __init__(self, fun, jac, shape):\n",
    "        self.eval = fun\n",
    "        self.jac = jac\n",
    "        self.shape = shape\n",
    "        \n",
    "def objective(z, y, A, G, w=1, lmbda = 0):\n",
    "    \"\"\"\n",
    "    LS objective\n",
    "        (0.5)*\\|A(G(z)) - y\\|_2^2 + 0.5*lmbda**2*\\|w*z\\|_2^2\n",
    "    \"\"\"\n",
    "    if len(y) != A.shape[0]:\n",
    "        print(\"y and A don't match\")\n",
    "        return\n",
    "    if len(z)//2 != G.shape[1]:\n",
    "        print(\"z and G don't match\")\n",
    "        return\n",
    "    if A.shape[1] != G.shape[0]:\n",
    "        print(\"A and G don't match!\")\n",
    "        return\n",
    "    \n",
    "    k  = len(z)//2\n",
    "    zc = z[:k] + 1j*z[k:]\n",
    "    \n",
    "    xc = G.eval(zc)\n",
    "    Dx = G.jac(zc)\n",
    "\n",
    "    #print(\"Dx\", Dx.shape)\n",
    "    \n",
    "    yp = A.eval(xc)\n",
    "    Dy = A.jac(xc)\n",
    "\n",
    "    #print(\"Dy\", Dy.shape)\n",
    "\n",
    "    val    = (0.5)*np.linalg.norm(yp - y)**2 + (0.5*lmbda**2)*np.linalg.norm(w*zc)**2\n",
    "    gradc  = Dx.H@(Dy.H@(yp - y)) + (lmbda**2)*(w*w)*zc\n",
    "    \n",
    "    grad  = np.concatenate((np.real(gradc), np.imag(gradc)))\n",
    "    \n",
    "    return val, grad\n",
    "\n",
    "def reconstruct(xtrue, A, G, w=1, sigma=0, lmbda=0):\n",
    "    # sizes\n",
    "    m,n = A.shape\n",
    "    n,k = G.shape\n",
    "    \n",
    "    # generate data\n",
    "    yobs  = A.eval(xtrue) + sigma*np.random.randn(m)\n",
    "\n",
    "    print(\"xtrue\", xtrue.shape)\n",
    "    print(\"yobs\", yobs.shape)\n",
    "    print(\"k\", k)\n",
    "    print(\"m\", m)\n",
    "\n",
    "    # inference\n",
    "    result = minimize(objective, x0=np.ones(2*k), args=(yobs, A, G, w, lmbda), method='L-BFGS-B', jac=True)\n",
    "    \n",
    "    # result\n",
    "    zhat = result.x[:k] + 1j*result.x[k:]\n",
    "    xhat = G.eval(zhat)\n",
    "    \n",
    "    # correct global phase\n",
    "    phi = np.mean(np.angle(xtrue/xhat))\n",
    "    xhat_corr = np.exp(1j*phi)*xhat\n",
    "    \n",
    "    # relative error\n",
    "    error = np.linalg.norm(xhat_corr - xtrue)/np.linalg.norm(xtrue)\n",
    "    \n",
    "    # return\n",
    "    return error, xhat_corr, yobs\n",
    "\n",
    "def plot_result(xtrue, xhat):\n",
    "    n  = len(xtrue)\n",
    "    nx = int(np.sqrt(n))\n",
    "    \n",
    "    # plot results\n",
    "    fig, ax = plt.subplots(2,2)\n",
    "\n",
    "    ax[0,0].imshow(np.real(xtrue.reshape((nx,nx))),clim=[0,1])\n",
    "    ax[0,0].set_title(r'$\\Re(x_{true})$')\n",
    "    ax[1,0].imshow(np.imag(xtrue.reshape((nx,nx))),clim=[0,1])\n",
    "    ax[1,0].set_title(r'$\\Im(x_{true})$')\n",
    "    ax[0,1].imshow(np.real(xhat.reshape((nx,nx))),clim=[0,1])\n",
    "    ax[0,1].set_title(r'$\\Re(x_{est})$')\n",
    "    ax[1,1].imshow(np.imag(xhat.reshape((nx,nx))),clim=[0,1])\n",
    "    ax[1,1].set_title(r'$\\Im(x_{est})$')\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5c5f9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaskedFourier(M):\n",
    "    \"\"\"\n",
    "    Defined masked 2D fourier transform as linear operator.\n",
    "    \n",
    "    input:\n",
    "        M - 3D array of size n x n x m containing m masks of size n x n\n",
    "        \n",
    "    out:\n",
    "        A - linear operator representing the masked Fourier transforms\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    nx = M.shape[0]\n",
    "    mx = M.shape[2]\n",
    "    \n",
    "    mv  = lambda x : fft2(M*(x.reshape((nx,nx,1))), axes=(0,1)).flatten()\n",
    "    rmv = lambda y : nx*nx*np.sum(np.conj(M)*ifft2(y.reshape((nx,nx,mx)), axes=(0,1)),axis=2).flatten()\n",
    "    A   = LinearOperator((mx*nx*nx, nx*nx), matvec=mv, rmatvec=rmv) # rmatvec is conjugate operation, so A^H * v\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e603f7a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters\n",
    "mx      = 10       # number of masks\n",
    "nx      = shape[0]  # one side of the image\n",
    "n       = nx**2     # total length of one image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9814a74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1000, 100)\n"
     ]
    }
   ],
   "source": [
    "# define forward operator with binary masks\n",
    "m  = mx * n\n",
    "\n",
    "M = np.random.randn(nx,nx,mx)\n",
    "M[M<0]=0\n",
    "M[M>0]=1\n",
    "\n",
    "MF   = MaskedFourier(M)\n",
    "print(MF.shape)\n",
    "Afun = lambda x : np.abs(MF@x)**2\n",
    "Ajac = lambda x : LinearOperator((m, n), matvec=lambda z : 2*(MF@x)*np.conj(MF@np.conj(z)), rmatvec=lambda z : 2*(MF.H@((MF@x)*z)))\n",
    "\n",
    "A    = Op(fun = Afun, jac = Ajac, shape=(m,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "013bb903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 10)\n",
      "(10, 100)\n",
      "<class 'scipy.sparse.linalg._interface._CustomLinearOperator'>\n",
      "<class 'scipy.sparse.linalg._interface._CustomLinearOperator'>\n",
      "(100,)\n",
      "(100, 110)\n",
      "(100,)\n",
      "(100, 110)\n",
      "(110, 100)\n"
     ]
    }
   ],
   "source": [
    "# get prior from decoder\n",
    "k               = latent_dim\n",
    "compute_jac     = jac_decoder_1D(autoencoder.decoder, latent_dim)\n",
    "block_identity  = lambda mat : np.concatenate((mat, np.eye(n)), axis=1)\n",
    "\n",
    "\n",
    "#define generative models\n",
    "I = Op(fun = lambda z : z, jac = lambda z: LinearOperator((n, n), matvec = lambda z : z, rmatvec = lambda z : z), shape=(n,n))\n",
    "\n",
    "G = Op(fun = lambda z : decoderfunc_1D(autoencoder.decoder, z), \n",
    "       jac = lambda z : LinearOperator((n,k), matvec = lambda v : compute_jac(z) @ v, rmatvec = lambda v : np.conj(compute_jac(z).T) @ v),\n",
    "       shape = (n,k))\n",
    "\n",
    "H = Op(fun = lambda z : decoderfunc_1D(autoencoder.decoder, z[:k]) + z[k:], \n",
    "       jac = lambda z : LinearOperator((n,k+n), matvec = lambda v : block_identity(compute_jac(z[:k])) @ v, rmatvec = lambda v : np.conj(block_identity(compute_jac(z[:k])).T) @ v),\n",
    "       shape = (n,k+n))\n",
    "\n",
    "# G = Op(fun = lambda z : decoderfunc_1D(autoencoder.decoder, z), \n",
    "#        jac = lambda z: (\n",
    "#                 lambda grads: LinearOperator(\n",
    "#                     (n, k),\n",
    "#                     matvec=lambda v: grads @ v,\n",
    "#                     rmatvec=lambda v: np.conj(grads.T) @ v\n",
    "#                 )\n",
    "#             )(decoderfun_1D(make_tensor_shape(z))[1].numpy()), \n",
    "#         shape = (n,k))\n",
    "\n",
    "# H = Op(fun = lambda z : (decoderfun_1D(make_tensor_shape(z[:,:k]))[0].numpy() + z[:,k:]).flatten(), \n",
    "#        jac = lambda z: (\n",
    "#                 lambda grads: LinearOperator(\n",
    "#                     (n, k+n),\n",
    "#                     matvec=lambda v: grads @ v,\n",
    "#                     rmatvec=lambda v: np.conj(grads.T) @ v\n",
    "#                 )\n",
    "#             )(np.concatenate((decoderfun_1D(make_tensor_shape(z[:,:k]))[1].numpy()[0], np.eye(n)), axis=1)),  \n",
    "#         shape=(n, k+n))\n",
    "\n",
    "\n",
    "#G = Op(fun = lambda z : decoderfun_1D(make_tensor(z))[0].numpy(),  \n",
    "       #jac = lambda z : LinearOperator((n, k), matvec = lambda x : decoderfun_1D(make_tensor(z))[1].numpy()@x, rmatvec = lambda y : np.conj(decoderfun_1D(make_tensor(z))[1].numpy().T)@y), shape=(n,k))\n",
    "#H = Op(fun = lambda z : mu + C@z, jac = lambda z : LinearOperator((n, k+n), matvec = lambda z : C@z, rmatvec = lambda z : np.conj(C.T)@z), shape=(n,k+n))\n",
    "\n",
    "# define weights\n",
    "w = 1\n",
    "\n",
    "# test\n",
    "z_testing = np.ones(10)\n",
    "x_testing = np.ones(100)\n",
    "y_testing = np.ones((1000))\n",
    "h_testing = np.ones((110))\n",
    "\n",
    "G_jac = G.jac(z_testing)\n",
    "G_H = G_jac.H\n",
    "\n",
    "print(G_jac.shape)\n",
    "print(G_H.shape)\n",
    "\n",
    "print(type(G_jac))\n",
    "print(type(G_H))\n",
    "\n",
    "G_jac@z_testing\n",
    "print((G_jac@z_testing).shape)\n",
    "\n",
    "H_test = block_identity(compute_jac(z_testing))\n",
    "\n",
    "print(H_test.shape)\n",
    "\n",
    "H_func = H.eval(h_testing)\n",
    "H_jac = H.jac(h_testing)\n",
    "H_H = H_jac.H\n",
    "\n",
    "print(H_func.shape)\n",
    "print(H_jac.shape)\n",
    "print(H_H.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86b296fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 64)\n",
      "(1, 64)\n",
      "(1, 784)\n",
      "(1, 28, 28)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x1d2a495e8b0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test going from 1D to 2D\n",
    "encoded_imgs = autoencoder.encoder(x_test).numpy()\n",
    "print(encoded_imgs.shape)\n",
    "\n",
    "one_test_img = np.zeros((1,latent_dim))\n",
    "one_test_img[0,:] = encoded_imgs[0,:]\n",
    "print(one_test_img.shape)\n",
    "\n",
    "test_G = G.eval(one_test_img)\n",
    "print(test_G.shape)\n",
    "restored = test_G.reshape((1,nx,nx))\n",
    "print(restored.shape)\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(restored[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "c6b4adc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 10)\n"
     ]
    }
   ],
   "source": [
    "xtrue = x_test_small[0].numpy()\n",
    "xtrue_1D = xtrue.reshape((1, -1))\n",
    "print(xtrue.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "6501943e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y (1000,)\n",
      "xc (100,)\n",
      "Dx (100, 10)\n",
      "yp (1000,)\n",
      "Dy (1000, 100)\n",
      "gradc (10,)\n",
      "grad (20,)\n"
     ]
    }
   ],
   "source": [
    "z = np.ones(k)\n",
    "w = 1\n",
    "lmbda = 0\n",
    "sigma = 0\n",
    "\n",
    "xtrue = x_test_small[0].numpy()\n",
    "xtrue_1D = xtrue.flatten()\n",
    "\n",
    "y = A.eval(xtrue_1D) + sigma*np.random.randn(m)\n",
    "\n",
    "#k  = len(z)//2\n",
    "#zc = z[:k] + 1j*z[k:]\n",
    "\n",
    "#print(\"zc\", zc.shape)\n",
    "\n",
    "print(\"y\", y.shape)\n",
    "\n",
    "xc = G.eval(z)\n",
    "Dx = G.jac(z)\n",
    "\n",
    "print(\"xc\", xc.shape)\n",
    "print(\"Dx\", Dx.shape)\n",
    "    \n",
    "yp = A.eval(xc)\n",
    "Dy = A.jac(xc)\n",
    "\n",
    "print(\"yp\", yp.shape)\n",
    "print(\"Dy\", Dy.shape)\n",
    "\n",
    "val    = (0.5)*np.linalg.norm(yp - y)**2 + (0.5*lmbda**2)*np.linalg.norm(w*zc)**2    \n",
    "gradc  = Dx.H@(Dy.H@(yp - y)) + (lmbda**2)*(w*w)*z\n",
    "\n",
    "print(\"gradc\", gradc.shape)\n",
    "    \n",
    "grad  = np.concatenate((np.real(gradc), np.imag(gradc)))\n",
    "\n",
    "print(\"grad\", grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a1fa354a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "xtrue (100,)\n",
      "yobs (1000,)\n",
      "k 110\n",
      "m 1000\n",
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\framework\\constant_op.py:108: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "WARNING: You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: You are casting an input of type complex128 to an incompatible dtype float32.  This will discard the imaginary part and may not be what you intended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x274d84b61f0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test with l2\n",
    "xtrue = x_test_small[0].numpy()\n",
    "plt.figure()\n",
    "plt.imshow(xtrue)\n",
    "\n",
    "xtrue_1D = xtrue.flatten()\n",
    "print(xtrue_1D.shape)\n",
    "\n",
    "error, xhat_corr, yobs = reconstruct(xtrue_1D, A, H, w=1, sigma=0, lmbda=0)\n",
    "\n",
    "xhat_corr = xhat_corr.reshape((nx,nx))\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.real(xhat_corr))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
