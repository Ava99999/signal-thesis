{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "e465fce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%load_ext autoreload\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import scipy\n",
    "import random\n",
    "import cmath\n",
    "#import pylops # might not need\n",
    "import math\n",
    "import pyproximal\n",
    "\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, losses\n",
    "from tensorflow.keras.datasets import fashion_mnist, mnist\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.saving import register_keras_serializable, deserialize_keras_object\n",
    "from tensorflow.test import compute_gradient\n",
    "from tensorflow.compat.v1 import assign_sub\n",
    "\n",
    "from scipy.sparse.linalg import LinearOperator\n",
    "from scipy.fft import fft, ifft, fft2, ifft2\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "import autosetup \n",
    "from backpropagation import CBP, CBP_decoder\n",
    "from complex_optimizer import Complex_SGD, adaptive_stepsize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6243d911",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version: 2.19.0\n"
     ]
    }
   ],
   "source": [
    "print(\"TensorFlow version:\", tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ed190db",
   "metadata": {},
   "source": [
    "Some nice tensorflow links\n",
    "https://www.tensorflow.org/guide/keras/making_new_layers_and_models_via_subclassing#putting_it_all_together_an_end-to-end_example \n",
    "https://www.tensorflow.org/guide/keras/functional_api\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Layer#used-in-the-notebooks\n",
    "https://www.tensorflow.org/api_docs/python/tf/keras/Layer#call"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64642c61",
   "metadata": {},
   "source": [
    "## Autoencoder ptygenography"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d00bbead",
   "metadata": {},
   "source": [
    "### Loading datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ae6f68b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first draft code from: https://www.tensorflow.org/tutorials/generative/autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "1653b30e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size training dataset:  (60000, 28, 28)\n",
      "Size testing dataset:  (10000, 28, 28)\n",
      "Size lower resolution training set:  (60000, 10, 10)\n",
      "Size lower resolution testing set:  (10000, 10, 10)\n",
      "Size of the complex and lower res training set:  (60000, 10, 10)\n",
      "Size complex lower resolution training set of only 3's:  (6131, 10, 10)\n",
      "Size complex lower resolution testing set of only 3's:  (1010, 10, 10)\n"
     ]
    }
   ],
   "source": [
    "## prep different datasets\n",
    "\n",
    "# original dataset\n",
    "(x_train, cls_train), (x_test, cls_test) = mnist.load_data()\n",
    "\n",
    "x_train = x_train.astype('float32') / 255. #normalize the data\n",
    "x_test = x_test.astype('float32') / 255.\n",
    "\n",
    "print(\"Size training dataset: \", x_train.shape)\n",
    "print(\"Size testing dataset: \", x_test.shape)\n",
    "\n",
    "# dataset of 10 x 10 pixels instead of 28 x 28\n",
    "x_train_temp = x_train[..., tf.newaxis]\n",
    "x_train_temp = tf.image.resize(x_train_temp, [10,10])\n",
    "x_train_small = x_train_temp[:,:,:,0]\n",
    "\n",
    "x_test_temp = x_test[..., tf.newaxis]\n",
    "x_test_temp = tf.image.resize(x_test_temp, [10,10])\n",
    "x_test_small = x_test_temp[:,:,:,0]\n",
    "\n",
    "print(\"Size lower resolution training set: \", x_train_small.shape)\n",
    "print(\"Size lower resolution testing set: \", x_test_small.shape)\n",
    "\n",
    "# dataset of 10 x 10 pixels as complex images\n",
    "x_train_cx_small = tf.complex(np.ones((x_train_small.shape)).astype('float32'), x_train_small)\n",
    "x_test_cx_small = tf.complex(np.ones((x_test_small.shape)).astype('float32'), x_test_small)\n",
    "\n",
    "print(\"Size of the complex and lower res training set: \",x_train_cx_small.shape)\n",
    "\n",
    "# filter dataset for 3's to 10 x 10 complex set\n",
    "#training\n",
    "x_train_3 = x_train[np.where(cls_train==3),:] \n",
    "x_train_3 = x_train_3.astype('float32')\n",
    "x_train_3 = tf.squeeze(x_train_3)\n",
    "\n",
    "x_train_temp = x_train_3[..., tf.newaxis]\n",
    "x_train_temp = tf.image.resize(x_train_temp, [10,10])\n",
    "x_train_3_small = x_train_temp[:,:,:,0]\n",
    "\n",
    "x_train_3_cx_small = tf.complex(np.ones((x_train_3_small.shape)).astype('float32'), x_train_3_small)\n",
    "\n",
    "print(\"Size complex lower resolution training set of only 3's: \", x_train_3_cx_small.shape)\n",
    "\n",
    "#testing\n",
    "x_test_3 = x_test[np.where(cls_test==3),:] \n",
    "x_test_3 = x_test_3.astype('float32')\n",
    "x_test_3 = tf.squeeze(x_test_3)\n",
    "\n",
    "x_test_temp = x_test_3[..., tf.newaxis]\n",
    "x_test_temp = tf.image.resize(x_test_temp, [10,10])\n",
    "x_test_3_small = x_test_temp[:,:,:,0]\n",
    "\n",
    "x_test_3_cx_small = tf.complex(np.ones((x_test_3_small.shape)).astype('float32'), x_test_3_small)\n",
    "\n",
    "print(\"Size complex lower resolution testing set of only 3's: \", x_test_3_cx_small.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "4dfeb2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## export\n",
    "export_train = x_train_3_cx_small.numpy()\n",
    "export_test = x_test_3_cx_small.numpy()\n",
    "\n",
    "np.save('MNIST_100_only3_train.npy', export_train)\n",
    "np.save('MNIST_100_only3_test.npy', export_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "135dc8a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape current dataset using:  (6131, 10, 10)\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "## set current dataset\n",
    "dataset = x_train_3_cx_small\n",
    "datatest = x_test_3_cx_small\n",
    "dataset_size = dataset[0]\n",
    "nx = dataset.shape[1]\n",
    "\n",
    "print(\"Shape current dataset using: \", dataset.shape)\n",
    "print(\"Length of side: \", nx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2a30b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load MNIST dataset from ptygenography instead\n",
    "X_pty = np.load('MNIST_64_only3.npy')\n",
    "n = X_pty.shape[1]\n",
    "nx = int(np.sqrt(n))\n",
    "print(X_pty.shape)\n",
    "\n",
    "X_tf = tf.convert_to_tensor(X_pty, dtype=tf.complex64)\n",
    "print(type(X_tf))\n",
    "print(X_tf.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "e3324ce2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# show the data\n",
    "ns = 5\n",
    "fig, ax = plt.subplots(2,ns)\n",
    "\n",
    "for i in range(ns):\n",
    "    x = dataset[i]\n",
    "    ax[0,i].imshow(np.real(x).reshape((nx,nx)),clim=[0,1])\n",
    "    ax[0,i].set_xticks([])\n",
    "    ax[0,i].set_yticks([])\n",
    "    ax[1,i].imshow(np.imag(x).reshape((nx,nx)),clim=[0,1])\n",
    "    ax[1,i].set_xticks([])\n",
    "    ax[1,i].set_yticks([])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2f5faaa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAnUAAACBCAYAAACma0xyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuNCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8ekN5oAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAHvUlEQVR4nO3df4zXdR0H8Pf37hAW3gFeNHfAqWREu2la/ippq2W/DiMXg2wuM6mla7UsauuPZg39o8wWzB8bZLlZW3M5ijValtUmga7+AUKFYqnnDh0pBKH8uPt+22G02mC9vgfnl+/r83j8c/zxPPbavT7bPfmwu1et0Wg0CgAAba2j1QMAAHDylDoAgASUOgCABJQ6AIAElDoAgASUOgCABJQ6AIAEuiKher1ehoeHS3d3d6nVahM/FafE2K8g3L9/f+nr6ysdHc31dztvT3ZePXZePXZePY3gzkOlbuwBmDNnzqmcj9fQ0NBQmT17dlOfY+ftzc6rx86rx86rZ+j/7DxU6sYa/ZgFZbB0lUmnbjom1Eg5UjaU9f/ZXzPsvD3ZefXYefXYefWMBHceKnXHXtGOPQBdNQ9B2/j3AbjxvGK38zZl59Vj59Vj59XTiO3cD0oAACSg1AEAJKDUAQAkoNQBACSg1AEAJKDUAQAkoNQBACSg1AEAJBD65cOQTefAm8PZpz47PZx90xceH+dEAHByvKkDAEhAqQMASECpAwBIQKkDAEhAqQMASECpAwBIQKkDAEhAqQMASECpAwBIQKkDAEig5WfCOmfMCGf/cvc54exXLn44nP1Uz1A4e93f3h/Obt3VF87OXb43nB15Jj5vpVx2QTi6du0PwtnBJxeHs0Nff2c4O2fFxtLODiy+PJyd+lDe82m718VPzs1ctH1CZ2H83rXlYDj74+2XhrP9S7aOcyLGc9Zxxw1nhbPnrYvvfNITz4Szoy++VFrFmzoAgASUOgCABJQ6AIAElDoAgASUOgCABJQ6AIAElDoAgASUOgCABJQ6AIAElDoAgARafiZsdM+ecHby5reEsx9esCOcvXrWgnC2c+D14Wz/tvh5mJFwsmKuuDAcXfvT74ezb7v7i+Fsz9P1cHbFN34Uzq5eMbe0swPX/yOcnfpQSWvm1AOtHoET2HPDO8LZxT13hrOPLpkyzok45vAH46fWbl71YDj7w4sGwtnvPPFIOHvLx28KZ2ubnAkDAOAkKHUAAAkodQAACSh1AAAJKHUAAAkodQAACSh1AAAJKHUAAAkodQAACSh1AAAJtPxMWDNmfWtjOPuZDy0JZ7vOnRTOjmzbHs5yfB1T4id21jx4Tzi75JLF4ezs5+PPUjMW3RE/e7e6tLfbBn4Wzq4q80vL1Wrh6M47Lg9nz/h9/N/Gc8pz4SzHV+uKf9v69W3fDWevHbyxiSmeaiJbHf9cekU4+8lvrgtn75t3Xji7++a3hrMfffz8cPbcTZtLO/CmDgAgAaUOACABpQ4AIAGlDgAgAaUOACABpQ4AIAGlDgAgAaUOACABpQ4AIAGlDgAggbY6E9aMI+/eFc7WfjsrnH3p5Xnh7FlX7whnq2Tn/fGv4TUrLg5ne5/fNM6JGI+D9TPC2WkbesPZL/U9HM7urb8unL3lgWXh7MyBF8LZnoVPh7OcvDv/+mg4O/jn68LZM7c4/XWyXrgsnp0/eTicvf/Z+PfS7o7HwtnF/VeWbLypAwBIQKkDAEhAqQMASECpAwBIQKkDAEhAqQMASECpAwBIQKkDAEhAqQMASECpAwBIIO2ZsGbs/kl/OPvYrXeFsx/peU84O7pvX6mK6d2vhLMz1mwprdbMiauFS24MZ2tlc2lnq+fNbSL9Yjh5a3l7mQj9ZWM4+9WdW8PZb9cvGOdEHHPkqvjO+zrje+y5Jn6Kqh5OciJvXB4/0XX78ovC2Y4pU8LZdTv/EM6W+mjJxps6AIAElDoAgASUOgCABJQ6AIAElDoAgASUOgCABJQ6AIAElDoAgASUOgCABJQ6AIAE2upM2KHBS8PZe+9ZGc4Oj8ZPAr3v0zeFs5P3/TGc5fg6f9cXzu47FD8l87Xz14ezK6//WDhb29jep7+gFRatfCScvXbH0vhffPC58Q3E6aWzs9UTtA1v6gAAElDqAAASUOoAABJQ6gAAElDqAAASUOoAABJQ6gAAElDqAAASUOoAABJQ6gAAEpiQM2GHP3BJOPvAmu+Fs795eTic/cTtXw5ne9dsCmcnF6e/Tlbv0vgeD/28N5w98Iuzw9lVd80PZ2vF6a+q2Ts6tdUjVMrgmdvC2V++d/qEzsLpp37gQDj799FXwtlaV7wCNUZGSjvwpg4AIAGlDgAgAaUOACABpQ4AIAGlDgAgAaUOACABpQ4AIAGlDgAgAaUOACABpQ4AIIEJORN2xq/+FM4u618wESOU3hI//cXpe/Kl66p49g3l2XFOBP9r9by5rR6hUj5/zpWtHoEkll24MJzd9bmBcPbslRtLO/CmDgAgAaUOACABpQ4AIAGlDgAgAaUOACABpQ4AIAGlDgAgAaUOACABpQ4AoCoXJRqNxtGPI+VIKa/+kTZwdF//tb9m2Hl7svPqsfPqsfMTazQOh7Ojhw6GsyONV7/mp/vOQ6Vu//79Rz9uKOtPxWy8xsb2N23atKY/Z4ydtyc7rx47rx47P469TWTvjUefLO2x81ojUPXr9XoZHh4u3d3dpVarneoZmSBjqx17APr6+kpHR3P/027n7cnOq8fOq8fOq6cR3Hmo1AEAcHrzgxIAAAkodQAACSh1AAAJKHUAAAkodQAACSh1AAAJKHUAAKX9/QsOwQx6ri2IKgAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 640x480 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# representation training dataset (real case)\n",
    "ns = 5\n",
    "fig, ax = plt.subplots(1,ns)\n",
    "\n",
    "for i in range(ns):\n",
    "    x = x_train_small[i]\n",
    "    ax[i].imshow(np.real(x).reshape((10,10)),clim=[0,1])\n",
    "    ax[i].set_xticks([])\n",
    "    ax[i].set_yticks([])\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "acad1eab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ns = 5\n",
    "fig, ax = plt.subplots(2,ns)\n",
    "\n",
    "for i in range(ns):\n",
    "    x = x_train_cx_small[i]\n",
    "    ax[0,i].imshow(np.real(x).reshape((10,10)),clim=[0,1], cmap= 'viridis')\n",
    "    ax[0,i].set_xticks([])\n",
    "    ax[0,i].set_yticks([])\n",
    "    ax[1,i].imshow(np.imag(x).reshape((10,10)),clim=[0,1], cmap='viridis')\n",
    "    ax[1,i].set_xticks([])\n",
    "    ax[1,i].set_yticks([])\n",
    "fig.tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12ea2bf",
   "metadata": {},
   "source": [
    "### Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "846f4edb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of epochs 50\n",
      "Dataset size:  6131\n",
      "Dimension of one sample:  100\n",
      "Latent dimension:  10\n"
     ]
    }
   ],
   "source": [
    "## parameters relevant to training\n",
    "EPOCHS = 50\n",
    "dataset_size = dataset.shape[0]\n",
    "reshape_dataset = tf.reshape(dataset, (dataset_size,-1))\n",
    "sample_shape = reshape_dataset.shape[-1] # data dimension\n",
    "nx = int(np.sqrt(sample_shape)) # one side of the 2D image\n",
    "latent_dim = 10 # reduction of data \n",
    "\n",
    "print(\"Number of epochs\", EPOCHS)\n",
    "print(\"Dataset size: \", dataset_size)\n",
    "print(\"Dimension of one sample: \", sample_shape)\n",
    "print(\"Latent dimension: \", latent_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "481a9dac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrapper for training\n",
    "@tf.function\n",
    "def train_step(x, alpha, encoder, decoder, optimizer):\n",
    "    y = decoder(encoder(x))\n",
    "    loss_value = autosetup.loss_MSE(y, x)\n",
    "    grads_and_vars = CBP(x, y, encoder, decoder, autosetup.dLossdaL, autosetup.Jac_modrelu)\n",
    "    new_alpha = adaptive_stepsize(x, y, alpha, encoder, decoder, autosetup.loss_MSE, grads_and_vars)\n",
    "    _ = optimizer.apply_gradients(grads_and_vars, alpha = alpha)\n",
    "    return loss_value, new_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "78244d5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'tensorflow.python.data.ops.batch_op._BatchDataset'>\n",
      "\n",
      "Start of epoch 1\n",
      "Training loss (for one sample) at sample 613: 13.6847\n",
      "Training loss (for one sample) at sample 1226: 12.1149\n",
      "Training loss (for one sample) at sample 1839: 7.5868\n",
      "Training loss (for one sample) at sample 2452: 4.9213\n",
      "Training loss (for one sample) at sample 3065: 8.7666\n",
      "Training loss (for one sample) at sample 3678: 4.1126\n",
      "Training loss (for one sample) at sample 4291: 2.6608\n",
      "Training loss (for one sample) at sample 4904: 3.0486\n",
      "Training loss (for one sample) at sample 5517: 4.1503\n",
      "Training loss (for one sample) at sample 6130: 3.2792\n",
      "Epoch 1 | Loss: 9.69450\n",
      "Time taken: 11.79s\n",
      "\n",
      "Start of epoch 2\n",
      "Training loss (for one sample) at sample 613: 5.0238\n",
      "Training loss (for one sample) at sample 1226: 3.4438\n",
      "Training loss (for one sample) at sample 1839: 5.8705\n",
      "Training loss (for one sample) at sample 2452: 3.1020\n",
      "Training loss (for one sample) at sample 3065: 2.3332\n",
      "Training loss (for one sample) at sample 3678: 5.8027\n",
      "Training loss (for one sample) at sample 4291: 5.4897\n",
      "Training loss (for one sample) at sample 4904: 5.3863\n",
      "Training loss (for one sample) at sample 5517: 5.0580\n",
      "Training loss (for one sample) at sample 6130: 3.4281\n",
      "Epoch 2 | Loss: 4.40644\n",
      "Time taken: 10.14s\n",
      "\n",
      "Start of epoch 3\n",
      "Training loss (for one sample) at sample 613: 5.8890\n",
      "Training loss (for one sample) at sample 1226: 2.8052\n",
      "Training loss (for one sample) at sample 1839: 3.0309\n",
      "Training loss (for one sample) at sample 2452: 5.1285\n",
      "Training loss (for one sample) at sample 3065: 2.9544\n",
      "Training loss (for one sample) at sample 3678: 2.6009\n",
      "Training loss (for one sample) at sample 4291: 6.3106\n",
      "Training loss (for one sample) at sample 4904: 2.2314\n",
      "Training loss (for one sample) at sample 5517: 5.2224\n",
      "Training loss (for one sample) at sample 6130: 2.7941\n",
      "Epoch 3 | Loss: 3.78803\n",
      "Time taken: 10.44s\n",
      "\n",
      "Start of epoch 4\n",
      "Training loss (for one sample) at sample 613: 4.0666\n",
      "Training loss (for one sample) at sample 1226: 1.5293\n",
      "Training loss (for one sample) at sample 1839: 2.8166\n",
      "Training loss (for one sample) at sample 2452: 2.5564\n",
      "Training loss (for one sample) at sample 3065: 2.8164\n",
      "Training loss (for one sample) at sample 3678: 2.0524\n",
      "Training loss (for one sample) at sample 4291: 3.9415\n",
      "Training loss (for one sample) at sample 4904: 3.4866\n",
      "Training loss (for one sample) at sample 5517: 3.0425\n",
      "Training loss (for one sample) at sample 6130: 5.4131\n",
      "Epoch 4 | Loss: 3.32136\n",
      "Time taken: 10.03s\n",
      "\n",
      "Start of epoch 5\n",
      "Training loss (for one sample) at sample 613: 2.4571\n",
      "Training loss (for one sample) at sample 1226: 2.9928\n",
      "Training loss (for one sample) at sample 1839: 3.7464\n",
      "Training loss (for one sample) at sample 2452: 2.3260\n",
      "Training loss (for one sample) at sample 3065: 3.9782\n",
      "Training loss (for one sample) at sample 3678: 1.7764\n",
      "Training loss (for one sample) at sample 4291: 2.7335\n",
      "Training loss (for one sample) at sample 4904: 2.0619\n",
      "Training loss (for one sample) at sample 5517: 3.3113\n",
      "Training loss (for one sample) at sample 6130: 6.0883\n",
      "Epoch 5 | Loss: 2.98422\n",
      "Time taken: 9.95s\n",
      "\n",
      "Start of epoch 6\n",
      "Training loss (for one sample) at sample 613: 5.2378\n",
      "Training loss (for one sample) at sample 1226: 1.8433\n",
      "Training loss (for one sample) at sample 1839: 3.0708\n",
      "Training loss (for one sample) at sample 2452: 2.6670\n",
      "Training loss (for one sample) at sample 3065: 1.8577\n",
      "Training loss (for one sample) at sample 3678: 1.6376\n",
      "Training loss (for one sample) at sample 4291: 3.3593\n",
      "Training loss (for one sample) at sample 4904: 3.0630\n",
      "Training loss (for one sample) at sample 5517: 1.3874\n",
      "Training loss (for one sample) at sample 6130: 2.6380\n",
      "Epoch 6 | Loss: 2.74323\n",
      "Time taken: 10.11s\n",
      "\n",
      "Start of epoch 7\n",
      "Training loss (for one sample) at sample 613: 2.8408\n",
      "Training loss (for one sample) at sample 1226: 1.5869\n",
      "Training loss (for one sample) at sample 1839: 1.9573\n",
      "Training loss (for one sample) at sample 2452: 3.2504\n",
      "Training loss (for one sample) at sample 3065: 1.1112\n",
      "Training loss (for one sample) at sample 3678: 1.7223\n",
      "Training loss (for one sample) at sample 4291: 1.8551\n",
      "Training loss (for one sample) at sample 4904: 3.9735\n",
      "Training loss (for one sample) at sample 5517: 2.4211\n",
      "Training loss (for one sample) at sample 6130: 3.4129\n",
      "Epoch 7 | Loss: 2.56307\n",
      "Time taken: 9.96s\n",
      "\n",
      "Start of epoch 8\n",
      "Training loss (for one sample) at sample 613: 2.8831\n",
      "Training loss (for one sample) at sample 1226: 1.8138\n",
      "Training loss (for one sample) at sample 1839: 2.0988\n",
      "Training loss (for one sample) at sample 2452: 2.7999\n",
      "Training loss (for one sample) at sample 3065: 4.1827\n",
      "Training loss (for one sample) at sample 3678: 1.4492\n",
      "Training loss (for one sample) at sample 4291: 1.9993\n",
      "Training loss (for one sample) at sample 4904: 0.7085\n",
      "Training loss (for one sample) at sample 5517: 2.5269\n",
      "Training loss (for one sample) at sample 6130: 0.9517\n",
      "Epoch 8 | Loss: 2.41650\n",
      "Time taken: 10.05s\n",
      "\n",
      "Start of epoch 9\n",
      "Training loss (for one sample) at sample 613: 2.8525\n",
      "Training loss (for one sample) at sample 1226: 2.0778\n",
      "Training loss (for one sample) at sample 1839: 1.2461\n",
      "Training loss (for one sample) at sample 2452: 1.9041\n",
      "Training loss (for one sample) at sample 3065: 1.3366\n",
      "Training loss (for one sample) at sample 3678: 1.2843\n",
      "Training loss (for one sample) at sample 4291: 1.8915\n",
      "Training loss (for one sample) at sample 4904: 1.4990\n",
      "Training loss (for one sample) at sample 5517: 1.8770\n",
      "Training loss (for one sample) at sample 6130: 3.3489\n",
      "Epoch 9 | Loss: 2.29482\n",
      "Time taken: 10.26s\n",
      "\n",
      "Start of epoch 10\n",
      "Training loss (for one sample) at sample 613: 1.8708\n",
      "Training loss (for one sample) at sample 1226: 1.2088\n",
      "Training loss (for one sample) at sample 1839: 1.6028\n",
      "Training loss (for one sample) at sample 2452: 1.4761\n",
      "Training loss (for one sample) at sample 3065: 3.8949\n",
      "Training loss (for one sample) at sample 3678: 1.4088\n",
      "Training loss (for one sample) at sample 4291: 2.4146\n",
      "Training loss (for one sample) at sample 4904: 1.7248\n",
      "Training loss (for one sample) at sample 5517: 2.0055\n",
      "Training loss (for one sample) at sample 6130: 2.9309\n",
      "Epoch 10 | Loss: 2.18725\n",
      "Time taken: 10.22s\n",
      "\n",
      "Start of epoch 11\n",
      "Training loss (for one sample) at sample 613: 0.6532\n",
      "Training loss (for one sample) at sample 1226: 2.5608\n",
      "Training loss (for one sample) at sample 1839: 3.2719\n",
      "Training loss (for one sample) at sample 2452: 1.5428\n",
      "Training loss (for one sample) at sample 3065: 3.9150\n",
      "Training loss (for one sample) at sample 3678: 3.5296\n",
      "Training loss (for one sample) at sample 4291: 1.2903\n",
      "Training loss (for one sample) at sample 4904: 2.3960\n",
      "Training loss (for one sample) at sample 5517: 4.6160\n",
      "Training loss (for one sample) at sample 6130: 1.6565\n",
      "Epoch 11 | Loss: 2.08937\n",
      "Time taken: 9.96s\n",
      "\n",
      "Start of epoch 12\n",
      "Training loss (for one sample) at sample 613: 2.0895\n",
      "Training loss (for one sample) at sample 1226: 0.8300\n",
      "Training loss (for one sample) at sample 1839: 1.7162\n",
      "Training loss (for one sample) at sample 2452: 1.5811\n",
      "Training loss (for one sample) at sample 3065: 1.5209\n",
      "Training loss (for one sample) at sample 3678: 1.1291\n",
      "Training loss (for one sample) at sample 4291: 2.8167\n",
      "Training loss (for one sample) at sample 4904: 1.2813\n",
      "Training loss (for one sample) at sample 5517: 1.1721\n",
      "Training loss (for one sample) at sample 6130: 1.8369\n",
      "Epoch 12 | Loss: 1.99922\n",
      "Time taken: 10.18s\n",
      "\n",
      "Start of epoch 13\n",
      "Training loss (for one sample) at sample 613: 1.3847\n",
      "Training loss (for one sample) at sample 1226: 2.6937\n",
      "Training loss (for one sample) at sample 1839: 2.0429\n",
      "Training loss (for one sample) at sample 2452: 1.8547\n",
      "Training loss (for one sample) at sample 3065: 3.5500\n",
      "Training loss (for one sample) at sample 3678: 1.7821\n",
      "Training loss (for one sample) at sample 4291: 2.1462\n",
      "Training loss (for one sample) at sample 4904: 2.9860\n",
      "Training loss (for one sample) at sample 5517: 2.4072\n",
      "Training loss (for one sample) at sample 6130: 2.7419\n",
      "Epoch 13 | Loss: 1.91882\n",
      "Time taken: 10.01s\n",
      "\n",
      "Start of epoch 14\n",
      "Training loss (for one sample) at sample 613: 1.6977\n",
      "Training loss (for one sample) at sample 1226: 1.9324\n",
      "Training loss (for one sample) at sample 1839: 3.6912\n",
      "Training loss (for one sample) at sample 2452: 2.5146\n",
      "Training loss (for one sample) at sample 3065: 0.7964\n",
      "Training loss (for one sample) at sample 3678: 2.4326\n",
      "Training loss (for one sample) at sample 4291: 1.1086\n",
      "Training loss (for one sample) at sample 4904: 4.3972\n",
      "Training loss (for one sample) at sample 5517: 1.5959\n",
      "Training loss (for one sample) at sample 6130: 1.5470\n",
      "Epoch 14 | Loss: 1.84748\n",
      "Time taken: 9.98s\n",
      "\n",
      "Start of epoch 15\n",
      "Training loss (for one sample) at sample 613: 1.3547\n",
      "Training loss (for one sample) at sample 1226: 2.5899\n",
      "Training loss (for one sample) at sample 1839: 0.9750\n",
      "Training loss (for one sample) at sample 2452: 1.5880\n",
      "Training loss (for one sample) at sample 3065: 2.2051\n",
      "Training loss (for one sample) at sample 3678: 1.8157\n",
      "Training loss (for one sample) at sample 4291: 2.6323\n",
      "Training loss (for one sample) at sample 4904: 0.9965\n",
      "Training loss (for one sample) at sample 5517: 1.4854\n",
      "Training loss (for one sample) at sample 6130: 1.0603\n",
      "Epoch 15 | Loss: 1.78324\n",
      "Time taken: 10.00s\n",
      "\n",
      "Start of epoch 16\n",
      "Training loss (for one sample) at sample 613: 2.1088\n",
      "Training loss (for one sample) at sample 1226: 1.0818\n",
      "Training loss (for one sample) at sample 1839: 2.2971\n",
      "Training loss (for one sample) at sample 2452: 1.8731\n",
      "Training loss (for one sample) at sample 3065: 1.8900\n",
      "Training loss (for one sample) at sample 3678: 0.9134\n",
      "Training loss (for one sample) at sample 4291: 1.6755\n",
      "Training loss (for one sample) at sample 4904: 1.3940\n",
      "Training loss (for one sample) at sample 5517: 2.7841\n",
      "Training loss (for one sample) at sample 6130: 1.0497\n",
      "Epoch 16 | Loss: 1.72514\n",
      "Time taken: 10.10s\n",
      "\n",
      "Start of epoch 17\n",
      "Training loss (for one sample) at sample 613: 1.2822\n",
      "Training loss (for one sample) at sample 1226: 2.6795\n",
      "Training loss (for one sample) at sample 1839: 1.2381\n",
      "Training loss (for one sample) at sample 2452: 2.5083\n",
      "Training loss (for one sample) at sample 3065: 1.3958\n",
      "Training loss (for one sample) at sample 3678: 1.3020\n",
      "Training loss (for one sample) at sample 4291: 0.8691\n",
      "Training loss (for one sample) at sample 4904: 3.4327\n",
      "Training loss (for one sample) at sample 5517: 1.8058\n",
      "Training loss (for one sample) at sample 6130: 1.4232\n",
      "Epoch 17 | Loss: 1.67382\n",
      "Time taken: 10.05s\n",
      "\n",
      "Start of epoch 18\n",
      "Training loss (for one sample) at sample 613: 2.3208\n",
      "Training loss (for one sample) at sample 1226: 3.4445\n",
      "Training loss (for one sample) at sample 1839: 0.7333\n",
      "Training loss (for one sample) at sample 2452: 0.6695\n",
      "Training loss (for one sample) at sample 3065: 1.0201\n",
      "Training loss (for one sample) at sample 3678: 1.7512\n",
      "Training loss (for one sample) at sample 4291: 1.8352\n",
      "Training loss (for one sample) at sample 4904: 1.3797\n",
      "Training loss (for one sample) at sample 5517: 1.6353\n",
      "Training loss (for one sample) at sample 6130: 0.8743\n",
      "Epoch 18 | Loss: 1.62699\n",
      "Time taken: 10.08s\n",
      "\n",
      "Start of epoch 19\n",
      "Training loss (for one sample) at sample 613: 1.3140\n",
      "Training loss (for one sample) at sample 1226: 1.0657\n",
      "Training loss (for one sample) at sample 1839: 0.6764\n",
      "Training loss (for one sample) at sample 2452: 1.2596\n",
      "Training loss (for one sample) at sample 3065: 0.8900\n",
      "Training loss (for one sample) at sample 3678: 0.6455\n",
      "Training loss (for one sample) at sample 4291: 1.1227\n",
      "Training loss (for one sample) at sample 4904: 2.0213\n",
      "Training loss (for one sample) at sample 5517: 1.0357\n",
      "Training loss (for one sample) at sample 6130: 4.1226\n",
      "Epoch 19 | Loss: 1.58565\n",
      "Time taken: 10.03s\n",
      "\n",
      "Start of epoch 20\n",
      "Training loss (for one sample) at sample 613: 1.2054\n",
      "Training loss (for one sample) at sample 1226: 1.8195\n",
      "Training loss (for one sample) at sample 1839: 2.3818\n",
      "Training loss (for one sample) at sample 2452: 1.0106\n",
      "Training loss (for one sample) at sample 3065: 1.6857\n",
      "Training loss (for one sample) at sample 3678: 1.4668\n",
      "Training loss (for one sample) at sample 4291: 1.5889\n",
      "Training loss (for one sample) at sample 4904: 1.2747\n",
      "Training loss (for one sample) at sample 5517: 1.1851\n",
      "Training loss (for one sample) at sample 6130: 1.7240\n",
      "Epoch 20 | Loss: 1.54799\n",
      "Time taken: 9.93s\n",
      "\n",
      "Start of epoch 21\n",
      "Training loss (for one sample) at sample 613: 1.3881\n",
      "Training loss (for one sample) at sample 1226: 1.3070\n",
      "Training loss (for one sample) at sample 1839: 1.2895\n",
      "Training loss (for one sample) at sample 2452: 1.0821\n",
      "Training loss (for one sample) at sample 3065: 1.1473\n",
      "Training loss (for one sample) at sample 3678: 1.6019\n",
      "Training loss (for one sample) at sample 4291: 0.9387\n",
      "Training loss (for one sample) at sample 4904: 1.4068\n",
      "Training loss (for one sample) at sample 5517: 2.9309\n",
      "Training loss (for one sample) at sample 6130: 0.5832\n",
      "Epoch 21 | Loss: 1.51198\n",
      "Time taken: 10.00s\n",
      "\n",
      "Start of epoch 22\n",
      "Training loss (for one sample) at sample 613: 1.3103\n",
      "Training loss (for one sample) at sample 1226: 0.3396\n",
      "Training loss (for one sample) at sample 1839: 2.8594\n",
      "Training loss (for one sample) at sample 2452: 0.8238\n",
      "Training loss (for one sample) at sample 3065: 3.5483\n",
      "Training loss (for one sample) at sample 3678: 1.8795\n",
      "Training loss (for one sample) at sample 4291: 0.7435\n",
      "Training loss (for one sample) at sample 4904: 1.2344\n",
      "Training loss (for one sample) at sample 5517: 1.6395\n",
      "Training loss (for one sample) at sample 6130: 1.5352\n",
      "Epoch 22 | Loss: 1.48033\n",
      "Time taken: 10.01s\n",
      "\n",
      "Start of epoch 23\n",
      "Training loss (for one sample) at sample 613: 0.8790\n",
      "Training loss (for one sample) at sample 1226: 1.9733\n",
      "Training loss (for one sample) at sample 1839: 1.7434\n",
      "Training loss (for one sample) at sample 2452: 1.1767\n",
      "Training loss (for one sample) at sample 3065: 1.9356\n",
      "Training loss (for one sample) at sample 3678: 1.1350\n",
      "Training loss (for one sample) at sample 4291: 1.0954\n",
      "Training loss (for one sample) at sample 4904: 1.7573\n",
      "Training loss (for one sample) at sample 5517: 0.5566\n",
      "Training loss (for one sample) at sample 6130: 1.6785\n",
      "Epoch 23 | Loss: 1.45051\n",
      "Time taken: 9.96s\n",
      "\n",
      "Start of epoch 24\n",
      "Training loss (for one sample) at sample 613: 1.3446\n",
      "Training loss (for one sample) at sample 1226: 2.1373\n",
      "Training loss (for one sample) at sample 1839: 2.2518\n",
      "Training loss (for one sample) at sample 2452: 1.5128\n",
      "Training loss (for one sample) at sample 3065: 1.8719\n",
      "Training loss (for one sample) at sample 3678: 0.9313\n",
      "Training loss (for one sample) at sample 4291: 0.9739\n",
      "Training loss (for one sample) at sample 4904: 1.2312\n",
      "Training loss (for one sample) at sample 5517: 0.5759\n",
      "Training loss (for one sample) at sample 6130: 1.1631\n",
      "Epoch 24 | Loss: 1.42254\n",
      "Time taken: 9.93s\n",
      "\n",
      "Start of epoch 25\n",
      "Training loss (for one sample) at sample 613: 1.1941\n",
      "Training loss (for one sample) at sample 1226: 1.7753\n",
      "Training loss (for one sample) at sample 1839: 1.4470\n",
      "Training loss (for one sample) at sample 2452: 1.0292\n",
      "Training loss (for one sample) at sample 3065: 1.4380\n",
      "Training loss (for one sample) at sample 3678: 1.1014\n",
      "Training loss (for one sample) at sample 4291: 1.6513\n",
      "Training loss (for one sample) at sample 4904: 1.7526\n",
      "Training loss (for one sample) at sample 5517: 0.6352\n",
      "Training loss (for one sample) at sample 6130: 1.6927\n",
      "Epoch 25 | Loss: 1.39567\n",
      "Time taken: 9.96s\n",
      "\n",
      "Start of epoch 26\n",
      "Training loss (for one sample) at sample 613: 1.0576\n",
      "Training loss (for one sample) at sample 1226: 0.3635\n",
      "Training loss (for one sample) at sample 1839: 1.4991\n",
      "Training loss (for one sample) at sample 2452: 1.0619\n",
      "Training loss (for one sample) at sample 3065: 0.9487\n",
      "Training loss (for one sample) at sample 3678: 1.2294\n",
      "Training loss (for one sample) at sample 4291: 0.9284\n",
      "Training loss (for one sample) at sample 4904: 1.3949\n",
      "Training loss (for one sample) at sample 5517: 2.8230\n",
      "Training loss (for one sample) at sample 6130: 0.3750\n",
      "Epoch 26 | Loss: 1.37048\n",
      "Time taken: 9.90s\n",
      "\n",
      "Start of epoch 27\n",
      "Training loss (for one sample) at sample 613: 1.3752\n",
      "Training loss (for one sample) at sample 1226: 1.1073\n",
      "Training loss (for one sample) at sample 1839: 1.3378\n",
      "Training loss (for one sample) at sample 2452: 0.5662\n",
      "Training loss (for one sample) at sample 3065: 2.7416\n",
      "Training loss (for one sample) at sample 3678: 1.6792\n",
      "Training loss (for one sample) at sample 4291: 1.2700\n",
      "Training loss (for one sample) at sample 4904: 1.6100\n",
      "Training loss (for one sample) at sample 5517: 0.6453\n",
      "Training loss (for one sample) at sample 6130: 1.3098\n",
      "Epoch 27 | Loss: 1.34688\n",
      "Time taken: 10.13s\n",
      "\n",
      "Start of epoch 28\n",
      "Training loss (for one sample) at sample 613: 0.4698\n",
      "Training loss (for one sample) at sample 1226: 1.3847\n",
      "Training loss (for one sample) at sample 1839: 1.7380\n",
      "Training loss (for one sample) at sample 2452: 2.3420\n",
      "Training loss (for one sample) at sample 3065: 0.9285\n",
      "Training loss (for one sample) at sample 3678: 0.8020\n",
      "Training loss (for one sample) at sample 4291: 2.0834\n",
      "Training loss (for one sample) at sample 4904: 1.7350\n",
      "Training loss (for one sample) at sample 5517: 1.2907\n",
      "Training loss (for one sample) at sample 6130: 1.3768\n",
      "Epoch 28 | Loss: 1.32357\n",
      "Time taken: 9.98s\n",
      "\n",
      "Start of epoch 29\n",
      "Training loss (for one sample) at sample 613: 0.4897\n",
      "Training loss (for one sample) at sample 1226: 0.5951\n",
      "Training loss (for one sample) at sample 1839: 0.5947\n",
      "Training loss (for one sample) at sample 2452: 0.5728\n",
      "Training loss (for one sample) at sample 3065: 2.4756\n",
      "Training loss (for one sample) at sample 3678: 0.8097\n",
      "Training loss (for one sample) at sample 4291: 0.6056\n",
      "Training loss (for one sample) at sample 4904: 2.1861\n",
      "Training loss (for one sample) at sample 5517: 1.3079\n",
      "Training loss (for one sample) at sample 6130: 3.2491\n",
      "Epoch 29 | Loss: 1.30251\n",
      "Time taken: 9.96s\n",
      "\n",
      "Start of epoch 30\n",
      "Training loss (for one sample) at sample 613: 0.8132\n",
      "Training loss (for one sample) at sample 1226: 0.8916\n",
      "Training loss (for one sample) at sample 1839: 1.5986\n",
      "Training loss (for one sample) at sample 2452: 1.2759\n",
      "Training loss (for one sample) at sample 3065: 2.0810\n",
      "Training loss (for one sample) at sample 3678: 1.0682\n",
      "Training loss (for one sample) at sample 4291: 0.4390\n",
      "Training loss (for one sample) at sample 4904: 1.4786\n",
      "Training loss (for one sample) at sample 5517: 0.3127\n",
      "Training loss (for one sample) at sample 6130: 1.9796\n",
      "Epoch 30 | Loss: 1.28186\n",
      "Time taken: 10.07s\n",
      "\n",
      "Start of epoch 31\n",
      "Training loss (for one sample) at sample 613: 1.2531\n",
      "Training loss (for one sample) at sample 1226: 0.8996\n",
      "Training loss (for one sample) at sample 1839: 0.6546\n",
      "Training loss (for one sample) at sample 2452: 0.3333\n",
      "Training loss (for one sample) at sample 3065: 1.1064\n",
      "Training loss (for one sample) at sample 3678: 0.4395\n",
      "Training loss (for one sample) at sample 4291: 1.3244\n",
      "Training loss (for one sample) at sample 4904: 0.9330\n",
      "Training loss (for one sample) at sample 5517: 1.7044\n",
      "Training loss (for one sample) at sample 6130: 1.7288\n",
      "Epoch 31 | Loss: 1.26204\n",
      "Time taken: 9.96s\n",
      "\n",
      "Start of epoch 32\n",
      "Training loss (for one sample) at sample 613: 1.0885\n",
      "Training loss (for one sample) at sample 1226: 1.4011\n",
      "Training loss (for one sample) at sample 1839: 2.9565\n",
      "Training loss (for one sample) at sample 2452: 0.8123\n",
      "Training loss (for one sample) at sample 3065: 2.1557\n",
      "Training loss (for one sample) at sample 3678: 0.7754\n",
      "Training loss (for one sample) at sample 4291: 1.2461\n",
      "Training loss (for one sample) at sample 4904: 1.6251\n",
      "Training loss (for one sample) at sample 5517: 0.6681\n",
      "Training loss (for one sample) at sample 6130: 0.8063\n",
      "Epoch 32 | Loss: 1.24349\n",
      "Time taken: 9.90s\n",
      "\n",
      "Start of epoch 33\n",
      "Training loss (for one sample) at sample 613: 0.5828\n",
      "Training loss (for one sample) at sample 1226: 1.2420\n",
      "Training loss (for one sample) at sample 1839: 0.9008\n",
      "Training loss (for one sample) at sample 2452: 0.9653\n",
      "Training loss (for one sample) at sample 3065: 0.6090\n",
      "Training loss (for one sample) at sample 3678: 0.8414\n",
      "Training loss (for one sample) at sample 4291: 2.2287\n",
      "Training loss (for one sample) at sample 4904: 0.3275\n",
      "Training loss (for one sample) at sample 5517: 3.3170\n",
      "Training loss (for one sample) at sample 6130: 1.1108\n",
      "Epoch 33 | Loss: 1.22588\n",
      "Time taken: 10.01s\n",
      "\n",
      "Start of epoch 34\n",
      "Training loss (for one sample) at sample 613: 2.0499\n",
      "Training loss (for one sample) at sample 1226: 0.7279\n",
      "Training loss (for one sample) at sample 1839: 0.6424\n",
      "Training loss (for one sample) at sample 2452: 0.7028\n",
      "Training loss (for one sample) at sample 3065: 1.7858\n",
      "Training loss (for one sample) at sample 3678: 1.0380\n",
      "Training loss (for one sample) at sample 4291: 2.4230\n",
      "Training loss (for one sample) at sample 4904: 3.5242\n",
      "Training loss (for one sample) at sample 5517: 0.8169\n",
      "Training loss (for one sample) at sample 6130: 1.4419\n",
      "Epoch 34 | Loss: 1.20888\n",
      "Time taken: 9.98s\n",
      "\n",
      "Start of epoch 35\n",
      "Training loss (for one sample) at sample 613: 1.2893\n",
      "Training loss (for one sample) at sample 1226: 0.7722\n",
      "Training loss (for one sample) at sample 1839: 1.2163\n",
      "Training loss (for one sample) at sample 2452: 1.2745\n",
      "Training loss (for one sample) at sample 3065: 0.9960\n",
      "Training loss (for one sample) at sample 3678: 1.3448\n",
      "Training loss (for one sample) at sample 4291: 1.4273\n",
      "Training loss (for one sample) at sample 4904: 0.5810\n",
      "Training loss (for one sample) at sample 5517: 1.2435\n",
      "Training loss (for one sample) at sample 6130: 0.9333\n",
      "Epoch 35 | Loss: 1.19213\n",
      "Time taken: 9.91s\n",
      "\n",
      "Start of epoch 36\n",
      "Training loss (for one sample) at sample 613: 0.4868\n",
      "Training loss (for one sample) at sample 1226: 1.6798\n",
      "Training loss (for one sample) at sample 1839: 0.7175\n",
      "Training loss (for one sample) at sample 2452: 0.9609\n",
      "Training loss (for one sample) at sample 3065: 1.0676\n",
      "Training loss (for one sample) at sample 3678: 0.7089\n",
      "Training loss (for one sample) at sample 4291: 0.8426\n",
      "Training loss (for one sample) at sample 4904: 0.7986\n",
      "Training loss (for one sample) at sample 5517: 0.6281\n",
      "Training loss (for one sample) at sample 6130: 3.8659\n",
      "Epoch 36 | Loss: 1.17718\n",
      "Time taken: 10.10s\n",
      "\n",
      "Start of epoch 37\n",
      "Training loss (for one sample) at sample 613: 1.6015\n",
      "Training loss (for one sample) at sample 1226: 0.5657\n",
      "Training loss (for one sample) at sample 1839: 0.5474\n",
      "Training loss (for one sample) at sample 2452: 0.6787\n",
      "Training loss (for one sample) at sample 3065: 1.6383\n",
      "Training loss (for one sample) at sample 3678: 1.6416\n",
      "Training loss (for one sample) at sample 4291: 0.8287\n",
      "Training loss (for one sample) at sample 4904: 1.9708\n",
      "Training loss (for one sample) at sample 5517: 2.1022\n",
      "Training loss (for one sample) at sample 6130: 1.2595\n",
      "Epoch 37 | Loss: 1.16279\n",
      "Time taken: 9.91s\n",
      "\n",
      "Start of epoch 38\n",
      "Training loss (for one sample) at sample 613: 2.0021\n",
      "Training loss (for one sample) at sample 1226: 0.4975\n",
      "Training loss (for one sample) at sample 1839: 1.4058\n",
      "Training loss (for one sample) at sample 2452: 0.3840\n",
      "Training loss (for one sample) at sample 3065: 0.8113\n",
      "Training loss (for one sample) at sample 3678: 0.8381\n",
      "Training loss (for one sample) at sample 4291: 0.3528\n",
      "Training loss (for one sample) at sample 4904: 1.5997\n",
      "Training loss (for one sample) at sample 5517: 0.7759\n",
      "Training loss (for one sample) at sample 6130: 0.9874\n",
      "Epoch 38 | Loss: 1.14805\n",
      "Time taken: 9.90s\n",
      "\n",
      "Start of epoch 39\n",
      "Training loss (for one sample) at sample 613: 1.4983\n",
      "Training loss (for one sample) at sample 1226: 1.4605\n",
      "Training loss (for one sample) at sample 1839: 0.6342\n",
      "Training loss (for one sample) at sample 2452: 0.9711\n",
      "Training loss (for one sample) at sample 3065: 1.0120\n",
      "Training loss (for one sample) at sample 3678: 1.3009\n",
      "Training loss (for one sample) at sample 4291: 0.7510\n",
      "Training loss (for one sample) at sample 4904: 0.5837\n",
      "Training loss (for one sample) at sample 5517: 1.1562\n",
      "Training loss (for one sample) at sample 6130: 0.8579\n",
      "Epoch 39 | Loss: 1.13461\n",
      "Time taken: 9.88s\n",
      "\n",
      "Start of epoch 40\n",
      "Training loss (for one sample) at sample 613: 0.4343\n",
      "Training loss (for one sample) at sample 1226: 0.6398\n",
      "Training loss (for one sample) at sample 1839: 0.6996\n",
      "Training loss (for one sample) at sample 2452: 0.6479\n",
      "Training loss (for one sample) at sample 3065: 0.8519\n",
      "Training loss (for one sample) at sample 3678: 0.9723\n",
      "Training loss (for one sample) at sample 4291: 0.7148\n",
      "Training loss (for one sample) at sample 4904: 0.8626\n",
      "Training loss (for one sample) at sample 5517: 0.5477\n",
      "Training loss (for one sample) at sample 6130: 1.2421\n",
      "Epoch 40 | Loss: 1.12199\n",
      "Time taken: 9.95s\n",
      "\n",
      "Start of epoch 41\n",
      "Training loss (for one sample) at sample 613: 1.2465\n",
      "Training loss (for one sample) at sample 1226: 0.9031\n",
      "Training loss (for one sample) at sample 1839: 2.0030\n",
      "Training loss (for one sample) at sample 2452: 0.8743\n",
      "Training loss (for one sample) at sample 3065: 1.3807\n",
      "Training loss (for one sample) at sample 3678: 0.8132\n",
      "Training loss (for one sample) at sample 4291: 0.7261\n",
      "Training loss (for one sample) at sample 4904: 1.2739\n",
      "Training loss (for one sample) at sample 5517: 0.9061\n",
      "Training loss (for one sample) at sample 6130: 1.5523\n",
      "Epoch 41 | Loss: 1.10940\n",
      "Time taken: 10.05s\n",
      "\n",
      "Start of epoch 42\n",
      "Training loss (for one sample) at sample 613: 1.6540\n",
      "Training loss (for one sample) at sample 1226: 1.4765\n",
      "Training loss (for one sample) at sample 1839: 0.6603\n",
      "Training loss (for one sample) at sample 2452: 2.0274\n",
      "Training loss (for one sample) at sample 3065: 0.6255\n",
      "Training loss (for one sample) at sample 3678: 1.4928\n",
      "Training loss (for one sample) at sample 4291: 0.6363\n",
      "Training loss (for one sample) at sample 4904: 0.5549\n",
      "Training loss (for one sample) at sample 5517: 0.8833\n",
      "Training loss (for one sample) at sample 6130: 0.6593\n",
      "Epoch 42 | Loss: 1.09805\n",
      "Time taken: 9.93s\n",
      "\n",
      "Start of epoch 43\n",
      "Training loss (for one sample) at sample 613: 0.8726\n",
      "Training loss (for one sample) at sample 1226: 1.1864\n",
      "Training loss (for one sample) at sample 1839: 0.8305\n",
      "Training loss (for one sample) at sample 2452: 0.8155\n",
      "Training loss (for one sample) at sample 3065: 1.0936\n",
      "Training loss (for one sample) at sample 3678: 0.7537\n",
      "Training loss (for one sample) at sample 4291: 1.6622\n",
      "Training loss (for one sample) at sample 4904: 0.7820\n",
      "Training loss (for one sample) at sample 5517: 0.8454\n",
      "Training loss (for one sample) at sample 6130: 1.5102\n",
      "Epoch 43 | Loss: 1.08674\n",
      "Time taken: 9.93s\n",
      "\n",
      "Start of epoch 44\n",
      "Training loss (for one sample) at sample 613: 0.9939\n",
      "Training loss (for one sample) at sample 1226: 0.6800\n",
      "Training loss (for one sample) at sample 1839: 1.0855\n",
      "Training loss (for one sample) at sample 2452: 0.3731\n",
      "Training loss (for one sample) at sample 3065: 1.1804\n",
      "Training loss (for one sample) at sample 3678: 0.6952\n",
      "Training loss (for one sample) at sample 4291: 0.6819\n",
      "Training loss (for one sample) at sample 4904: 0.9547\n",
      "Training loss (for one sample) at sample 5517: 1.1506\n",
      "Training loss (for one sample) at sample 6130: 0.6621\n",
      "Epoch 44 | Loss: 1.07644\n",
      "Time taken: 9.91s\n",
      "\n",
      "Start of epoch 45\n",
      "Training loss (for one sample) at sample 613: 0.7742\n",
      "Training loss (for one sample) at sample 1226: 1.0807\n",
      "Training loss (for one sample) at sample 1839: 2.0605\n",
      "Training loss (for one sample) at sample 2452: 0.3223\n",
      "Training loss (for one sample) at sample 3065: 0.5908\n",
      "Training loss (for one sample) at sample 3678: 0.5424\n",
      "Training loss (for one sample) at sample 4291: 0.7468\n",
      "Training loss (for one sample) at sample 4904: 0.7841\n",
      "Training loss (for one sample) at sample 5517: 0.8295\n",
      "Training loss (for one sample) at sample 6130: 0.5994\n",
      "Epoch 45 | Loss: 1.06638\n",
      "Time taken: 9.91s\n",
      "\n",
      "Start of epoch 46\n",
      "Training loss (for one sample) at sample 613: 0.8377\n",
      "Training loss (for one sample) at sample 1226: 0.7227\n",
      "Training loss (for one sample) at sample 1839: 0.9447\n",
      "Training loss (for one sample) at sample 2452: 1.2412\n",
      "Training loss (for one sample) at sample 3065: 1.0144\n",
      "Training loss (for one sample) at sample 3678: 0.4305\n",
      "Training loss (for one sample) at sample 4291: 0.5324\n",
      "Training loss (for one sample) at sample 4904: 0.9311\n",
      "Training loss (for one sample) at sample 5517: 1.9572\n",
      "Training loss (for one sample) at sample 6130: 0.9692\n",
      "Epoch 46 | Loss: 1.05642\n",
      "Time taken: 9.96s\n",
      "\n",
      "Start of epoch 47\n",
      "Training loss (for one sample) at sample 613: 0.7599\n",
      "Training loss (for one sample) at sample 1226: 0.8930\n",
      "Training loss (for one sample) at sample 1839: 1.1986\n",
      "Training loss (for one sample) at sample 2452: 0.6641\n",
      "Training loss (for one sample) at sample 3065: 1.0914\n",
      "Training loss (for one sample) at sample 3678: 0.5476\n",
      "Training loss (for one sample) at sample 4291: 0.9123\n",
      "Training loss (for one sample) at sample 4904: 0.5509\n",
      "Training loss (for one sample) at sample 5517: 1.4672\n",
      "Training loss (for one sample) at sample 6130: 0.9446\n",
      "Epoch 47 | Loss: 1.04757\n",
      "Time taken: 9.93s\n",
      "\n",
      "Start of epoch 48\n",
      "Training loss (for one sample) at sample 613: 1.9187\n",
      "Training loss (for one sample) at sample 1226: 0.7162\n",
      "Training loss (for one sample) at sample 1839: 0.8025\n",
      "Training loss (for one sample) at sample 2452: 0.8873\n",
      "Training loss (for one sample) at sample 3065: 0.5458\n",
      "Training loss (for one sample) at sample 3678: 0.9440\n",
      "Training loss (for one sample) at sample 4291: 1.2183\n",
      "Training loss (for one sample) at sample 4904: 1.0769\n",
      "Training loss (for one sample) at sample 5517: 0.5756\n",
      "Training loss (for one sample) at sample 6130: 0.7246\n",
      "Epoch 48 | Loss: 1.03926\n",
      "Time taken: 9.90s\n",
      "\n",
      "Start of epoch 49\n",
      "Training loss (for one sample) at sample 613: 0.9588\n",
      "Training loss (for one sample) at sample 1226: 1.9359\n",
      "Training loss (for one sample) at sample 1839: 0.5077\n",
      "Training loss (for one sample) at sample 2452: 1.2475\n",
      "Training loss (for one sample) at sample 3065: 0.9235\n",
      "Training loss (for one sample) at sample 3678: 0.4359\n",
      "Training loss (for one sample) at sample 4291: 1.2900\n",
      "Training loss (for one sample) at sample 4904: 0.8349\n",
      "Training loss (for one sample) at sample 5517: 0.7813\n",
      "Training loss (for one sample) at sample 6130: 0.4904\n",
      "Epoch 49 | Loss: 1.03097\n",
      "Time taken: 9.91s\n",
      "\n",
      "Start of epoch 50\n",
      "Training loss (for one sample) at sample 613: 0.8146\n",
      "Training loss (for one sample) at sample 1226: 2.0852\n",
      "Training loss (for one sample) at sample 1839: 0.6029\n",
      "Training loss (for one sample) at sample 2452: 1.0280\n",
      "Training loss (for one sample) at sample 3065: 1.4534\n",
      "Training loss (for one sample) at sample 3678: 0.9183\n",
      "Training loss (for one sample) at sample 4291: 1.0309\n",
      "Training loss (for one sample) at sample 4904: 0.5546\n",
      "Training loss (for one sample) at sample 5517: 0.5679\n",
      "Training loss (for one sample) at sample 6130: 0.9925\n",
      "Epoch 50 | Loss: 1.02288\n",
      "Time taken: 9.93s\n"
     ]
    }
   ],
   "source": [
    "# ref: https://www.tensorflow.org/guide/keras/writing_a_training_loop_from_scratch\n",
    "\n",
    "train_dataset = (\n",
    "    tf.data.Dataset.from_tensor_slices(reshape_dataset)\n",
    "    .shuffle(dataset_size, reshuffle_each_iteration=True) # reshuffle the entire dataset\n",
    "    .batch(1)\n",
    ")\n",
    "\n",
    "encoder = autosetup.ComplexEncoder([50, latent_dim])\n",
    "decoder = autosetup.ComplexDecoder([50, sample_shape])\n",
    "\n",
    "# initialize layers: on first call their shape is set based on the shapes of the first data\n",
    "dummy = tf.zeros((1, sample_shape), dtype=tf.complex64)\n",
    "_ = decoder(encoder(dummy))\n",
    "\n",
    "print(type(train_dataset))\n",
    "\n",
    "optimizer = Complex_SGD()\n",
    "alpha = 1e-4 # initial value\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print(f\"\\nStart of epoch {epoch+1}\")\n",
    "    start_time = time.time()\n",
    "\n",
    "    count = 0\n",
    "    epoch_loss = 0.0\n",
    "    for x in train_dataset:\n",
    "        loss, alpha = train_step(x, alpha, encoder, decoder, optimizer)\n",
    "\n",
    "        count += 1 # this is a bit ugly\n",
    "        epoch_loss += loss.numpy()\n",
    "\n",
    "        if count % (int(dataset_size/10)) == 0:\n",
    "            print(\n",
    "                \"Training loss (for one sample) at sample %d: %.4f\"\n",
    "                % (count, float(loss))\n",
    "            )\n",
    "\n",
    "    avg_loss = epoch_loss/(dataset_size)\n",
    "    print(f\"Epoch {epoch+1} | Loss: {avg_loss:.5f}\") \n",
    "    print(\"Time taken: %.2fs\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "962d3882",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the encoder weights (not needed for least squares but helpful in generating examples)\n",
    "wrap_encoder = autosetup.EncoderSave(encoder)\n",
    "_ = wrap_encoder(tf.zeros((1, sample_shape), dtype = tf.complex64))\n",
    "\n",
    "wrap_encoder.save_weights(\"encoder_50epochs_X3train_k10.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c494670b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## save the decoder weights\n",
    "wrap_decoder = autosetup.DecoderSave(decoder)\n",
    "_ = wrap_decoder(tf.zeros((1, latent_dim), dtype = tf.complex64))\n",
    "\n",
    "wrap_decoder.save_weights(\"decoder_50epochs_X3train_k10.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b0acf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load the encoder weights\n",
    "encoder_from_load = autosetup.ComplexEncoder([50, latent_dim])\n",
    "encoder_model_from_load = autosetup.EncoderSave(encoder_from_load)\n",
    "\n",
    "## load the decoder weights\n",
    "decoder_from_load = autosetup.ComplexDecoder([50, sample_shape])\n",
    "model_from_load = autosetup.DecoderSave(decoder_from_load)\n",
    "\n",
    "# build\n",
    "dummy_enc = tf.zeros((1, sample_shape), dtype = tf.complex64)\n",
    "_ = encoder_from_load(dummy_enc)\n",
    "_ = encoder_model_from_load(dummy_enc)\n",
    "\n",
    "dummy_dec = tf.zeros((1, latent_dim), dtype = tf.complex64)\n",
    "_ = decoder_from_load(dummy_dec)\n",
    "_ = model_from_load(tf.zeros((1, latent_dim), dtype = tf.complex64))\n",
    "\n",
    "# load\n",
    "#model_from_load.load_weights(\"saved_decoder_test.weights.h5\")\n",
    "model_from_load.load_weights(\"decoder_8epochs_x_cx_small.weights.h5\")\n",
    "#encoder_model_from_load.load_weights(\"encoder_8epochs_x_cx_small.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fe50fb1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 100)\n",
      "<class 'tensorflow.python.framework.ops.EagerTensor'>\n",
      "tf.Tensor(\n",
      "[[1.0560035 -7.74386898e-02j 1.0573239 +8.20555985e-02j\n",
      "  1.1151439 -9.14341062e-02j 1.0566394 -3.52024026e-02j\n",
      "  0.93093467-7.01772124e-02j 0.98010314-1.08131403e-02j\n",
      "  1.0116947 -6.06522523e-02j 1.0721003 +2.21436489e-02j\n",
      "  0.9977986 +7.54325837e-02j 1.1252183 -9.12407115e-02j\n",
      "  0.98584217+7.65499771e-02j 1.1194189 -3.10081970e-02j\n",
      "  1.0479074 +8.06405470e-02j 1.0364313 -1.06292199e-02j\n",
      "  0.9330173 +1.00438990e-01j 1.053675  +2.20988348e-01j\n",
      "  1.0738726 +2.39383459e-01j 1.0857968 +4.43139449e-02j\n",
      "  1.03635   -7.87219480e-02j 0.9503862 -4.71685864e-02j\n",
      "  0.9079056 -1.49019165e-02j 0.8564091 -3.92761752e-02j\n",
      "  0.9362015 +5.44368252e-02j 0.9575463 +1.76161274e-01j\n",
      "  1.0529252 +5.25073826e-01j 1.0500501 +6.51388526e-01j\n",
      "  1.0366496 +5.24619102e-01j 1.1171299 +3.76128852e-01j\n",
      "  0.96216846+6.17846064e-02j 1.0660409 +8.73341635e-02j\n",
      "  1.0847453 -5.12152584e-03j 1.0241363 +4.79821227e-02j\n",
      "  0.9760021 +1.58020541e-01j 1.0814556 +2.91096598e-01j\n",
      "  1.0535152 +5.55166006e-01j 0.9526315 +2.97709435e-01j\n",
      "  1.0267683 +3.28449428e-01j 1.0330402 +3.21560681e-01j\n",
      "  0.98320305-9.89362523e-02j 1.0880387 -6.31687865e-02j\n",
      "  1.0526031 -1.23771448e-02j 0.9839762 -6.53552450e-03j\n",
      "  1.0246439 +4.25742827e-02j 1.11533   +1.73348099e-01j\n",
      "  0.9749657 +3.69154036e-01j 1.113561  +3.44498783e-01j\n",
      "  0.95758647+4.59754229e-01j 1.1428967 +2.44592279e-01j\n",
      "  0.99573797+1.53462244e-02j 1.0015408 -3.12598161e-02j\n",
      "  1.0500426 +4.51379083e-02j 1.087172  -1.04521774e-02j\n",
      "  0.9759435 +2.05443874e-01j 1.0085222 +3.04104835e-01j\n",
      "  1.0280935 +3.68622541e-01j 1.0485847 +6.11569881e-01j\n",
      "  0.9671645 +4.82455552e-01j 1.0878669 +2.31826872e-01j\n",
      "  1.0816195 -4.65694889e-02j 1.0287117 -6.50902241e-02j\n",
      "  0.9866466 +1.79192815e-02j 1.057642  -5.85351847e-02j\n",
      "  1.0112156 +1.78291842e-01j 0.9980824 +2.88504928e-01j\n",
      "  1.1203616 +2.45235622e-01j 1.0909275 +3.38759243e-01j\n",
      "  1.0355871 +6.25705719e-01j 1.059353  +2.43134424e-01j\n",
      "  0.93053883+1.15311537e-02j 1.0168926 -7.30931060e-03j\n",
      "  0.85039043+4.57549356e-02j 0.95495594+5.30015714e-02j\n",
      "  0.968765  +2.96884030e-01j 0.942666  +3.41189563e-01j\n",
      "  1.0291957 +6.09030545e-01j 1.0264461 +6.50605857e-01j\n",
      "  1.0422275 +2.74099499e-01j 1.0353549 +1.65900618e-01j\n",
      "  1.0780534 -2.67867129e-02j 1.0923184 +4.34010960e-02j\n",
      "  1.0675977 +8.24682638e-02j 1.0707918 +2.50325352e-02j\n",
      "  1.0454168 +2.74871737e-01j 1.0811124 +2.67751455e-01j\n",
      "  1.0067972 +3.16208273e-01j 1.0304202 +1.25436127e-01j\n",
      "  0.9461455 +1.04200691e-01j 1.0102051 -3.99327241e-02j\n",
      "  0.984258  -8.45163465e-02j 0.84359413-6.75433576e-02j\n",
      "  0.9713124 -1.68332167e-03j 1.0173757 +9.56301298e-03j\n",
      "  0.92174274-2.92138383e-02j 0.9609496 -1.77715123e-02j\n",
      "  0.9054386 +3.03061195e-02j 1.1156515 -3.80987413e-02j\n",
      "  1.0033677 +6.12808503e-02j 1.0021721 -6.07553907e-02j\n",
      "  0.95382047-2.86927359e-04j 0.9473032 -7.51902387e-02j]], shape=(1, 100), dtype=complex64)\n"
     ]
    }
   ],
   "source": [
    "## test if it does the same\n",
    "x_testing = tf.reshape(x_train_cx_small[0], [1,-1])\n",
    "print(x_testing.shape)\n",
    "print(type(x_testing))\n",
    "y = encoder(x_testing)\n",
    "\n",
    "# if zeros are returned, test succesfull\n",
    "#print(decoder(y) - model_from_load.decoder(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c3531ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "## run if decoder should be loaded from save\n",
    "decoder = model_from_load.decoder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9de89a64",
   "metadata": {},
   "source": [
    "#### Extracting and wrapping autoencoder function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6cc3a47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## testing the quality of the encoder decoder\n",
    "# random output\n",
    "z_random = np.random.normal(size=(1,latent_dim))\n",
    "test_z = decoder(z_random) #test_z is a tf \n",
    "show_z = tf.reshape(test_z, (1,nx,nx))\n",
    "im_z = tf.math.imag(show_z)\n",
    "\n",
    "plt.figure()\n",
    "plt.title(\"Output of random latent space input\")\n",
    "plt.imshow(im_z[0])\n",
    "\n",
    "# comparing training image with result of decoder\n",
    "x_testing = tf.reshape(dataset[0], [1,-1])\n",
    "y = encoder(x_testing)\n",
    "x_recon = decoder(y)\n",
    "im_x = tf.math.imag(tf.reshape(x_recon, (1,nx,nx)))\n",
    "\n",
    "x_plottable = dataset[0].numpy().flatten()\n",
    "x_plot_recon = x_recon.numpy().flatten()\n",
    "\n",
    "plot_result(x_plottable, x_plot_recon)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "fac24c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute function generative map\n",
    "def make_tensor_shape(z):\n",
    "    #z = z.reshape((1,-1))\n",
    "    tensor_z = tf.convert_to_tensor(z, dtype=tf.complex64)\n",
    "    return tf.reshape(tensor_z,[1,-1])\n",
    "\n",
    "def make_tensor(z):\n",
    "    return tf.convert_to_tensor(z, dtype=tf.complex64)\n",
    "\n",
    "# wrapper for decoder to numpy function\n",
    "def decoderfunc_1D(z, decoder):\n",
    "    '''\n",
    "    Converts the autoencoder.decoder function into a generative embedding function\n",
    "\n",
    "    input:\n",
    "        z:              np.array of length (latent_dim)\n",
    "        decoder:        custom class autosetup.ComplexDecoder, numpy.array(sample size, latent_dim) --> tensor(sample size, dim^2))    \n",
    "\n",
    "    output:\n",
    "        decoderfunc_1D: function that maps z to numpy array of lenght dim^2 (flattened original image). flatten() ensures shape (n,) and not (1,n)\n",
    "    '''\n",
    "    return decoder(tf.reshape(make_tensor(z), [1,-1])).numpy().flatten()\n",
    "\n",
    "# wrapper for Jacobian computation to numpy function\n",
    "def jac_decoder_1D(z, decoder, type = \"normal\"):\n",
    "    '''\n",
    "    Converts the CBP_decoder computation into a numpy function, outputting the R or R*-derivative of the decoder in z as a numpy array\n",
    "    NOTE: activation function is hardcoded at this point\n",
    "\n",
    "    input:\n",
    "        z:              np.array of length (latent_dim)\n",
    "        decoder:        custom class autosetup.ComplexDecoder, numpy.array(sample size, latent_dim) --> tensor(sample size, dim^2))\n",
    "        type:           str, either \"normal\" or \"conj\", indicating the R or the R*-derivative\n",
    "    '''\n",
    "    dG_dz, dG_dzstar = CBP_decoder(tf.reshape(make_tensor(z), [1,-1]), decoder, autosetup.Jac_modrelu)\n",
    "    if type == \"normal\":\n",
    "        return dG_dz.numpy()\n",
    "    elif type == \"conj\":\n",
    "        return dG_dzstar.numpy()\n",
    "    else:\n",
    "        raise ValueError(f\"Invalid type '{type}. Must be 'normal' or 'conj'.\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e57d273",
   "metadata": {},
   "source": [
    "### Integrate with least squares signal optimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "5615aec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Op:\n",
    "    def __init__(self, fun, jac, shape):\n",
    "        self.eval = fun\n",
    "        self.jac = jac\n",
    "        self.shape = shape\n",
    "        \n",
    "def objective(z, y, A, G, Gstar, w=1, lmbda = 0):\n",
    "    \"\"\"\n",
    "    LS objective\n",
    "        (0.5)*\\|A(G(z)) - y\\|_2^2 + 0.5*lmbda**2*\\|w*z\\|_2^2\n",
    "    \"\"\"\n",
    "    if len(y) != A.shape[0]:\n",
    "        print(\"y and A don't match\")\n",
    "        return\n",
    "    if len(z)//2 != G.shape[1]:\n",
    "        print(\"z and G don't match\")\n",
    "        return\n",
    "    if A.shape[1] != G.shape[0]:\n",
    "        print(\"A and G don't match!\")\n",
    "        return\n",
    "    \n",
    "    k  = len(z)//2\n",
    "    zc = z[:k] + 1j*z[k:]\n",
    "    \n",
    "    xc = G.eval(zc)\n",
    "    Dx = G.jac(zc)\n",
    "    Dxstar = Gstar.jac(zc)\n",
    "\n",
    "    #print(\"Dx norm\", np.linalg.norm(Dx @ np.ones_like(zc)))\n",
    "    \n",
    "    yp = A.eval(xc)\n",
    "    Dy = A.jac(xc)\n",
    "\n",
    "    #print(\"Dy\", Dy.shape)\n",
    "\n",
    "    DF = Dxstar.T@Dy.T + Dx.H@Dy.H\n",
    "\n",
    "    val    = (0.5)*np.linalg.norm(yp - y)**2 + (0.5*lmbda**2)*np.linalg.norm(w*zc)**2\n",
    "    #gradc  = Dx.H@(Dy.H@(yp - y)) + (lmbda**2)*(w*w)*zc\n",
    "    gradc  = DF@(yp - y) + (lmbda**2)*(w*w)*zc\n",
    "\n",
    "    #print(\"val\", val)\n",
    "    #print(\"gradc\", gradc)\n",
    "    \n",
    "    grad  = np.concatenate((np.real(gradc), np.imag(gradc)))\n",
    "    \n",
    "    return val, grad\n",
    "\n",
    "def reconstruct(xtrue, A, G, Gstar, w=1, sigma=0, lmbda=0):\n",
    "    # sizes\n",
    "    m,n = A.shape\n",
    "    n,k = G.shape\n",
    "    \n",
    "    # generate data\n",
    "    yobs  = A.eval(xtrue) + sigma*np.random.randn(m)\n",
    "\n",
    "    # inference\n",
    "    guess_z0 = np.concatenate([np.ones(k), 0.5*np.ones(k)])\n",
    "    fake_z0_tf = encoder(make_tensor_shape(xtrue))\n",
    "    fake_z0_cx = fake_z0_tf.numpy().flatten()\n",
    "    fake_z0 = np.concatenate([np.real(fake_z0_cx), np.imag(fake_z0_cx)])\n",
    "\n",
    "    result = minimize(objective, x0=guess_z0, args=(yobs, A, G, Gstar, w, lmbda), method='L-BFGS-B', jac=True, options={\n",
    "        'maxiter': 10000,      # total outer iterations\n",
    "        'maxls': 40,          # line search steps per iteration\n",
    "        'ftol' : 1e-14,\n",
    "        'gtol': 1e-14,         # gradient tolerance\n",
    "        'disp': True          # print optimization log\n",
    "    })\n",
    "    \n",
    "    # result = minimize(objective, np.concatenate([np.ones(k), 0.5*np.ones(k)]), args=(yobs, A, G, w, lmbda), method='Powell', jac=True, options={\n",
    "    #     'maxiter': 1000,      # total outer iterations\n",
    "    #     'ftol' : 1e-10,\n",
    "    #     'disp': True          # print optimization log\n",
    "    # })\n",
    "\n",
    "    # result\n",
    "    zhat = result.x[:k] + 1j*result.x[k:]\n",
    "    xhat = G.eval(zhat)\n",
    "\n",
    "    # print(\"zhat\", zhat)\n",
    "    # print(\"xhat\", xhat)\n",
    "\n",
    "    # print(\"Result message:\", result.message)\n",
    "    # print(\"Result status:\", result.status)\n",
    "    # print(\"Function evals:\", result.nfev)\n",
    "    # print(\"Jacobian evals:\", result.njev)\n",
    "    # print(\"Final gradient norm:\", np.linalg.norm(result.jac))\n",
    "    \n",
    "    # correct global phase\n",
    "    phi = np.mean(np.angle(xtrue/(xhat + 1e-5*np.ones_like(xhat)))) # avoid division by zero for bad reconstructions\n",
    "    #phi = np.mean(np.angle(xtrue/xhat))\n",
    "    xhat_corr = np.exp(1j*phi)*xhat\n",
    "    \n",
    "    # relative error\n",
    "    error = np.linalg.norm(xhat_corr - xtrue)/np.linalg.norm(xtrue)\n",
    "    \n",
    "    # return\n",
    "    return error, xhat_corr, yobs\n",
    "\n",
    "def plot_result(xtrue, xhat):\n",
    "    n  = len(xtrue)\n",
    "    nx = int(np.sqrt(n))\n",
    "    \n",
    "    # plot results\n",
    "    fig, ax = plt.subplots(2,2)\n",
    "\n",
    "    ax[0,0].imshow(np.real(xtrue.reshape((nx,nx))),clim=[0,1])\n",
    "    ax[0,0].set_title(r'$\\Re(x_{true})$')\n",
    "    ax[1,0].imshow(np.imag(xtrue.reshape((nx,nx))),clim=[0,1])\n",
    "    ax[1,0].set_title(r'$\\Im(x_{true})$')\n",
    "    ax[0,1].imshow(np.real(xhat.reshape((nx,nx))),clim=[0,1])\n",
    "    ax[0,1].set_title(r'$\\Re(x_{est})$')\n",
    "    ax[1,1].imshow(np.imag(xhat.reshape((nx,nx))),clim=[0,1])\n",
    "    ax[1,1].set_title(r'$\\Im(x_{est})$')\n",
    "\n",
    "    fig.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "5c5f9989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MaskedFourier(M):\n",
    "    \"\"\"\n",
    "    Defined masked 2D fourier transform as linear operator.\n",
    "    \n",
    "    input:\n",
    "        M - 3D array of size n x n x m containing m masks of size n x n\n",
    "        \n",
    "    out:\n",
    "        A - linear operator representing the masked Fourier transforms\n",
    "        \n",
    "    \n",
    "    \"\"\"\n",
    "    nx = M.shape[0]\n",
    "    mx = M.shape[2]\n",
    "    \n",
    "    mv  = lambda x : fft2(M*(x.reshape((nx,nx,1))), axes=(0,1)).flatten()\n",
    "    rmv = lambda y : nx*nx*np.sum(np.conj(M)*ifft2(y.reshape((nx,nx,mx)), axes=(0,1)),axis=2).flatten()\n",
    "    A   = LinearOperator((mx*nx*nx, nx*nx), matvec=mv, rmatvec=rmv) # rmatvec is conjugate operation, so A^H * v\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "id": "9814a74d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 100)\n"
     ]
    }
   ],
   "source": [
    "# define forward operator with binary masks\n",
    "mx = 100       # number of masks\n",
    "m  = mx * n\n",
    "\n",
    "M = np.random.randn(nx,nx,mx)\n",
    "M[M<0]=0\n",
    "M[M>0]=1\n",
    "\n",
    "MF   = MaskedFourier(M)\n",
    "print(MF.shape)\n",
    "Afun = lambda x : np.abs(MF@x)**2\n",
    "Ajac = lambda x : LinearOperator((m, n), matvec=lambda z : (MF@x)*np.conj(MF@np.conj(z)), rmatvec=lambda z : (MF.H@((MF@x)*z)))\n",
    "\n",
    "A    = Op(fun = Afun, jac = Ajac, shape=(m,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "013bb903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get prior from decoder\n",
    "k               = latent_dim\n",
    "block_identity  = lambda mat : np.concatenate((mat, np.eye(n)), axis=1)\n",
    "\n",
    "\n",
    "#define generative models\n",
    "I = Op(fun = lambda z : z, jac = lambda z: LinearOperator((n, n), matvec = lambda z : z, rmatvec = lambda z : z), shape=(n,n))\n",
    "\n",
    "G = Op(fun = lambda z : decoderfunc_1D(z, decoder), \n",
    "       jac = lambda z : LinearOperator((n,k), matvec = lambda v : jac_decoder_1D(z, decoder) @ v, \n",
    "                                       rmatvec = lambda p : np.conj(jac_decoder_1D(z, decoder).T) @ p),\n",
    "       shape = (n,k))\n",
    "\n",
    "Gstar = Op(fun = lambda z : decoderfunc_1D(z, decoder), \n",
    "       jac = lambda z : LinearOperator((n,k), matvec = lambda v : jac_decoder_1D(z, decoder, type=\"conj\") @ v, \n",
    "                                       rmatvec = lambda p : np.conj(jac_decoder_1D(z, decoder, type=\"conj\").T) @ p),\n",
    "       shape = (n,k))\n",
    "\n",
    "H = Op(fun = lambda z : decoderfunc_1D(z[:k], decoder) + z[k:], \n",
    "       jac = lambda z : LinearOperator((n,k+n), matvec = lambda v : block_identity(jac_decoder_1D(z[:k], decoder)) @ v, \n",
    "                                       rmatvec = lambda p : np.conj(block_identity(jac_decoder_1D(z[:k], decoder)).T) @ p),\n",
    "       shape = (n,k+n))\n",
    "\n",
    "# not 100% sure about this one\n",
    "Hstar = Op(fun = lambda z : decoderfunc_1D(z[:k], decoder) + z[k:], \n",
    "       jac = lambda z : LinearOperator((n,k+n), matvec = lambda v : block_identity(jac_decoder_1D(z[:k], decoder, type=\"conj\")) @ v, \n",
    "                                       rmatvec = lambda p : np.conj(block_identity(jac_decoder_1D(z[:k], decoder, type = \"conj\")).T) @ p),\n",
    "       shape = (n,k+n))\n",
    "\n",
    "# define weights\n",
    "w = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6ec47418",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100,)\n",
      "(100, 10)\n",
      "(10, 100)\n",
      "conj G (100, 10)\n",
      "conj G.H (10, 100)\n",
      "<class 'scipy.sparse.linalg._interface._CustomLinearOperator'>\n",
      "<class 'scipy.sparse.linalg._interface._CustomLinearOperator'>\n",
      "(100,)\n",
      "(10,)\n",
      "(100,)\n",
      "(100, 110)\n",
      "(110, 100)\n"
     ]
    }
   ],
   "source": [
    "# testing operators\n",
    "z_testing = np.ones(10)\n",
    "x_testing = np.ones(100)\n",
    "# y_testing = np.ones((1000))\n",
    "h_testing = np.ones((110))\n",
    "\n",
    "print(G.eval(z_testing).shape)\n",
    "\n",
    "G_jac = G.jac(z_testing)\n",
    "G_H = G_jac.H\n",
    "\n",
    "Gstar_jac = Gstar.jac(z_testing)\n",
    "Gstar_H = Gstar_jac.H\n",
    "\n",
    "print(G_jac.shape)\n",
    "print(G_H.shape)\n",
    "\n",
    "print(\"conj G\", Gstar_jac.shape)\n",
    "print(\"conj G.H\", Gstar_H.shape)\n",
    "\n",
    "print(type(G_jac))\n",
    "print(type(G_H))\n",
    "\n",
    "G_jac@z_testing\n",
    "print((G_jac@z_testing).shape)\n",
    "\n",
    "G_Hx = G_H @ x_testing\n",
    "print(G_Hx.shape)\n",
    "\n",
    "H_func = H.eval(h_testing)\n",
    "H_jac = H.jac(h_testing)\n",
    "H_H = H_jac.H\n",
    "\n",
    "print(H_func.shape)\n",
    "print(H_jac.shape)\n",
    "print(H_H.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb9f719",
   "metadata": {},
   "source": [
    "##### Example of reconstruction with no noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "6501943e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y (1000,)\n",
      "xc (100,)\n",
      "Dx (100, 10)\n",
      "yp (1000,)\n",
      "Dy (1000, 100)\n",
      "val 27660830.740326907\n",
      "tussenstap (100,)\n",
      "Dx_H (10, 100)\n",
      "tussenstap2 (10, 1000)\n",
      "tussenstap3 (10,)\n",
      "gradc (10,)\n",
      "grad (20,)\n"
     ]
    }
   ],
   "source": [
    "z = np.ones(2*k)\n",
    "w = 1\n",
    "lmbda = 0\n",
    "sigma = 0\n",
    "\n",
    "xtrue = x_test_cx_small[0].numpy()\n",
    "xtrue_1D = xtrue.flatten()\n",
    "\n",
    "y = A.eval(xtrue_1D) + sigma*np.random.randn(m)\n",
    "\n",
    "temp  = len(z)//2\n",
    "zc = z[:temp] + 1j*z[temp:]\n",
    "\n",
    "#print(\"zc\", zc.shape)\n",
    "\n",
    "print(\"y\", y.shape)\n",
    "\n",
    "xc = G.eval(zc)\n",
    "Dx = G.jac(zc)\n",
    "\n",
    "print(\"xc\", xc.shape)\n",
    "print(\"Dx\", Dx.shape)\n",
    "    \n",
    "yp = A.eval(xc)\n",
    "Dy = A.jac(xc)\n",
    "\n",
    "print(\"yp\", yp.shape)\n",
    "print(\"Dy\", Dy.shape)\n",
    "\n",
    "val    = (0.5)*np.linalg.norm(yp - y)**2 + (0.5*lmbda**2)*np.linalg.norm(w*zc)**2    \n",
    "\n",
    "print(\"val\", val)\n",
    "\n",
    "tussenstap = Dy.H @ (yp - y)\n",
    "\n",
    "print(\"tussenstap\", tussenstap.shape)\n",
    "\n",
    "Dx_H = Dx.H\n",
    "print(\"Dx_H\", Dx_H.shape)\n",
    "\n",
    "print(\"tussenstap2\", (Dx.H @ Dy.H).shape)\n",
    "\n",
    "tussenstap3 = (Dx.H @ Dy.H) @ (yp - y)\n",
    "print(\"tussenstap3\", tussenstap3.shape)\n",
    "\n",
    "gradc  = Dx.H@(Dy.H@(yp - y)) + (lmbda**2)*(w*w)*zc\n",
    "\n",
    "print(\"gradc\", gradc.shape)\n",
    "    \n",
    "grad  = np.concatenate((np.real(gradc), np.imag(gradc)))\n",
    "\n",
    "print(\"grad\", grad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "a3ffba92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reconstruction error (sigma = 0):  0.06814345\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test generative model itself\n",
    "sigma = 0\n",
    "xtrue = datatest[1].numpy()\n",
    "xtrue_1D = xtrue.flatten()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(\"ground truth\")\n",
    "# plt.imshow(np.imag(xtrue.reshape(nx,nx)))\n",
    "\n",
    "error, xhat_corr, yobs = reconstruct(xtrue_1D, A, G, Gstar, w=1, sigma = sigma, lmbda=0)\n",
    "#xhat_corr = xhat_corr.reshape((nx,nx))\n",
    "\n",
    "print(f\"Reconstruction error (sigma = {sigma}): \", error)\n",
    "\n",
    "plot_result(xtrue_1D, xhat_corr)\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(f\"reconstruction with sigma = {sigma}\")\n",
    "# plt.imshow(np.imag(xhat_corr))\n",
    "\n",
    "# compare with direct reconstruction of the test image\n",
    "compare_y = encoder(make_tensor_shape(xtrue))\n",
    "compare_x = decoder(compare_y).numpy()\n",
    "\n",
    "# plt.figure()\n",
    "# plt.title(f\"reconstruction through decoder\")\n",
    "# plt.imshow(np.imag(compare_x.reshape(nx,nx)))\n",
    "\n",
    "fig, ax = plt.subplots(2,1)\n",
    "\n",
    "ax[0].imshow(np.real(compare_x.reshape((nx,nx))),clim=[0,1])\n",
    "ax[0].set_title(r'$\\Re(x_{recon})$')\n",
    "ax[1].imshow(np.imag(compare_x.reshape((nx,nx))),clim=[0,1])\n",
    "ax[1].set_title(r'$\\Im(x_{recon})$')\n",
    "\n",
    "fig.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1fa354a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x16a82929e50>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# test with l2\n",
    "xtrue = x_test_cx_small[0].numpy()\n",
    "xtrue_1D = xtrue.flatten()\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.imag(xtrue))\n",
    "\n",
    "error, xhat_corr, yobs = reconstruct(xtrue_1D, A, G, w=1, sigma=0.01, lmbda=0)\n",
    "\n",
    "xhat_corr = xhat_corr.reshape((nx,nx))\n",
    "\n",
    "\n",
    "plt.figure()\n",
    "plt.imshow(np.imag(xhat_corr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa7fe53",
   "metadata": {},
   "source": [
    "### Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78a78dd0",
   "metadata": {},
   "source": [
    "##### but first test if my code works for the error plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a139ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Abel\\AppData\\Local\\Temp\\ipykernel_1516\\1002254489.py:69: RuntimeWarning: invalid value encountered in divide\n",
      "  phi = np.mean(np.angle(xtrue/xhat))\n",
      "C:\\Users\\Abel\\AppData\\Local\\Temp\\ipykernel_1516\\1002254489.py:69: RuntimeWarning: divide by zero encountered in divide\n",
      "  phi = np.mean(np.angle(xtrue/xhat))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1516\\3807263837.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0msigmas\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlogspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m6\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[0merrors_i\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigmas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     19\u001b[0m \u001b[0mxhats_i\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigmas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'complex'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 20\u001b[1;33m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     21\u001b[0m \u001b[0merrors_g\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigmas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[0mxhats_g\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msigmas\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'complex'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1516\\1002254489.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(xtrue, A, G, w, sigma, lmbda)\u001b[0m\n\u001b[0;32m     55\u001b[0m     \u001b[1;31m# print(\"k\", k)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[1;31m# print(\"m\", m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# inference\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 59\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mminimize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobjective\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx0\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mA\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mG\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlmbda\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'L-BFGS-B'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mjac\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     60\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m     \u001b[1;31m# result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mzhat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1j\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\scipy\\optimize\\_minimize.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[0;32m    709\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'newton-cg'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m         res = _minimize_newtoncg(fun, x0, args, jac, hess, hessp, callback,\n\u001b[0;32m    711\u001b[0m                                  **options)\n\u001b[0;32m    712\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'l-bfgs-b'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 713\u001b[1;33m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[0;32m    714\u001b[0m                                callback=callback, **options)\n\u001b[0;32m    715\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'tnc'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    716\u001b[0m         res = _minimize_tnc(fun, x0, args, jac, bounds, callback=callback,\n",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\scipy\\optimize\\_lbfgsb_py.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[0;32m    403\u001b[0m             \u001b[1;31m# The minimization routine wants f and g at the current x.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m             \u001b[1;31m# Note that interruptions due to maxfun are postponed\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    405\u001b[0m             \u001b[1;31m# until the completion of the current minimization iteration.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m             \u001b[1;31m# Overwrite f and g:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m             \u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m         \u001b[1;32melif\u001b[0m \u001b[0mtask_str\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstartswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mb'NEW_X'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m             \u001b[1;31m# new iteration\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    410\u001b[0m             \u001b[0mn_iterations\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    293\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mfun_and_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    295\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_x_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 296\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    297\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    298\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_fun_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf_updated\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m?\u001b[1;34m()\u001b[0m\n\u001b[0;32m    162\u001b[0m         \u001b[1;32mdef\u001b[0m \u001b[0mupdate_fun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun_wrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\scipy\\optimize\\_differentiable_functions.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x)\u001b[0m\n\u001b[0;32m    141\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnfev\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    142\u001b[0m             \u001b[1;31m# Send a copy because the user may overwrite it.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m             \u001b[1;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m             \u001b[1;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 145\u001b[1;33m             \u001b[0mfx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    146\u001b[0m             \u001b[1;31m# Make sure the function returns a true scalar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    147\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     77\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;34m\"\"\" returns the function value \"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\scipy\\optimize\\_optimize.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x, *args)\u001b[0m\n\u001b[0;32m     70\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_compute_if_needed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     72\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m             \u001b[0mfg\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1516\\1002254489.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(z, y, A, G, w, lmbda)\u001b[0m\n\u001b[0;32m     32\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[1;31m#print(\"Dy\", Dy.shape)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m     \u001b[0mval\u001b[0m    \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m0.5\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 36\u001b[1;33m     \u001b[0mgradc\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[0mDx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m@\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mH\u001b[0m\u001b[1;33m@\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0myp\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlmbda\u001b[0m\u001b[1;33m**\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mzc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     37\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     38\u001b[0m     \u001b[1;31m# print(\"val\", val)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[1;31m# print(\"gradc\", gradc)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\scipy\\sparse\\linalg\\_interface.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, other)\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__matmul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    452\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    453\u001b[0m             raise ValueError(\"Scalar operands are not allowed, \"\n\u001b[0;32m    454\u001b[0m                              \"use '*' instead\")\n\u001b[1;32m--> 455\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__mul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\scipy\\sparse\\linalg\\_interface.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    410\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__mul__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 411\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\scipy\\sparse\\linalg\\_interface.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    440\u001b[0m                 \u001b[1;31m# Sparse matrices shouldn't be converted to numpy arrays.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m                 \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 444\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    445\u001b[0m             \u001b[1;32melif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    446\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    447\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\scipy\\sparse\\linalg\\_interface.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    234\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'dimension mismatch'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m         \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatrix\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0masmatrix\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\scipy\\sparse\\linalg\\_interface.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_matvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 593\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__matvec_impl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1516\\215325387.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(p)\u001b[0m\n\u001b[1;32m---> 16\u001b[1;33m                                        rmatvec = lambda p : np.conj(block_identity(jac_decoder_1D(z[:k], decoder)).T) @ p),\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_1516\\3354511919.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(z, decoder)\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0minput\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mz\u001b[0m\u001b[1;33m:\u001b[0m              \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m \u001b[0mof\u001b[0m \u001b[0mlength\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlatent_dim\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m         decoder:        custom class autosetup.ComplexDecoder, numpy.array(sample size, latent_dim) --> tensor(sample size, dim^2))\n\u001b[0;32m     33\u001b[0m     '''\n\u001b[1;32m---> 34\u001b[1;33m     \u001b[0mdG_dz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCBP_decoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmake_tensor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mautosetup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mJac_modrelu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     35\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdG_dz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abel\\Documents\\GitHub\\signal-thesis\\complex autoencoder\\backpropagation.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(z, decoder, jac_act)\u001b[0m\n\u001b[0;32m    193\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0mda_dq_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mda_dql_prev\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    195\u001b[0m         \u001b[0mda_dqstar_list\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mda_dql_prev_star\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    196\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 197\u001b[1;33m     \u001b[0mdaL_dz\u001b[0m      \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mda_dq_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_lprev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mda_dqstar_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_lprev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    198\u001b[0m     \u001b[0mdaL_dzstar\u001b[0m  \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mda_dq_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_lprev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW2\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mda_dqstar_list\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m@\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlayer_lprev\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mdaL_dz\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdaL_dzstar\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\framework\\override_binary_operator.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    127\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    128\u001b[0m           \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    129\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\ops\\tensor_math_operator_overrides.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(a, b, name)\u001b[0m\n\u001b[0;32m     49\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_matmul_factory\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     50\u001b[0m   \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpython\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mops\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatmul_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(a, b, name)\u001b[0m\n\u001b[0;32m   3812\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mmatmul_wrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=missing-function-docstring\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3813\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_numpy_style_type_promotion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3814\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_matmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3815\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mmatmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\ops\\weak_tensor_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    140\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    141\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mis_auto_dtype_conversion_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 142\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    143\u001b[0m     \u001b[0mbound_arguments\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msignature\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    144\u001b[0m     \u001b[0mbound_arguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_defaults\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    145\u001b[0m     \u001b[0mbound_kwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbound_arguments\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marguments\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\util\\traceback_utils.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    151\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    152\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    153\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    154\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 155\u001b[1;33m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\util\\dispatch.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m   1264\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mop_dispatch_handler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1265\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mresult\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mOpDispatcher\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNOT_SUPPORTED\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1266\u001b[0m           \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1267\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1268\u001b[1;33m           \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(a, b, transpose_a, transpose_b, adjoint_a, adjoint_b, a_is_sparse, b_is_sparse, output_type, grad_a, grad_b, name)\u001b[0m\n\u001b[0;32m   3695\u001b[0m             \u001b[0mgrad_y\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mgrad_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3696\u001b[0m             \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3697\u001b[0m         )\n\u001b[0;32m   3698\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3699\u001b[1;33m         return gen_math_ops.mat_mul(\n\u001b[0m\u001b[0;32m   3700\u001b[0m             \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3701\u001b[0m             \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3702\u001b[0m             \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\Abel\\miniconda3\\envs\\wtf\\lib\\site-packages\\tensorflow\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36m?\u001b[1;34m(a, b, transpose_a, transpose_b, grad_a, grad_b, name)\u001b[0m\n\u001b[0;32m   6233\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6234\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6235\u001b[0m       \u001b[0m_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mraise_from_not_ok_status\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6236\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6237\u001b[1;33m       \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   6238\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6239\u001b[0m       return mat_mul_eager_fallback(\n\u001b[0;32m   6240\u001b[0m           \u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mb\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_a\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_a\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtranspose_b\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtranspose_b\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# scan over noise levels with and without generative model on in-distribution gt\n",
    "ns     = 2\n",
    "sigmas = np.logspace(-6,6,10)\n",
    "\n",
    "errors_i = np.zeros((len(sigmas),ns))\n",
    "xhats_i  = np.zeros((len(sigmas),ns, n),dtype='complex')\n",
    "\n",
    "errors_g = np.zeros((len(sigmas),ns))\n",
    "xhats_g  = np.zeros((len(sigmas),ns, n),dtype='complex')\n",
    "\n",
    "errors_c = np.zeros((len(sigmas),ns))\n",
    "xhats_c  = np.zeros((len(sigmas),ns, n),dtype='complex')\n",
    "\n",
    "for i in range(len(sigmas)):\n",
    "    for j in range(ns):\n",
    "        xtrue = G.eval(np.random.randn(k) + 1j*np.random.randn(k)) #here xtrue comes from the generative model\n",
    "\n",
    "        errors_i[i,j], xhats_i[i,j,:], _ = reconstruct(xtrue, A, I, w=1, sigma=sigmas[i], lmbda=sigmas[i])\n",
    "        errors_g[i,j], xhats_g[i,j,:], _ = reconstruct(xtrue, A, G, w=1, sigma=sigmas[i], lmbda=sigmas[i])\n",
    "        errors_c[i,j], xhats_c[i,j,:], _ = reconstruct(xtrue, A, H, w=1, sigma=sigmas[i], lmbda=1e1*sigmas[i])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wtf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
